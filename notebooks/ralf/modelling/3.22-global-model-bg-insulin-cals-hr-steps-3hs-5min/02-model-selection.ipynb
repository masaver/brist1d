{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modelling most important features\n",
    "\n",
    "## Model Selection"
   ],
   "id": "c4f5fa4ffbc53369"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_data_file = os.path.join('..', '..', '..', '..', 'data', 'raw', 'train.csv')\n",
    "train_data = pd.read_csv(train_data_file, index_col=0, low_memory=False)\n",
    "\n",
    "validation_data_file = os.path.join('..', '..', '..', '..', 'data', 'interim', 'all_test_4_55h.csv')\n",
    "validation_data = pd.read_csv(validation_data_file, index_col=0, low_memory=False)\n",
    "\n",
    "additional_train_data_file = os.path.join('..', '..', '..', '..', 'data', 'interim', 'all_test_3h.csv')\n",
    "additional_train_data = pd.read_csv(additional_train_data_file, index_col=0, low_memory=False)\n",
    "# remove from additional data patients that are not in validation data ids\n",
    "additional_train_data = additional_train_data[~additional_train_data.index.isin(validation_data.index.unique())]\n",
    "\n",
    "# merge train and additional data\n",
    "train_data = pd.concat([train_data, additional_train_data], axis=0)\n",
    "\n",
    "# do not train with patients that are not have to be predicted\n",
    "test_data_file = os.path.join('..', '..', '..', '..', 'data', 'raw', 'test.csv')\n",
    "test_data = pd.read_csv(test_data_file, index_col=0, low_memory=False)\n",
    "\n",
    "unique_patients = test_data['p_num'].unique()\n",
    "train_data = train_data[train_data['p_num'].isin(unique_patients)]\n",
    "validation_data = validation_data[validation_data['p_num'].isin(unique_patients)]\n",
    "test_data = test_data[test_data['p_num'].isin(unique_patients)]"
   ],
   "id": "61c204ab0f9451f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pipelines import pipeline\n",
    "\n",
    "train_data = pipeline.fit_transform(train_data)\n",
    "validation_data = pipeline.transform(validation_data)"
   ],
   "id": "2f7ab421d5ccf55c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Splitting",
   "id": "3d2d3faf26fe5447"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = train_data.drop(columns=['bg+1:00'])\n",
    "y_train = train_data['bg+1:00']\n",
    "\n",
    "X_test = validation_data.drop(columns=['bg+1:00'])\n",
    "y_test = validation_data['bg+1:00']"
   ],
   "id": "5e39b1845bc7e6d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Selection with LazyPredict",
   "id": "591898d90d93c5e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from notebooks.helpers.LazyPredict import get_lazy_regressor\n",
    "\n",
    "reg = get_lazy_regressor(exclude=['SVR'])\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ],
   "id": "bcc68a5591d6ea65",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
