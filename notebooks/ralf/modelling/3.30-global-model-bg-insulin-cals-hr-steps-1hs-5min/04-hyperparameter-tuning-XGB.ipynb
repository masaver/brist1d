{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter Tuning\n",
   "id": "c4f5fa4ffbc53369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:15:35.856217Z",
     "start_time": "2024-11-25T23:56:00.809632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from data import load_data_selected_features\n",
    "from pipelines_selected_features import pipeline\n",
    "\n",
    "train_data, additional_train_data, test_data = load_data_selected_features()\n",
    "all_train_data = pipeline.fit_transform(pd.concat([train_data, additional_train_data]))\n",
    "\n",
    "# cut the data into train, additional train and test\n",
    "train_data = all_train_data.loc[train_data.index]\n",
    "additional_train_data = all_train_data.loc[additional_train_data.index]\n",
    "\n",
    "X_train = train_data.drop(columns=['bg+1:00'])\n",
    "y_train = train_data['bg+1:00']\n",
    "\n",
    "X_additional_train = additional_train_data.drop(columns=['bg+1:00'])\n",
    "y_additional_train = additional_train_data['bg+1:00']"
   ],
   "id": "6a34b21d4bb55fe0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tune XGBoost",
   "id": "49e54cddfe4a3b63"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-26T00:15:35.891738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "from skopt.space import Integer, Real\n",
    "from model_hyperparameter_tuning import tune_hyperparameters\n",
    "\n",
    "search_space = {\n",
    "    'n_estimators': Integer(1500, 5000),  # Allow for more boosting rounds\n",
    "    'learning_rate': Real(0.01, 0.05, 'log-uniform'),  # Slightly higher learning rates\n",
    "    'max_depth': Integer(3, 10),  # Allow deeper trees\n",
    "    'min_child_weight': Integer(2, 7),  # Explore smaller values\n",
    "    'subsample': Real(0.5, 0.8),  # Light subsampling for diversity while preserving data\n",
    "    'colsample_bytree': Real(0.6, 0.9),  # Common column sampling range\n",
    "    'gamma': Real(0.1, 2, 'log-uniform'),  # Small gamma range for light regularization\n",
    "    'alpha': Real(1, 50, 'log-uniform'),  # Increase upper bound for L1 regularization\n",
    "    'lambda': Real(1, 20, 'log-uniform'),  # Default L2 regularization\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "best_estimator, best_params = tune_hyperparameters(model, search_space, X_train, y_train, X_additional_train, y_additional_train)"
   ],
   "id": "750dad36f1674ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:15:37 - Start tuning XGBRegressor\n",
      "01:15:37 - Parameters: {'n_estimators': Integer(low=1500, high=5000, prior='uniform', transform='identity'), 'learning_rate': Real(low=0.01, high=0.05, prior='log-uniform', transform='identity'), 'max_depth': Integer(low=3, high=10, prior='uniform', transform='identity'), 'min_child_weight': Integer(low=2, high=7, prior='uniform', transform='identity'), 'subsample': Real(low=0.5, high=0.8, prior='uniform', transform='identity'), 'colsample_bytree': Real(low=0.6, high=0.9, prior='uniform', transform='identity'), 'gamma': Real(low=0.1, high=2, prior='log-uniform', transform='identity'), 'alpha': Real(low=1, high=50, prior='log-uniform', transform='identity'), 'lambda': Real(low=1, high=20, prior='log-uniform', transform='identity')}\n",
      "01:15:37 - Fitting the model\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "best_estimator_file_name = f'{model.__class__.__name__}.best_estimator.pkl'\n",
    "joblib.dump(best_estimator, os.path.join('models', best_estimator_file_name))"
   ],
   "id": "b2976efd1463a4dc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
