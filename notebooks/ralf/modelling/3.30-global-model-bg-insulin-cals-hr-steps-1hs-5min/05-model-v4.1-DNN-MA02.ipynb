{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tune the meta model\n",
    " \n",
    "We want to check if we can exchange the metamodel from Ridge to DNN\n",
    "\n",
    "We use the best base model parameters from the previous notebooks"
   ],
   "id": "32bfa9234ec39c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model v4.1 - Baseline model with MA02 DNN as base estimator",
   "id": "c4f5fa4ffbc53369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:55:01.693632Z",
     "start_time": "2024-11-28T11:54:44.843742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fileinput import filename\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils.version_utils import callbacks\n",
    "\n",
    "from data import load_data_selected_features\n",
    "\n",
    "train_data, additional_train_data, test_data = load_data_selected_features()"
   ],
   "id": "ed9cab10a4c9269",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:55:01.714669Z",
     "start_time": "2024-11-28T11:55:01.703324Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.info()",
   "id": "af6bdd55ecd2a72b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150996 entries, p01_0 to p12_25298\n",
      "Columns: 507 entries, p_num to bg+1:00\n",
      "dtypes: float64(433), object(74)\n",
      "memory usage: 585.2+ MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:55:01.845161Z",
     "start_time": "2024-11-28T11:55:01.835023Z"
    }
   },
   "cell_type": "code",
   "source": "additional_train_data.info()",
   "id": "e6efef1597276890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 168588 entries, p01_test_12 to p24_test_94938\n",
      "Columns: 507 entries, p_num to bg+1:00\n",
      "dtypes: float64(433), object(74)\n",
      "memory usage: 657.4+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:55:01.924011Z",
     "start_time": "2024-11-28T11:55:01.912303Z"
    }
   },
   "cell_type": "code",
   "source": "test_data.info()",
   "id": "16d75f6d697d8bc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3644 entries, p01_8459 to p24_260\n",
      "Columns: 506 entries, p_num to activity-0:00\n",
      "dtypes: float64(432), object(74)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare the data",
   "id": "fc5e077e5738d8eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T11:55:42.972178Z",
     "start_time": "2024-11-28T11:55:01.937975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pipelines_selected_features import pipeline\n",
    "\n",
    "all_train_data = pd.concat([train_data, additional_train_data], axis=0)\n",
    "all_train_data_transformed = pipeline.fit_transform(all_train_data)\n",
    "\n",
    "train_data_transformed = all_train_data_transformed[:len(train_data)]\n",
    "additional_train_data_transformed = all_train_data_transformed[len(train_data):]\n",
    "\n",
    "X_train = train_data_transformed.drop(columns=['bg+1:00'])\n",
    "y_train = train_data_transformed['bg+1:00']\n",
    "\n",
    "X_additional_train = additional_train_data_transformed.drop(columns=['bg+1:00'])\n",
    "y_additional_train = additional_train_data_transformed['bg+1:00']"
   ],
   "id": "c7df704ede80b62",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict for validation data and check results",
   "id": "9b608adb90b0235e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-28T11:55:43.002078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from model_performance_calculations import get_history_line_chart\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "def create_dnn_model(input_dimension: int):\n",
    "    dnn = Sequential([\n",
    "        # Input layer\n",
    "        Input(shape=(input_dimension,)),\n",
    "\n",
    "        # First dense block\n",
    "        Dense(512, activation='relu'),  # Increased neurons\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),  # Slightly reduced dropout for better capacity\n",
    "\n",
    "        # Second dense block\n",
    "        Dense(256, activation='relu'),  # Increased neurons\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # Third dense block\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # Fourth dense block (new)\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        # Output layer\n",
    "        Dense(1, activation='linear')  # Regression output\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    dnn.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),  # Retained learning rate\n",
    "        loss='mse',  # Mean Squared Error for regression\n",
    "        metrics=[rmse]  # Custom RMSE metric\n",
    "    )\n",
    "\n",
    "    return dnn\n",
    "\n",
    "\n",
    "def model_with_pretrained_weights():\n",
    "    dnn = create_dnn_model(X_train.shape[1])\n",
    "    dnn.load_weights('v4.1-MA02.weights.h5')  # Load the pre-trained weights\n",
    "\n",
    "    # Freeze all layers except the last one (optional)\n",
    "    for layer in dnn.layers:\n",
    "        layer.trainable = False\n",
    "    # Unfreeze the output layer if you want to fine-tune it\n",
    "    # dnn.layers[-1].trainable = True\n",
    "\n",
    "    dnn.compile(optimizer='adam', loss='mse', metrics=[rmse])\n",
    "    return dnn\n",
    "\n",
    "\n",
    "pretrained_dnn = create_dnn_model(X_train.shape[1])\n",
    "\n",
    "print('Pretrain with train data')\n",
    "pretrained_dnn.fit(\n",
    "    pd.concat([X_train, X_additional_train], axis=0),\n",
    "    pd.concat([y_train, y_additional_train], axis=0),\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(monitor='val_rmse', patience=10, restore_best_weights=True, mode='min')],\n",
    "    epochs=5,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "history = pretrained_dnn.history.history\n",
    "\n",
    "print('Pretrain save weights')\n",
    "pretrained_dnn.save_weights('v4.1-MA02.weights.h5')\n",
    "get_history_line_chart([history]).show()"
   ],
   "id": "c20aa25cccb09977",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain with train data\n",
      "Epoch 1/5\n",
      "7990/7990 - 25s - 3ms/step - loss: 7.3841 - rmse: 2.5348 - val_loss: 5.0144 - val_rmse: 1.9866\n",
      "Epoch 2/5\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import StackingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoLarsIC, Ridge\n",
    "\n",
    "hgb_estimator = HistGradientBoostingRegressor(max_iter=200, max_depth=5, learning_rate=0.1)\n",
    "lasso_lars_ic_base_model = LassoLarsIC(criterion='bic', max_iter=10000)\n",
    "knn_base_model = KNeighborsRegressor(n_neighbors=5)\n",
    "xgb_base_model = XGBRegressor(objective='reg:squarederror', random_state=42, n_estimators=500, max_depth=5, learning_rate=0.1)\n",
    "\n",
    "keras_regressor = KerasRegressor(\n",
    "    model=model_with_pretrained_weights,\n",
    "    epochs=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    ('hgb', hgb_estimator),\n",
    "    ('lasso_lars_ic', lasso_lars_ic_base_model),\n",
    "    ('knn', knn_base_model),\n",
    "    ('xgb', xgb_base_model),\n",
    "    ('dnn', keras_regressor)\n",
    "]\n",
    "\n",
    "model = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=0.1), n_jobs=1, verbose=2)"
   ],
   "id": "7e0583e9ae957c2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from model_performance_calculations import calculate_stacking_regressor_performance, get_rmse_boxplot_chart, get_rmse_line_chart, save_performances, save_model\n",
    "\n",
    "date_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "model_name = f'{date_time}-model-v4.1-DNN'\n",
    "\n",
    "save_model(model, os.path.join('models', f'{model_name}.pkl'))\n",
    "\n",
    "performances = calculate_stacking_regressor_performance(model, X_train, y_train, X_additional_train, y_additional_train, n_splits=5)\n",
    "save_performances(performances, os.path.join('models', f'{model_name}-performances.json'))\n",
    "\n",
    "get_rmse_boxplot_chart(performances).show()\n",
    "get_rmse_line_chart(performances).show()"
   ],
   "id": "c0be6db84ab0c1b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from pipelines_selected_features import pipeline\n",
    "\n",
    "all_train_data_transformed = pipeline.fit_transform(pd.concat([train_data, additional_train_data], axis=0))\n",
    "\n",
    "X_train = all_train_data_transformed.drop(columns=['bg+1:00'])\n",
    "y_train = all_train_data_transformed['bg+1:00']\n",
    "X_test = pipeline.transform(test_data)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ],
   "id": "43cf99724f468af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(X_test)\n",
    "test_data['bg+1:00'] = y_pred\n",
    "\n",
    "if np.sum(y_pred < 0) > 0:\n",
    "    print(f'Number of negative values: {np.sum(y_pred < 0)}')\n",
    "    bg_min_train = np.min(y_train)\n",
    "    print(f'Min value: {np.min(y_pred)}')\n",
    "    print(f'Filling negative values with {bg_min_train}')\n",
    "    y_pred = np.where(y_pred < 0, bg_min_train, y_pred)\n",
    "\n",
    "test_data['bg+1:00'] = y_pred\n",
    "test_data.head()"
   ],
   "id": "4bc5c6a7c86b6f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "submission = pd.DataFrame(test_data['bg+1:00'])\n",
    "submission.to_csv(f'submission-{model_name}.csv')\n",
    "submission"
   ],
   "id": "5167875e1afa3ec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "submission.describe()",
   "id": "76f34bf74bc9f805",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
