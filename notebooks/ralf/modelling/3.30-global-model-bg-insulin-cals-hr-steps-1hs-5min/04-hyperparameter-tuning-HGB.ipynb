{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "First result with Parameters: {'learning_rate': Real(low=0.005, high=0.1, prior='log-uniform', transform='identity'), 'max_iter': Integer(low=100, high=1500, prior='uniform', transform='identity'), 'max_depth': Integer(low=3, high=15, prior='uniform', transform='identity'), 'min_samples_leaf': Integer(low=10, high=50, prior='uniform', transform='identity'), 'l2_regularization': Real(low=0.0001, high=0.1, prior='log-uniform', transform='identity'), 'n_iter_no_change': Integer(low=10, high=30, prior='uniform', transform='identity')}\n",
    "\n",
    "Result: OrderedDict({'l2_regularization': 0.0001, 'learning_rate': 0.1, 'max_depth': 11, 'max_iter': 1500, 'min_samples_leaf': 10, 'n_iter_no_change': 22})\n",
    "\n",
    "RMSE: 1.5422279327391433\n",
    "R2 Score: 0.7584204840617608\n",
    "\n",
    "Next iteration trying to prevent overfitting:\n",
    "\n",
    "``` json\n",
    "search_space = {\n",
    "    'learning_rate': Real(0.005, 0.1, prior='log-uniform'),\n",
    "    'max_iter': Integer(100, 1500),\n",
    "    'max_depth': Integer(6, 12),\n",
    "    'min_samples_leaf': Integer(10, 20),\n",
    "    'max_leaf_nodes': Integer(20, 50),\n",
    "    'l2_regularization': Real(1e-5, 1e-3, prior='log-uniform'),\n",
    "    'n_iter_no_change': Integer(10, 30),\n",
    "}\n",
    "```\n"
   ],
   "id": "c4f5fa4ffbc53369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T10:54:24.260438Z",
     "start_time": "2024-11-27T10:53:23.090008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from data import load_data_selected_features\n",
    "from pipelines_selected_features import pipeline\n",
    "\n",
    "train_data, additional_train_data, test_data = load_data_selected_features()\n",
    "all_train_data = pipeline.fit_transform(pd.concat([train_data, additional_train_data]))\n",
    "\n",
    "# cut the data into train, additional train and test\n",
    "train_data = all_train_data.loc[train_data.index]\n",
    "additional_train_data = all_train_data.loc[additional_train_data.index]\n",
    "\n",
    "X_train = train_data.drop(columns=['bg+1:00'])\n",
    "y_train = train_data['bg+1:00']\n",
    "\n",
    "X_additional_train = additional_train_data.drop(columns=['bg+1:00'])\n",
    "y_additional_train = additional_train_data['bg+1:00']"
   ],
   "id": "6a34b21d4bb55fe0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tune HistGradientBoostingRegressor",
   "id": "49e54cddfe4a3b63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Stage 1: Tune learning_rate and l2_regularization\n",
    "search_space_stage1 = {\n",
    "    'learning_rate': Real(0.005, 0.1, prior='log-uniform'),\n",
    "    'l2_regularization': Real(1e-5, 1e-1, prior='log-uniform'),\n",
    "}\n",
    "\n",
    "#### Stage 2: Tune max_iter and max_depth based on Stage 1 results\n",
    "search_space_stage2 = {\n",
    "    'max_iter': Integer(100, 3000),\n",
    "    'max_depth': Integer(3, 20),\n",
    "    'min_samples_leaf': Integer(5, 100),\n",
    "}\n"
   ],
   "id": "1c353d88c322ae72"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-27T10:54:24.269956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skopt.space import Real, Integer\n",
    "from model_hyperparameter_tuning import tune_hyperparameters\n",
    "\n",
    "search_space = {\n",
    "    'learning_rate': Real(0.005, 0.3, prior='log-uniform'),\n",
    "    'max_iter': Integer(100, 1500),\n",
    "    'max_depth': Integer(6, 8),\n",
    "    'min_samples_leaf': Integer(15, 30),\n",
    "    'max_leaf_nodes': Integer(10, 30),\n",
    "    'l2_regularization': Real(1e-4, 1e-2, prior='log-uniform'),\n",
    "    'n_iter_no_change': Integer(10, 15),\n",
    "    'validation_fraction': Real(0.1, 0.3),\n",
    "}\n",
    "\n",
    "model = HistGradientBoostingRegressor(scoring='neg_mean_squared_error', random_state=42, max_bins=255)\n",
    "best_estimator, best_params = tune_hyperparameters(model, search_space, pd.DataFrame(), pd.Series(), X_additional_train, y_additional_train, num_iter=50, n_splits=2)"
   ],
   "id": "750dad36f1674ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:54:25 - Start tuning HistGradientBoostingRegressor\n",
      "11:54:25 - Parameters: {'learning_rate': Real(low=0.005, high=0.3, prior='log-uniform', transform='identity'), 'max_iter': Integer(low=100, high=1500, prior='uniform', transform='identity'), 'max_depth': Integer(low=6, high=8, prior='uniform', transform='identity'), 'min_samples_leaf': Integer(low=15, high=30, prior='uniform', transform='identity'), 'max_leaf_nodes': Integer(low=10, high=30, prior='uniform', transform='identity'), 'l2_regularization': Real(low=0.0001, high=0.01, prior='log-uniform', transform='identity'), 'n_iter_no_change': Integer(low=10, high=15, prior='uniform', transform='identity'), 'validation_fraction': Real(low=0.1, high=0.3, prior='uniform', transform='identity')}\n",
      "11:54:25 - Fitting the model\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/notebooks/ralf/modelling/3.30-global-model-bg-insulin-cals-hr-steps-1hs-5min/model_hyperparameter_tuning.py:55: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  y_all_train = pd.concat([y_train, y_additional_train])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "best_estimator_file_name = f'{model.__class__.__name__}.best_estimator.pkl'\n",
    "joblib.dump(best_estimator, os.path.join('models', best_estimator_file_name))"
   ],
   "id": "b2976efd1463a4dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5db6010f144d2874"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
