{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict for each patient",
   "id": "c4f5fa4ffbc53369"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:35:48.012869Z",
     "start_time": "2024-11-27T23:35:33.481805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from data import load_data\n",
    "\n",
    "train_data, additional_train_data, test_data, unique_patients = load_data()"
   ],
   "id": "ed9cab10a4c9269",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T23:36:28.553772Z",
     "start_time": "2024-11-27T23:35:48.022185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pipelines import pipeline\n",
    "\n",
    "data = {}\n",
    "for p_num in unique_patients:\n",
    "    train_data_patient = pd.concat([train_data[train_data['p_num'] == p_num], additional_train_data[additional_train_data['p_num'] == p_num]])\n",
    "    test_data_patient = test_data[test_data['p_num'] == p_num]\n",
    "\n",
    "    train_data_patient_transformed = pipeline.fit_transform(train_data_patient)\n",
    "    test_data_patient_transformed = pipeline.transform(test_data_patient)\n",
    "\n",
    "    data[p_num] = {\n",
    "        'X_train': train_data_patient_transformed.drop(columns=['bg+1:00']),\n",
    "        'y_train': train_data_patient_transformed['bg+1:00'],\n",
    "        'X_test': test_data_patient_transformed,\n",
    "        'y_pred': test_data_patient_transformed[[]]\n",
    "    }"
   ],
   "id": "1a0b06ffae1ad7e5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.171614Z",
     "start_time": "2024-11-27T23:36:28.714766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import os\n",
    "import datetime\n",
    "from regressors import get_hgb_regressor, get_xgb_regressor, get_knn_regressor, get_keras_regressor, get_lasso_lars_ic_regressor\n",
    "\n",
    "\n",
    "def get_date_time_now():\n",
    "    return datetime.datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "\n",
    "models = {}\n",
    "results = test_data[[]].copy()\n",
    "results.loc[:, 'bg+1:00'] = -1.0\n",
    "results['bg+1:00'] = results['bg+1:00'].astype(float)\n",
    "for p_num in data.keys():\n",
    "    print(f'{get_date_time_now()} - {p_num} - Predicting for patient {p_num}')\n",
    "    print(f'{get_date_time_now()} - {p_num} - Transforming the data -')\n",
    "\n",
    "    X_train = data[p_num]['X_train']\n",
    "    y_train = data[p_num]['y_train']\n",
    "    X_test = data[p_num]['X_test']\n",
    "\n",
    "    print(f'{get_date_time_now()} - {p_num} - Fitting the model -')\n",
    "\n",
    "    _, X_val, _, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    estimators = [\n",
    "        ('hgb', get_hgb_regressor()),\n",
    "        ('xgb', get_xgb_regressor()),\n",
    "        ('llic', get_lasso_lars_ic_regressor()),\n",
    "        ('knn', get_knn_regressor()),\n",
    "        ('dnn', get_keras_regressor(\n",
    "            p_num=p_num,\n",
    "            X_train=X_train,\n",
    "            X_val=X_val,\n",
    "            y_train=y_train,\n",
    "            y_val=y_val))\n",
    "    ]\n",
    "\n",
    "    model = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=0.1), n_jobs=1, verbose=2)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "\n",
    "    print(f'{get_date_time_now()} - {p_num} - Predicting -')\n",
    "    y_pred = model.predict(X=X_test)\n",
    "\n",
    "    # count and replace negative values\n",
    "    if np.sum(y_pred < 0) > 0:\n",
    "        print(f'{get_date_time_now()} - {p_num} - Number of negative values: {np.sum(y_pred < 0)}')\n",
    "        bg_min_train = np.min(y_train)\n",
    "        print(f'{get_date_time_now()} - {p_num} - Min value: {np.min(y_pred)}')\n",
    "        y_pred = np.where(y_pred < 0, bg_min_train, y_pred)\n",
    "\n",
    "    data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n",
    "    results.loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n",
    "    print(f'{get_date_time_now()} - {p_num} - Done -')\n",
    "\n",
    "results.head()"
   ],
   "id": "96dfd2e02e41a9dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:36:31 - p01 - Predicting for patient p01\n",
      "00:36:31 - p01 - Transforming the data -\n",
      "00:36:31 - p01 - Fitting the model -\n",
      "Epoch 1/100\n",
      "601/601 - 1s - 2ms/step - loss: 42.5974 - rmse: 6.1399 - val_loss: 7.9503 - val_rmse: 2.7899\n",
      "Epoch 2/100\n",
      "601/601 - 0s - 697us/step - loss: 11.5053 - rmse: 3.3540 - val_loss: 7.3328 - val_rmse: 2.6820\n",
      "Epoch 3/100\n",
      "601/601 - 0s - 696us/step - loss: 10.1646 - rmse: 3.1554 - val_loss: 6.9792 - val_rmse: 2.6109\n",
      "Epoch 4/100\n",
      "601/601 - 0s - 696us/step - loss: 9.2451 - rmse: 3.0091 - val_loss: 6.8161 - val_rmse: 2.5828\n",
      "Epoch 5/100\n",
      "601/601 - 0s - 694us/step - loss: 9.0382 - rmse: 2.9771 - val_loss: 6.7983 - val_rmse: 2.5805\n",
      "Epoch 6/100\n",
      "601/601 - 0s - 698us/step - loss: 8.6381 - rmse: 2.9073 - val_loss: 6.6432 - val_rmse: 2.5324\n",
      "Epoch 7/100\n",
      "601/601 - 0s - 680us/step - loss: 8.4301 - rmse: 2.8741 - val_loss: 6.7989 - val_rmse: 2.5672\n",
      "Epoch 8/100\n",
      "601/601 - 0s - 684us/step - loss: 8.2862 - rmse: 2.8456 - val_loss: 6.5107 - val_rmse: 2.5194\n",
      "Epoch 9/100\n",
      "601/601 - 0s - 706us/step - loss: 8.0954 - rmse: 2.8162 - val_loss: 6.3742 - val_rmse: 2.4915\n",
      "Epoch 10/100\n",
      "601/601 - 0s - 683us/step - loss: 8.0290 - rmse: 2.8023 - val_loss: 6.5603 - val_rmse: 2.5327\n",
      "Epoch 11/100\n",
      "601/601 - 0s - 683us/step - loss: 8.0210 - rmse: 2.8029 - val_loss: 6.2684 - val_rmse: 2.4676\n",
      "Epoch 12/100\n",
      "601/601 - 0s - 692us/step - loss: 7.8978 - rmse: 2.7783 - val_loss: 6.2876 - val_rmse: 2.4640\n",
      "Epoch 13/100\n",
      "601/601 - 0s - 685us/step - loss: 7.9017 - rmse: 2.7809 - val_loss: 6.5061 - val_rmse: 2.5101\n",
      "Epoch 14/100\n",
      "601/601 - 0s - 702us/step - loss: 7.7711 - rmse: 2.7517 - val_loss: 6.2071 - val_rmse: 2.4593\n",
      "Epoch 15/100\n",
      "601/601 - 0s - 692us/step - loss: 7.7163 - rmse: 2.7445 - val_loss: 6.2780 - val_rmse: 2.4762\n",
      "Epoch 16/100\n",
      "601/601 - 0s - 685us/step - loss: 7.5652 - rmse: 2.7198 - val_loss: 6.1531 - val_rmse: 2.4444\n",
      "Epoch 17/100\n",
      "601/601 - 0s - 680us/step - loss: 7.6012 - rmse: 2.7269 - val_loss: 5.9741 - val_rmse: 2.4047\n",
      "Epoch 18/100\n",
      "601/601 - 0s - 697us/step - loss: 7.5323 - rmse: 2.7122 - val_loss: 6.2413 - val_rmse: 2.4634\n",
      "Epoch 19/100\n",
      "601/601 - 0s - 709us/step - loss: 7.4654 - rmse: 2.7007 - val_loss: 6.0448 - val_rmse: 2.4006\n",
      "Epoch 20/100\n",
      "601/601 - 0s - 677us/step - loss: 7.3998 - rmse: 2.6866 - val_loss: 6.1357 - val_rmse: 2.4294\n",
      "Epoch 21/100\n",
      "601/601 - 0s - 710us/step - loss: 7.3392 - rmse: 2.6790 - val_loss: 5.8727 - val_rmse: 2.3727\n",
      "Epoch 22/100\n",
      "601/601 - 0s - 687us/step - loss: 7.2571 - rmse: 2.6653 - val_loss: 5.9919 - val_rmse: 2.4169\n",
      "Epoch 23/100\n",
      "601/601 - 0s - 695us/step - loss: 7.3198 - rmse: 2.6783 - val_loss: 5.8274 - val_rmse: 2.3664\n",
      "Epoch 24/100\n",
      "601/601 - 0s - 690us/step - loss: 7.1246 - rmse: 2.6410 - val_loss: 5.8760 - val_rmse: 2.3821\n",
      "Epoch 25/100\n",
      "601/601 - 0s - 691us/step - loss: 7.1218 - rmse: 2.6377 - val_loss: 5.8766 - val_rmse: 2.3819\n",
      "Epoch 26/100\n",
      "601/601 - 0s - 681us/step - loss: 7.0416 - rmse: 2.6231 - val_loss: 5.9379 - val_rmse: 2.4098\n",
      "Epoch 27/100\n",
      "601/601 - 0s - 728us/step - loss: 7.1355 - rmse: 2.6423 - val_loss: 5.7477 - val_rmse: 2.3338\n",
      "Epoch 28/100\n",
      "601/601 - 0s - 705us/step - loss: 7.1112 - rmse: 2.6363 - val_loss: 5.7558 - val_rmse: 2.3627\n",
      "Epoch 29/100\n",
      "601/601 - 0s - 694us/step - loss: 6.9889 - rmse: 2.6135 - val_loss: 5.6745 - val_rmse: 2.3427\n",
      "Epoch 30/100\n",
      "601/601 - 0s - 693us/step - loss: 6.8914 - rmse: 2.5927 - val_loss: 5.7690 - val_rmse: 2.3563\n",
      "Epoch 31/100\n",
      "601/601 - 0s - 689us/step - loss: 6.8483 - rmse: 2.5829 - val_loss: 5.7971 - val_rmse: 2.3637\n",
      "Epoch 32/100\n",
      "601/601 - 0s - 679us/step - loss: 6.8791 - rmse: 2.5927 - val_loss: 5.9668 - val_rmse: 2.3791\n",
      "Epoch 33/100\n",
      "601/601 - 0s - 677us/step - loss: 6.9345 - rmse: 2.6025 - val_loss: 5.7736 - val_rmse: 2.3572\n",
      "Epoch 34/100\n",
      "601/601 - 0s - 684us/step - loss: 6.8662 - rmse: 2.5869 - val_loss: 5.7039 - val_rmse: 2.3491\n",
      "Epoch 35/100\n",
      "601/601 - 0s - 697us/step - loss: 6.8260 - rmse: 2.5833 - val_loss: 5.6306 - val_rmse: 2.3295\n",
      "Epoch 36/100\n",
      "601/601 - 0s - 688us/step - loss: 6.8262 - rmse: 2.5838 - val_loss: 5.7038 - val_rmse: 2.3537\n",
      "Epoch 37/100\n",
      "601/601 - 1s - 900us/step - loss: 6.7653 - rmse: 2.5708 - val_loss: 5.6635 - val_rmse: 2.3349\n",
      "Epoch 38/100\n",
      "601/601 - 0s - 694us/step - loss: 6.5994 - rmse: 2.5362 - val_loss: 5.5820 - val_rmse: 2.3301\n",
      "Epoch 39/100\n",
      "601/601 - 0s - 697us/step - loss: 6.7893 - rmse: 2.5758 - val_loss: 5.5971 - val_rmse: 2.3203\n",
      "Epoch 40/100\n",
      "601/601 - 0s - 707us/step - loss: 6.6573 - rmse: 2.5498 - val_loss: 5.4737 - val_rmse: 2.3021\n",
      "Epoch 41/100\n",
      "601/601 - 0s - 793us/step - loss: 6.6286 - rmse: 2.5444 - val_loss: 5.5987 - val_rmse: 2.2956\n",
      "Epoch 42/100\n",
      "601/601 - 0s - 697us/step - loss: 6.7001 - rmse: 2.5579 - val_loss: 5.5815 - val_rmse: 2.3169\n",
      "Epoch 43/100\n",
      "601/601 - 0s - 691us/step - loss: 6.5802 - rmse: 2.5370 - val_loss: 5.4699 - val_rmse: 2.2893\n",
      "Epoch 44/100\n",
      "601/601 - 0s - 681us/step - loss: 6.6133 - rmse: 2.5399 - val_loss: 5.6233 - val_rmse: 2.3261\n",
      "Epoch 45/100\n",
      "601/601 - 0s - 693us/step - loss: 6.4814 - rmse: 2.5180 - val_loss: 5.6311 - val_rmse: 2.3222\n",
      "Epoch 46/100\n",
      "601/601 - 0s - 685us/step - loss: 6.4742 - rmse: 2.5159 - val_loss: 5.5026 - val_rmse: 2.2971\n",
      "Epoch 47/100\n",
      "601/601 - 0s - 707us/step - loss: 6.4523 - rmse: 2.5099 - val_loss: 5.3859 - val_rmse: 2.2733\n",
      "Epoch 48/100\n",
      "601/601 - 0s - 693us/step - loss: 6.4239 - rmse: 2.5048 - val_loss: 5.4577 - val_rmse: 2.3082\n",
      "Epoch 49/100\n",
      "601/601 - 0s - 701us/step - loss: 6.4783 - rmse: 2.5179 - val_loss: 5.3679 - val_rmse: 2.2796\n",
      "Epoch 50/100\n",
      "601/601 - 0s - 693us/step - loss: 6.3741 - rmse: 2.4985 - val_loss: 5.6175 - val_rmse: 2.2873\n",
      "Epoch 51/100\n",
      "601/601 - 0s - 678us/step - loss: 6.4142 - rmse: 2.5031 - val_loss: 5.4329 - val_rmse: 2.2952\n",
      "Epoch 52/100\n",
      "601/601 - 0s - 688us/step - loss: 6.3746 - rmse: 2.4952 - val_loss: 5.7297 - val_rmse: 2.3680\n",
      "Epoch 53/100\n",
      "601/601 - 0s - 694us/step - loss: 6.4344 - rmse: 2.5080 - val_loss: 5.3732 - val_rmse: 2.2897\n",
      "Epoch 54/100\n",
      "601/601 - 0s - 700us/step - loss: 6.3545 - rmse: 2.4895 - val_loss: 5.8191 - val_rmse: 2.3886\n",
      "Epoch 55/100\n",
      "601/601 - 0s - 700us/step - loss: 6.2543 - rmse: 2.4733 - val_loss: 5.6325 - val_rmse: 2.3391\n",
      "Epoch 56/100\n",
      "601/601 - 0s - 695us/step - loss: 6.2662 - rmse: 2.4741 - val_loss: 5.2245 - val_rmse: 2.2596\n",
      "Epoch 57/100\n",
      "601/601 - 0s - 696us/step - loss: 6.2559 - rmse: 2.4681 - val_loss: 5.5668 - val_rmse: 2.3336\n",
      "Epoch 58/100\n",
      "601/601 - 0s - 694us/step - loss: 6.2025 - rmse: 2.4630 - val_loss: 5.2475 - val_rmse: 2.2646\n",
      "Epoch 59/100\n",
      "601/601 - 0s - 695us/step - loss: 6.2683 - rmse: 2.4756 - val_loss: 5.0234 - val_rmse: 2.2138\n",
      "Epoch 60/100\n",
      "601/601 - 0s - 696us/step - loss: 6.1836 - rmse: 2.4566 - val_loss: 5.1420 - val_rmse: 2.2395\n",
      "Epoch 61/100\n",
      "601/601 - 0s - 696us/step - loss: 6.2289 - rmse: 2.4698 - val_loss: 5.2058 - val_rmse: 2.2591\n",
      "Epoch 62/100\n",
      "601/601 - 0s - 679us/step - loss: 6.1309 - rmse: 2.4481 - val_loss: 5.3749 - val_rmse: 2.2956\n",
      "Epoch 63/100\n",
      "601/601 - 0s - 705us/step - loss: 6.1420 - rmse: 2.4497 - val_loss: 5.0911 - val_rmse: 2.2214\n",
      "Epoch 64/100\n",
      "601/601 - 0s - 685us/step - loss: 6.1649 - rmse: 2.4521 - val_loss: 5.0592 - val_rmse: 2.2206\n",
      "Epoch 65/100\n",
      "601/601 - 0s - 695us/step - loss: 6.1178 - rmse: 2.4440 - val_loss: 5.3170 - val_rmse: 2.2837\n",
      "Epoch 66/100\n",
      "601/601 - 0s - 692us/step - loss: 6.1375 - rmse: 2.4456 - val_loss: 5.3861 - val_rmse: 2.2959\n",
      "Epoch 67/100\n",
      "601/601 - 0s - 676us/step - loss: 6.0448 - rmse: 2.4301 - val_loss: 5.0106 - val_rmse: 2.2065\n",
      "Epoch 68/100\n",
      "601/601 - 0s - 689us/step - loss: 6.0581 - rmse: 2.4342 - val_loss: 5.0409 - val_rmse: 2.2169\n",
      "Epoch 69/100\n",
      "601/601 - 0s - 693us/step - loss: 6.0970 - rmse: 2.4405 - val_loss: 5.1146 - val_rmse: 2.2373\n",
      "Epoch 70/100\n",
      "601/601 - 0s - 698us/step - loss: 6.0424 - rmse: 2.4326 - val_loss: 5.2456 - val_rmse: 2.2602\n",
      "Epoch 71/100\n",
      "601/601 - 0s - 679us/step - loss: 6.0750 - rmse: 2.4362 - val_loss: 5.3126 - val_rmse: 2.2866\n",
      "Epoch 72/100\n",
      "601/601 - 0s - 698us/step - loss: 6.0504 - rmse: 2.4313 - val_loss: 4.9044 - val_rmse: 2.1911\n",
      "Epoch 73/100\n",
      "601/601 - 0s - 689us/step - loss: 6.0641 - rmse: 2.4334 - val_loss: 5.2353 - val_rmse: 2.2665\n",
      "Epoch 74/100\n",
      "601/601 - 0s - 693us/step - loss: 5.9225 - rmse: 2.4076 - val_loss: 4.9778 - val_rmse: 2.1776\n",
      "Epoch 75/100\n",
      "601/601 - 0s - 692us/step - loss: 6.0462 - rmse: 2.4309 - val_loss: 5.0258 - val_rmse: 2.2151\n",
      "Epoch 76/100\n",
      "601/601 - 0s - 701us/step - loss: 5.9668 - rmse: 2.4152 - val_loss: 5.1413 - val_rmse: 2.2379\n",
      "Epoch 77/100\n",
      "601/601 - 0s - 698us/step - loss: 5.9522 - rmse: 2.4134 - val_loss: 5.3243 - val_rmse: 2.2784\n",
      "Epoch 78/100\n",
      "601/601 - 0s - 699us/step - loss: 5.9143 - rmse: 2.4027 - val_loss: 5.0722 - val_rmse: 2.2269\n",
      "Epoch 79/100\n",
      "601/601 - 0s - 695us/step - loss: 5.9437 - rmse: 2.4095 - val_loss: 5.1770 - val_rmse: 2.2513\n",
      "Epoch 80/100\n",
      "601/601 - 0s - 698us/step - loss: 5.9251 - rmse: 2.4056 - val_loss: 5.0427 - val_rmse: 2.2151\n",
      "Epoch 81/100\n",
      "601/601 - 0s - 693us/step - loss: 5.9151 - rmse: 2.4057 - val_loss: 4.8703 - val_rmse: 2.1779\n",
      "Epoch 82/100\n",
      "601/601 - 0s - 696us/step - loss: 5.9505 - rmse: 2.4112 - val_loss: 5.1663 - val_rmse: 2.2482\n",
      "Epoch 83/100\n",
      "601/601 - 0s - 684us/step - loss: 5.7945 - rmse: 2.3824 - val_loss: 5.3123 - val_rmse: 2.2823\n",
      "Epoch 84/100\n",
      "601/601 - 0s - 683us/step - loss: 5.8364 - rmse: 2.3851 - val_loss: 5.0020 - val_rmse: 2.1978\n",
      "Epoch 85/100\n",
      "601/601 - 0s - 689us/step - loss: 5.8441 - rmse: 2.3889 - val_loss: 5.3743 - val_rmse: 2.2988\n",
      "Epoch 86/100\n",
      "601/601 - 0s - 695us/step - loss: 5.8506 - rmse: 2.3903 - val_loss: 5.0142 - val_rmse: 2.2106\n",
      "Epoch 87/100\n",
      "601/601 - 0s - 699us/step - loss: 5.8912 - rmse: 2.3990 - val_loss: 5.1438 - val_rmse: 2.2447\n",
      "Epoch 88/100\n",
      "601/601 - 0s - 702us/step - loss: 5.8116 - rmse: 2.3836 - val_loss: 4.8568 - val_rmse: 2.1631\n",
      "Epoch 89/100\n",
      "601/601 - 0s - 693us/step - loss: 5.8313 - rmse: 2.3855 - val_loss: 5.5088 - val_rmse: 2.3224\n",
      "Epoch 90/100\n",
      "601/601 - 0s - 701us/step - loss: 5.8503 - rmse: 2.3897 - val_loss: 5.1627 - val_rmse: 2.2411\n",
      "Epoch 91/100\n",
      "601/601 - 0s - 697us/step - loss: 5.8431 - rmse: 2.3904 - val_loss: 5.1067 - val_rmse: 2.2295\n",
      "Epoch 92/100\n",
      "601/601 - 0s - 699us/step - loss: 5.8004 - rmse: 2.3808 - val_loss: 5.1813 - val_rmse: 2.2477\n",
      "Epoch 93/100\n",
      "601/601 - 0s - 683us/step - loss: 5.7872 - rmse: 2.3788 - val_loss: 5.4796 - val_rmse: 2.3154\n",
      "Epoch 94/100\n",
      "601/601 - 0s - 694us/step - loss: 5.7791 - rmse: 2.3765 - val_loss: 4.8939 - val_rmse: 2.1782\n",
      "Epoch 95/100\n",
      "601/601 - 0s - 687us/step - loss: 5.8001 - rmse: 2.3799 - val_loss: 5.7430 - val_rmse: 2.3401\n",
      "Epoch 96/100\n",
      "601/601 - 0s - 697us/step - loss: 5.7585 - rmse: 2.3697 - val_loss: 5.4018 - val_rmse: 2.3003\n",
      "Epoch 97/100\n",
      "601/601 - 0s - 697us/step - loss: 5.7811 - rmse: 2.3780 - val_loss: 5.1336 - val_rmse: 2.2401\n",
      "Epoch 98/100\n",
      "601/601 - 0s - 732us/step - loss: 5.6974 - rmse: 2.3575 - val_loss: 4.8823 - val_rmse: 2.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/601 - 0s - 640us/step - loss: 5.9932 - rmse: 4.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 - 0s - 758us/step - loss: 5.7490 - rmse: 4.7963\n",
      "121/121 - 0s - 912us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 - 0s - 704us/step - loss: 5.9542 - rmse: 4.7798\n",
      "121/121 - 0s - 909us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 - 0s - 700us/step - loss: 6.0243 - rmse: 4.9345\n",
      "121/121 - 0s - 914us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 - 0s - 962us/step - loss: 6.0867 - rmse: 4.8170\n",
      "121/121 - 0s - 904us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481/481 - 0s - 708us/step - loss: 5.5682 - rmse: 4.8553\n",
      "121/121 - 0s - 894us/step\n",
      "00:38:05 - p01 - Predicting -\n",
      "8/8 - 0s - 11ms/step\n",
      "00:38:05 - p01 - Done -\n",
      "00:38:05 - p02 - Predicting for patient p02\n",
      "00:38:05 - p02 - Transforming the data -\n",
      "00:38:05 - p02 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143/1143 - 2s - 1ms/step - loss: 28.1836 - rmse: 4.7354 - val_loss: 5.3877 - val_rmse: 2.2925\n",
      "Epoch 2/100\n",
      "1143/1143 - 1s - 650us/step - loss: 7.8416 - rmse: 2.7670 - val_loss: 5.0322 - val_rmse: 2.2145\n",
      "Epoch 3/100\n",
      "1143/1143 - 1s - 644us/step - loss: 7.0668 - rmse: 2.6282 - val_loss: 4.9439 - val_rmse: 2.1960\n",
      "Epoch 4/100\n",
      "1143/1143 - 1s - 645us/step - loss: 6.6240 - rmse: 2.5438 - val_loss: 4.7383 - val_rmse: 2.1506\n",
      "Epoch 5/100\n",
      "1143/1143 - 1s - 646us/step - loss: 6.4291 - rmse: 2.5058 - val_loss: 4.6675 - val_rmse: 2.1341\n",
      "Epoch 6/100\n",
      "1143/1143 - 1s - 641us/step - loss: 6.3118 - rmse: 2.4807 - val_loss: 4.6700 - val_rmse: 2.1346\n",
      "Epoch 7/100\n",
      "1143/1143 - 1s - 645us/step - loss: 6.1541 - rmse: 2.4497 - val_loss: 4.5839 - val_rmse: 2.1150\n",
      "Epoch 8/100\n",
      "1143/1143 - 1s - 643us/step - loss: 6.0479 - rmse: 2.4288 - val_loss: 4.5449 - val_rmse: 2.1056\n",
      "Epoch 9/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.9155 - rmse: 2.4017 - val_loss: 4.5145 - val_rmse: 2.0982\n",
      "Epoch 10/100\n",
      "1143/1143 - 1s - 662us/step - loss: 5.8854 - rmse: 2.3959 - val_loss: 4.4753 - val_rmse: 2.0896\n",
      "Epoch 11/100\n",
      "1143/1143 - 1s - 646us/step - loss: 5.8060 - rmse: 2.3795 - val_loss: 4.4332 - val_rmse: 2.0793\n",
      "Epoch 12/100\n",
      "1143/1143 - 1s - 643us/step - loss: 5.7321 - rmse: 2.3649 - val_loss: 4.3649 - val_rmse: 2.0629\n",
      "Epoch 13/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.7087 - rmse: 2.3578 - val_loss: 4.4051 - val_rmse: 2.0714\n",
      "Epoch 14/100\n",
      "1143/1143 - 1s - 643us/step - loss: 5.6002 - rmse: 2.3376 - val_loss: 4.3020 - val_rmse: 2.0486\n",
      "Epoch 15/100\n",
      "1143/1143 - 1s - 643us/step - loss: 5.5808 - rmse: 2.3330 - val_loss: 4.2806 - val_rmse: 2.0442\n",
      "Epoch 16/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.5196 - rmse: 2.3187 - val_loss: 4.2261 - val_rmse: 2.0299\n",
      "Epoch 17/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.4420 - rmse: 2.3034 - val_loss: 4.2373 - val_rmse: 2.0324\n",
      "Epoch 18/100\n",
      "1143/1143 - 1s - 642us/step - loss: 5.3779 - rmse: 2.2899 - val_loss: 4.1842 - val_rmse: 2.0201\n",
      "Epoch 19/100\n",
      "1143/1143 - 1s - 640us/step - loss: 5.3722 - rmse: 2.2885 - val_loss: 4.1846 - val_rmse: 2.0197\n",
      "Epoch 20/100\n",
      "1143/1143 - 1s - 643us/step - loss: 5.2893 - rmse: 2.2691 - val_loss: 4.2717 - val_rmse: 2.0406\n",
      "Epoch 21/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.2722 - rmse: 2.2681 - val_loss: 4.0978 - val_rmse: 1.9995\n",
      "Epoch 22/100\n",
      "1143/1143 - 1s - 644us/step - loss: 5.2739 - rmse: 2.2679 - val_loss: 4.1013 - val_rmse: 1.9995\n",
      "Epoch 23/100\n",
      "1143/1143 - 1s - 641us/step - loss: 5.1843 - rmse: 2.2484 - val_loss: 4.1089 - val_rmse: 2.0015\n",
      "Epoch 24/100\n",
      "1143/1143 - 1s - 645us/step - loss: 5.1769 - rmse: 2.2474 - val_loss: 4.0660 - val_rmse: 1.9907\n",
      "Epoch 25/100\n",
      "1143/1143 - 1s - 645us/step - loss: 5.1480 - rmse: 2.2393 - val_loss: 4.0193 - val_rmse: 1.9795\n",
      "Epoch 26/100\n",
      "1143/1143 - 1s - 642us/step - loss: 5.0977 - rmse: 2.2302 - val_loss: 4.0537 - val_rmse: 1.9886\n",
      "Epoch 27/100\n",
      "1143/1143 - 1s - 642us/step - loss: 5.1303 - rmse: 2.2369 - val_loss: 4.0490 - val_rmse: 1.9869\n",
      "Epoch 28/100\n",
      "1143/1143 - 1s - 642us/step - loss: 5.0236 - rmse: 2.2129 - val_loss: 4.0347 - val_rmse: 1.9835\n",
      "Epoch 29/100\n",
      "1143/1143 - 1s - 646us/step - loss: 5.0362 - rmse: 2.2139 - val_loss: 4.0353 - val_rmse: 1.9838\n",
      "Epoch 30/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.9861 - rmse: 2.2030 - val_loss: 4.0286 - val_rmse: 1.9808\n",
      "Epoch 31/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.9827 - rmse: 2.2027 - val_loss: 3.9756 - val_rmse: 1.9686\n",
      "Epoch 32/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.9608 - rmse: 2.1992 - val_loss: 3.9556 - val_rmse: 1.9630\n",
      "Epoch 33/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.9094 - rmse: 2.1878 - val_loss: 3.9048 - val_rmse: 1.9508\n",
      "Epoch 34/100\n",
      "1143/1143 - 1s - 641us/step - loss: 4.9039 - rmse: 2.1859 - val_loss: 3.9298 - val_rmse: 1.9569\n",
      "Epoch 35/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.8892 - rmse: 2.1853 - val_loss: 3.9272 - val_rmse: 1.9559\n",
      "Epoch 36/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.8600 - rmse: 2.1782 - val_loss: 3.9824 - val_rmse: 1.9690\n",
      "Epoch 37/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.8673 - rmse: 2.1774 - val_loss: 3.9132 - val_rmse: 1.9524\n",
      "Epoch 38/100\n",
      "1143/1143 - 1s - 640us/step - loss: 4.8447 - rmse: 2.1719 - val_loss: 3.8759 - val_rmse: 1.9444\n",
      "Epoch 39/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.8082 - rmse: 2.1649 - val_loss: 3.9115 - val_rmse: 1.9531\n",
      "Epoch 40/100\n",
      "1143/1143 - 1s - 639us/step - loss: 4.7714 - rmse: 2.1568 - val_loss: 3.8682 - val_rmse: 1.9412\n",
      "Epoch 41/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.7356 - rmse: 2.1508 - val_loss: 3.9338 - val_rmse: 1.9580\n",
      "Epoch 42/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.7662 - rmse: 2.1552 - val_loss: 3.8431 - val_rmse: 1.9358\n",
      "Epoch 43/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.7224 - rmse: 2.1450 - val_loss: 3.8678 - val_rmse: 1.9417\n",
      "Epoch 44/100\n",
      "1143/1143 - 1s - 649us/step - loss: 4.7275 - rmse: 2.1464 - val_loss: 3.8216 - val_rmse: 1.9294\n",
      "Epoch 45/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.7276 - rmse: 2.1436 - val_loss: 3.8625 - val_rmse: 1.9396\n",
      "Epoch 46/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.6792 - rmse: 2.1364 - val_loss: 3.7885 - val_rmse: 1.9224\n",
      "Epoch 47/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.6772 - rmse: 2.1336 - val_loss: 3.9364 - val_rmse: 1.9575\n",
      "Epoch 48/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.6526 - rmse: 2.1294 - val_loss: 3.7975 - val_rmse: 1.9230\n",
      "Epoch 49/100\n",
      "1143/1143 - 1s - 642us/step - loss: 4.6670 - rmse: 2.1337 - val_loss: 3.8018 - val_rmse: 1.9238\n",
      "Epoch 50/100\n",
      "1143/1143 - 1s - 657us/step - loss: 4.6194 - rmse: 2.1204 - val_loss: 3.7909 - val_rmse: 1.9214\n",
      "Epoch 51/100\n",
      "1143/1143 - 1s - 649us/step - loss: 4.6321 - rmse: 2.1252 - val_loss: 3.8390 - val_rmse: 1.9336\n",
      "Epoch 52/100\n",
      "1143/1143 - 1s - 647us/step - loss: 4.5926 - rmse: 2.1167 - val_loss: 3.7248 - val_rmse: 1.9049\n",
      "Epoch 53/100\n",
      "1143/1143 - 1s - 642us/step - loss: 4.6478 - rmse: 2.1272 - val_loss: 3.8200 - val_rmse: 1.9300\n",
      "Epoch 54/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.6043 - rmse: 2.1162 - val_loss: 3.7243 - val_rmse: 1.9050\n",
      "Epoch 55/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.5849 - rmse: 2.1121 - val_loss: 3.7483 - val_rmse: 1.9116\n",
      "Epoch 56/100\n",
      "1143/1143 - 1s - 648us/step - loss: 4.5888 - rmse: 2.1128 - val_loss: 3.7901 - val_rmse: 1.9222\n",
      "Epoch 57/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.5703 - rmse: 2.1125 - val_loss: 3.7544 - val_rmse: 1.9129\n",
      "Epoch 58/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.5649 - rmse: 2.1104 - val_loss: 3.6917 - val_rmse: 1.8967\n",
      "Epoch 59/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.5522 - rmse: 2.1053 - val_loss: 3.6887 - val_rmse: 1.8970\n",
      "Epoch 60/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.5742 - rmse: 2.1114 - val_loss: 3.7855 - val_rmse: 1.9203\n",
      "Epoch 61/100\n",
      "1143/1143 - 1s - 641us/step - loss: 4.5127 - rmse: 2.0982 - val_loss: 3.7921 - val_rmse: 1.9228\n",
      "Epoch 62/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.5302 - rmse: 2.1007 - val_loss: 3.6216 - val_rmse: 1.8791\n",
      "Epoch 63/100\n",
      "1143/1143 - 1s - 642us/step - loss: 4.5258 - rmse: 2.0998 - val_loss: 3.6745 - val_rmse: 1.8926\n",
      "Epoch 64/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.4797 - rmse: 2.0897 - val_loss: 3.6253 - val_rmse: 1.8799\n",
      "Epoch 65/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.5254 - rmse: 2.0984 - val_loss: 3.6785 - val_rmse: 1.8933\n",
      "Epoch 66/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.4745 - rmse: 2.0879 - val_loss: 3.6304 - val_rmse: 1.8821\n",
      "Epoch 67/100\n",
      "1143/1143 - 1s - 647us/step - loss: 4.5051 - rmse: 2.0940 - val_loss: 3.6670 - val_rmse: 1.8908\n",
      "Epoch 68/100\n",
      "1143/1143 - 1s - 649us/step - loss: 4.4697 - rmse: 2.0843 - val_loss: 3.6219 - val_rmse: 1.8786\n",
      "Epoch 69/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.4725 - rmse: 2.0871 - val_loss: 3.6010 - val_rmse: 1.8743\n",
      "Epoch 70/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.4633 - rmse: 2.0859 - val_loss: 3.6147 - val_rmse: 1.8776\n",
      "Epoch 71/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.4740 - rmse: 2.0874 - val_loss: 3.5871 - val_rmse: 1.8697\n",
      "Epoch 72/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.4541 - rmse: 2.0848 - val_loss: 3.5999 - val_rmse: 1.8727\n",
      "Epoch 73/100\n",
      "1143/1143 - 1s - 647us/step - loss: 4.4137 - rmse: 2.0718 - val_loss: 3.5748 - val_rmse: 1.8669\n",
      "Epoch 74/100\n",
      "1143/1143 - 1s - 643us/step - loss: 4.4183 - rmse: 2.0739 - val_loss: 3.6422 - val_rmse: 1.8860\n",
      "Epoch 75/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.4070 - rmse: 2.0734 - val_loss: 3.6189 - val_rmse: 1.8788\n",
      "Epoch 76/100\n",
      "1143/1143 - 1s - 648us/step - loss: 4.4051 - rmse: 2.0709 - val_loss: 3.5548 - val_rmse: 1.8623\n",
      "Epoch 77/100\n",
      "1143/1143 - 1s - 648us/step - loss: 4.4196 - rmse: 2.0749 - val_loss: 3.6897 - val_rmse: 1.8973\n",
      "Epoch 78/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.4301 - rmse: 2.0782 - val_loss: 3.6306 - val_rmse: 1.8816\n",
      "Epoch 79/100\n",
      "1143/1143 - 1s - 648us/step - loss: 4.4044 - rmse: 2.0703 - val_loss: 3.5867 - val_rmse: 1.8702\n",
      "Epoch 80/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.4040 - rmse: 2.0704 - val_loss: 3.5630 - val_rmse: 1.8637\n",
      "Epoch 81/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.3760 - rmse: 2.0660 - val_loss: 3.5766 - val_rmse: 1.8675\n",
      "Epoch 82/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.3991 - rmse: 2.0712 - val_loss: 3.6370 - val_rmse: 1.8837\n",
      "Epoch 83/100\n",
      "1143/1143 - 1s - 649us/step - loss: 4.3978 - rmse: 2.0690 - val_loss: 3.5087 - val_rmse: 1.8498\n",
      "Epoch 84/100\n",
      "1143/1143 - 1s - 644us/step - loss: 4.3856 - rmse: 2.0681 - val_loss: 3.5331 - val_rmse: 1.8553\n",
      "Epoch 85/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.3870 - rmse: 2.0671 - val_loss: 3.5372 - val_rmse: 1.8564\n",
      "Epoch 86/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.4228 - rmse: 2.0743 - val_loss: 3.6307 - val_rmse: 1.8807\n",
      "Epoch 87/100\n",
      "1143/1143 - 1s - 642us/step - loss: 4.3876 - rmse: 2.0677 - val_loss: 3.5730 - val_rmse: 1.8664\n",
      "Epoch 88/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.4229 - rmse: 2.0749 - val_loss: 3.6036 - val_rmse: 1.8744\n",
      "Epoch 89/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.3746 - rmse: 2.0661 - val_loss: 3.5768 - val_rmse: 1.8660\n",
      "Epoch 90/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.3706 - rmse: 2.0628 - val_loss: 3.5485 - val_rmse: 1.8593\n",
      "Epoch 91/100\n",
      "1143/1143 - 1s - 664us/step - loss: 4.3732 - rmse: 2.0631 - val_loss: 3.5569 - val_rmse: 1.8619\n",
      "Epoch 92/100\n",
      "1143/1143 - 1s - 646us/step - loss: 4.3571 - rmse: 2.0611 - val_loss: 3.6312 - val_rmse: 1.8805\n",
      "Epoch 93/100\n",
      "1143/1143 - 1s - 645us/step - loss: 4.3741 - rmse: 2.0651 - val_loss: 3.5454 - val_rmse: 1.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143/1143 - 1s - 459us/step - loss: 4.0852 - rmse: 3.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 - 1s - 549us/step - loss: 4.2883 - rmse: 3.8935\n",
      "WARNING:tensorflow:5 out of the last 130 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3ae43c360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "229/229 - 0s - 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 - 0s - 524us/step - loss: 4.2449 - rmse: 3.9402\n",
      "229/229 - 0s - 626us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 - 0s - 520us/step - loss: 4.1317 - rmse: 3.8369\n",
      "229/229 - 0s - 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 - 0s - 527us/step - loss: 3.7950 - rmse: 3.6468\n",
      "229/229 - 0s - 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 - 0s - 522us/step - loss: 3.9623 - rmse: 3.7066\n",
      "229/229 - 0s - 613us/step\n",
      "00:41:41 - p02 - Predicting -\n",
      "8/8 - 0s - 13ms/step\n",
      "00:41:41 - p02 - Done -\n",
      "00:41:41 - p04 - Predicting for patient p04\n",
      "00:41:41 - p04 - Transforming the data -\n",
      "00:41:41 - p04 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 - 2s - 2ms/step - loss: 18.6888 - rmse: 3.8798 - val_loss: 3.9613 - val_rmse: 1.9638\n",
      "Epoch 2/100\n",
      "1151/1151 - 1s - 679us/step - loss: 5.7755 - rmse: 2.3753 - val_loss: 3.7766 - val_rmse: 1.9148\n",
      "Epoch 3/100\n",
      "1151/1151 - 1s - 671us/step - loss: 5.1208 - rmse: 2.2367 - val_loss: 3.7225 - val_rmse: 1.8998\n",
      "Epoch 4/100\n",
      "1151/1151 - 1s - 673us/step - loss: 4.8082 - rmse: 2.1654 - val_loss: 3.6801 - val_rmse: 1.8885\n",
      "Epoch 5/100\n",
      "1151/1151 - 1s - 673us/step - loss: 4.6354 - rmse: 2.1265 - val_loss: 3.6070 - val_rmse: 1.8699\n",
      "Epoch 6/100\n",
      "1151/1151 - 1s - 676us/step - loss: 4.4927 - rmse: 2.0929 - val_loss: 3.6044 - val_rmse: 1.8693\n",
      "Epoch 7/100\n",
      "1151/1151 - 1s - 676us/step - loss: 4.4072 - rmse: 2.0730 - val_loss: 3.4607 - val_rmse: 1.8340\n",
      "Epoch 8/100\n",
      "1151/1151 - 1s - 672us/step - loss: 4.3281 - rmse: 2.0566 - val_loss: 3.4452 - val_rmse: 1.8277\n",
      "Epoch 9/100\n",
      "1151/1151 - 1s - 689us/step - loss: 4.2551 - rmse: 2.0379 - val_loss: 3.4692 - val_rmse: 1.8356\n",
      "Epoch 10/100\n",
      "1151/1151 - 1s - 675us/step - loss: 4.2240 - rmse: 2.0301 - val_loss: 3.5469 - val_rmse: 1.8552\n",
      "Epoch 11/100\n",
      "1151/1151 - 1s - 673us/step - loss: 4.1748 - rmse: 2.0194 - val_loss: 3.4049 - val_rmse: 1.8178\n",
      "Epoch 12/100\n",
      "1151/1151 - 1s - 672us/step - loss: 4.0795 - rmse: 1.9945 - val_loss: 3.3771 - val_rmse: 1.8104\n",
      "Epoch 13/100\n",
      "1151/1151 - 1s - 675us/step - loss: 4.0390 - rmse: 1.9846 - val_loss: 3.3563 - val_rmse: 1.8055\n",
      "Epoch 14/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.9827 - rmse: 1.9727 - val_loss: 3.3254 - val_rmse: 1.7984\n",
      "Epoch 15/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.9808 - rmse: 1.9703 - val_loss: 3.3102 - val_rmse: 1.7945\n",
      "Epoch 16/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.9484 - rmse: 1.9619 - val_loss: 3.3147 - val_rmse: 1.7940\n",
      "Epoch 17/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.9166 - rmse: 1.9550 - val_loss: 3.2606 - val_rmse: 1.7804\n",
      "Epoch 18/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.8940 - rmse: 1.9500 - val_loss: 3.2605 - val_rmse: 1.7795\n",
      "Epoch 19/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.8322 - rmse: 1.9330 - val_loss: 3.2085 - val_rmse: 1.7650\n",
      "Epoch 20/100\n",
      "1151/1151 - 1s - 670us/step - loss: 3.8105 - rmse: 1.9291 - val_loss: 3.2260 - val_rmse: 1.7692\n",
      "Epoch 21/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.8000 - rmse: 1.9243 - val_loss: 3.1975 - val_rmse: 1.7622\n",
      "Epoch 22/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.7629 - rmse: 1.9170 - val_loss: 3.1856 - val_rmse: 1.7587\n",
      "Epoch 23/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.7408 - rmse: 1.9092 - val_loss: 3.1624 - val_rmse: 1.7538\n",
      "Epoch 24/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.7482 - rmse: 1.9110 - val_loss: 3.1632 - val_rmse: 1.7526\n",
      "Epoch 25/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.6796 - rmse: 1.8947 - val_loss: 3.2138 - val_rmse: 1.7661\n",
      "Epoch 26/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.6669 - rmse: 1.8912 - val_loss: 3.1639 - val_rmse: 1.7514\n",
      "Epoch 27/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.6481 - rmse: 1.8851 - val_loss: 3.1791 - val_rmse: 1.7561\n",
      "Epoch 28/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.6442 - rmse: 1.8843 - val_loss: 3.1608 - val_rmse: 1.7502\n",
      "Epoch 29/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.6115 - rmse: 1.8755 - val_loss: 3.0797 - val_rmse: 1.7283\n",
      "Epoch 30/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.6220 - rmse: 1.8786 - val_loss: 3.1111 - val_rmse: 1.7385\n",
      "Epoch 31/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.6042 - rmse: 1.8745 - val_loss: 3.0723 - val_rmse: 1.7255\n",
      "Epoch 32/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.5622 - rmse: 1.8639 - val_loss: 3.1011 - val_rmse: 1.7328\n",
      "Epoch 33/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.5712 - rmse: 1.8657 - val_loss: 3.0392 - val_rmse: 1.7162\n",
      "Epoch 34/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.5349 - rmse: 1.8571 - val_loss: 3.0463 - val_rmse: 1.7195\n",
      "Epoch 35/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.5561 - rmse: 1.8625 - val_loss: 3.0816 - val_rmse: 1.7286\n",
      "Epoch 36/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.5345 - rmse: 1.8571 - val_loss: 3.0227 - val_rmse: 1.7128\n",
      "Epoch 37/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.4906 - rmse: 1.8453 - val_loss: 3.0156 - val_rmse: 1.7110\n",
      "Epoch 38/100\n",
      "1151/1151 - 1s - 698us/step - loss: 3.5085 - rmse: 1.8505 - val_loss: 3.0664 - val_rmse: 1.7245\n",
      "Epoch 39/100\n",
      "1151/1151 - 1s - 693us/step - loss: 3.4976 - rmse: 1.8465 - val_loss: 3.0358 - val_rmse: 1.7166\n",
      "Epoch 40/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.4829 - rmse: 1.8429 - val_loss: 3.0045 - val_rmse: 1.7072\n",
      "Epoch 41/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.4818 - rmse: 1.8422 - val_loss: 3.0275 - val_rmse: 1.7134\n",
      "Epoch 42/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.4411 - rmse: 1.8313 - val_loss: 2.9943 - val_rmse: 1.7037\n",
      "Epoch 43/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.4676 - rmse: 1.8388 - val_loss: 3.0389 - val_rmse: 1.7168\n",
      "Epoch 44/100\n",
      "1151/1151 - 1s - 670us/step - loss: 3.4435 - rmse: 1.8329 - val_loss: 2.9717 - val_rmse: 1.6987\n",
      "Epoch 45/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.4301 - rmse: 1.8290 - val_loss: 2.9868 - val_rmse: 1.7019\n",
      "Epoch 46/100\n",
      "1151/1151 - 1s - 669us/step - loss: 3.4270 - rmse: 1.8296 - val_loss: 2.9829 - val_rmse: 1.7013\n",
      "Epoch 47/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.4017 - rmse: 1.8216 - val_loss: 2.9906 - val_rmse: 1.7023\n",
      "Epoch 48/100\n",
      "1151/1151 - 1s - 689us/step - loss: 3.4152 - rmse: 1.8260 - val_loss: 3.0156 - val_rmse: 1.7099\n",
      "Epoch 49/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.4027 - rmse: 1.8236 - val_loss: 2.9899 - val_rmse: 1.7025\n",
      "Epoch 50/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.4098 - rmse: 1.8242 - val_loss: 2.9925 - val_rmse: 1.7034\n",
      "Epoch 51/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.3955 - rmse: 1.8178 - val_loss: 2.9053 - val_rmse: 1.6777\n",
      "Epoch 52/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.3814 - rmse: 1.8146 - val_loss: 2.9045 - val_rmse: 1.6798\n",
      "Epoch 53/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.3787 - rmse: 1.8138 - val_loss: 2.8965 - val_rmse: 1.6772\n",
      "Epoch 54/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.3511 - rmse: 1.8092 - val_loss: 2.9073 - val_rmse: 1.6809\n",
      "Epoch 55/100\n",
      "1151/1151 - 1s - 677us/step - loss: 3.3940 - rmse: 1.8181 - val_loss: 2.8637 - val_rmse: 1.6676\n",
      "Epoch 56/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.3539 - rmse: 1.8088 - val_loss: 2.9493 - val_rmse: 1.6912\n",
      "Epoch 57/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.3478 - rmse: 1.8055 - val_loss: 2.9179 - val_rmse: 1.6816\n",
      "Epoch 58/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.3554 - rmse: 1.8088 - val_loss: 2.9074 - val_rmse: 1.6790\n",
      "Epoch 59/100\n",
      "1151/1151 - 1s - 673us/step - loss: 3.3495 - rmse: 1.8061 - val_loss: 2.9154 - val_rmse: 1.6825\n",
      "Epoch 60/100\n",
      "1151/1151 - 1s - 679us/step - loss: 3.3518 - rmse: 1.8086 - val_loss: 2.8590 - val_rmse: 1.6658\n",
      "Epoch 61/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.3414 - rmse: 1.8065 - val_loss: 2.8999 - val_rmse: 1.6773\n",
      "Epoch 62/100\n",
      "1151/1151 - 1s - 672us/step - loss: 3.3216 - rmse: 1.7976 - val_loss: 2.8695 - val_rmse: 1.6678\n",
      "Epoch 63/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.3235 - rmse: 1.8008 - val_loss: 2.8541 - val_rmse: 1.6650\n",
      "Epoch 64/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.3363 - rmse: 1.8033 - val_loss: 2.8158 - val_rmse: 1.6527\n",
      "Epoch 65/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.3390 - rmse: 1.8035 - val_loss: 2.8560 - val_rmse: 1.6649\n",
      "Epoch 66/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.2932 - rmse: 1.7915 - val_loss: 2.8489 - val_rmse: 1.6631\n",
      "Epoch 67/100\n",
      "1151/1151 - 1s - 677us/step - loss: 3.3017 - rmse: 1.7940 - val_loss: 2.8126 - val_rmse: 1.6521\n",
      "Epoch 68/100\n",
      "1151/1151 - 1s - 677us/step - loss: 3.2812 - rmse: 1.7890 - val_loss: 2.8934 - val_rmse: 1.6758\n",
      "Epoch 69/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.2963 - rmse: 1.7938 - val_loss: 2.8548 - val_rmse: 1.6643\n",
      "Epoch 70/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.2764 - rmse: 1.7856 - val_loss: 2.7789 - val_rmse: 1.6419\n",
      "Epoch 71/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.2958 - rmse: 1.7914 - val_loss: 2.7836 - val_rmse: 1.6427\n",
      "Epoch 72/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.2799 - rmse: 1.7894 - val_loss: 2.8381 - val_rmse: 1.6590\n",
      "Epoch 73/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.2744 - rmse: 1.7859 - val_loss: 2.8191 - val_rmse: 1.6539\n",
      "Epoch 74/100\n",
      "1151/1151 - 1s - 677us/step - loss: 3.2686 - rmse: 1.7849 - val_loss: 2.8147 - val_rmse: 1.6520\n",
      "Epoch 75/100\n",
      "1151/1151 - 1s - 679us/step - loss: 3.2618 - rmse: 1.7835 - val_loss: 2.7684 - val_rmse: 1.6394\n",
      "Epoch 76/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.2559 - rmse: 1.7832 - val_loss: 2.8251 - val_rmse: 1.6555\n",
      "Epoch 77/100\n",
      "1151/1151 - 1s - 681us/step - loss: 3.2564 - rmse: 1.7826 - val_loss: 2.8276 - val_rmse: 1.6571\n",
      "Epoch 78/100\n",
      "1151/1151 - 1s - 675us/step - loss: 3.2758 - rmse: 1.7859 - val_loss: 2.8143 - val_rmse: 1.6527\n",
      "Epoch 79/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.2600 - rmse: 1.7834 - val_loss: 2.8028 - val_rmse: 1.6488\n",
      "Epoch 80/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.2638 - rmse: 1.7834 - val_loss: 2.8026 - val_rmse: 1.6506\n",
      "Epoch 81/100\n",
      "1151/1151 - 1s - 677us/step - loss: 3.2625 - rmse: 1.7837 - val_loss: 2.7754 - val_rmse: 1.6403\n",
      "Epoch 82/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.2520 - rmse: 1.7807 - val_loss: 2.7752 - val_rmse: 1.6405\n",
      "Epoch 83/100\n",
      "1151/1151 - 1s - 678us/step - loss: 3.2406 - rmse: 1.7791 - val_loss: 2.7880 - val_rmse: 1.6444\n",
      "Epoch 84/100\n",
      "1151/1151 - 1s - 674us/step - loss: 3.2511 - rmse: 1.7825 - val_loss: 2.7786 - val_rmse: 1.6415\n",
      "Epoch 85/100\n",
      "1151/1151 - 1s - 676us/step - loss: 3.2541 - rmse: 1.7805 - val_loss: 2.7934 - val_rmse: 1.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151/1151 - 1s - 484us/step - loss: 3.1335 - rmse: 2.6427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 - 1s - 550us/step - loss: 3.1577 - rmse: 2.6707\n",
      "WARNING:tensorflow:5 out of the last 238 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x39c518e00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "231/231 - 0s - 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 - 0s - 529us/step - loss: 3.1139 - rmse: 2.6674\n",
      "231/231 - 0s - 630us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 - 0s - 524us/step - loss: 3.1149 - rmse: 2.6302\n",
      "231/231 - 0s - 627us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 - 0s - 524us/step - loss: 3.0904 - rmse: 2.6374\n",
      "231/231 - 0s - 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 - 0s - 525us/step - loss: 3.0875 - rmse: 2.6174\n",
      "231/231 - 0s - 611us/step\n",
      "00:45:16 - p04 - Predicting -\n",
      "9/9 - 0s - 10ms/step\n",
      "00:45:16 - p04 - Done -\n",
      "00:45:16 - p05 - Predicting for patient p05\n",
      "00:45:16 - p05 - Transforming the data -\n",
      "00:45:16 - p05 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642/642 - 2s - 2ms/step - loss: 32.5599 - rmse: 5.2788 - val_loss: 4.4807 - val_rmse: 2.0859\n",
      "Epoch 2/100\n",
      "642/642 - 0s - 709us/step - loss: 7.4279 - rmse: 2.6971 - val_loss: 3.9627 - val_rmse: 1.9609\n",
      "Epoch 3/100\n",
      "642/642 - 0s - 698us/step - loss: 6.1893 - rmse: 2.4622 - val_loss: 3.9513 - val_rmse: 1.9575\n",
      "Epoch 4/100\n",
      "642/642 - 1s - 1ms/step - loss: 5.8953 - rmse: 2.4043 - val_loss: 3.7321 - val_rmse: 1.9007\n",
      "Epoch 5/100\n",
      "642/642 - 0s - 693us/step - loss: 5.4823 - rmse: 2.3186 - val_loss: 3.6602 - val_rmse: 1.8828\n",
      "Epoch 6/100\n",
      "642/642 - 0s - 711us/step - loss: 5.3124 - rmse: 2.2819 - val_loss: 3.6102 - val_rmse: 1.8697\n",
      "Epoch 7/100\n",
      "642/642 - 0s - 704us/step - loss: 5.1525 - rmse: 2.2473 - val_loss: 3.7058 - val_rmse: 1.8942\n",
      "Epoch 8/100\n",
      "642/642 - 0s - 693us/step - loss: 5.0767 - rmse: 2.2311 - val_loss: 3.4795 - val_rmse: 1.8357\n",
      "Epoch 9/100\n",
      "642/642 - 0s - 698us/step - loss: 4.9104 - rmse: 2.1919 - val_loss: 3.4633 - val_rmse: 1.8327\n",
      "Epoch 10/100\n",
      "642/642 - 0s - 691us/step - loss: 4.9346 - rmse: 2.1986 - val_loss: 3.4669 - val_rmse: 1.8322\n",
      "Epoch 11/100\n",
      "642/642 - 0s - 696us/step - loss: 4.8309 - rmse: 2.1739 - val_loss: 3.4483 - val_rmse: 1.8269\n",
      "Epoch 12/100\n",
      "642/642 - 0s - 691us/step - loss: 4.8301 - rmse: 2.1777 - val_loss: 3.3712 - val_rmse: 1.8071\n",
      "Epoch 13/100\n",
      "642/642 - 0s - 694us/step - loss: 4.7609 - rmse: 2.1584 - val_loss: 3.3012 - val_rmse: 1.7881\n",
      "Epoch 14/100\n",
      "642/642 - 0s - 690us/step - loss: 4.6945 - rmse: 2.1437 - val_loss: 3.3041 - val_rmse: 1.7883\n",
      "Epoch 15/100\n",
      "642/642 - 0s - 689us/step - loss: 4.5851 - rmse: 2.1166 - val_loss: 3.4034 - val_rmse: 1.8169\n",
      "Epoch 16/100\n",
      "642/642 - 0s - 692us/step - loss: 4.6831 - rmse: 2.1404 - val_loss: 3.3280 - val_rmse: 1.7953\n",
      "Epoch 17/100\n",
      "642/642 - 0s - 693us/step - loss: 4.6526 - rmse: 2.1342 - val_loss: 3.2569 - val_rmse: 1.7753\n",
      "Epoch 18/100\n",
      "642/642 - 0s - 697us/step - loss: 4.4933 - rmse: 2.0955 - val_loss: 3.2308 - val_rmse: 1.7718\n",
      "Epoch 19/100\n",
      "642/642 - 0s - 697us/step - loss: 4.4737 - rmse: 2.0906 - val_loss: 3.1945 - val_rmse: 1.7588\n",
      "Epoch 20/100\n",
      "642/642 - 0s - 695us/step - loss: 4.4881 - rmse: 2.0930 - val_loss: 3.2615 - val_rmse: 1.7738\n",
      "Epoch 21/100\n",
      "642/642 - 0s - 689us/step - loss: 4.4660 - rmse: 2.0869 - val_loss: 3.1511 - val_rmse: 1.7474\n",
      "Epoch 22/100\n",
      "642/642 - 0s - 693us/step - loss: 4.3500 - rmse: 2.0628 - val_loss: 3.1662 - val_rmse: 1.7501\n",
      "Epoch 23/100\n",
      "642/642 - 0s - 689us/step - loss: 4.3507 - rmse: 2.0626 - val_loss: 3.1181 - val_rmse: 1.7380\n",
      "Epoch 24/100\n",
      "642/642 - 0s - 693us/step - loss: 4.2665 - rmse: 2.0453 - val_loss: 3.1299 - val_rmse: 1.7399\n",
      "Epoch 25/100\n",
      "642/642 - 0s - 692us/step - loss: 4.2445 - rmse: 2.0363 - val_loss: 3.1471 - val_rmse: 1.7457\n",
      "Epoch 26/100\n",
      "642/642 - 0s - 694us/step - loss: 4.2854 - rmse: 2.0476 - val_loss: 3.1473 - val_rmse: 1.7435\n",
      "Epoch 27/100\n",
      "642/642 - 0s - 693us/step - loss: 4.2116 - rmse: 2.0294 - val_loss: 3.0950 - val_rmse: 1.7291\n",
      "Epoch 28/100\n",
      "642/642 - 0s - 698us/step - loss: 4.2411 - rmse: 2.0346 - val_loss: 3.0425 - val_rmse: 1.7161\n",
      "Epoch 29/100\n",
      "642/642 - 0s - 713us/step - loss: 4.1573 - rmse: 2.0148 - val_loss: 2.9780 - val_rmse: 1.7001\n",
      "Epoch 30/100\n",
      "642/642 - 0s - 701us/step - loss: 4.1637 - rmse: 2.0185 - val_loss: 3.0080 - val_rmse: 1.7084\n",
      "Epoch 31/100\n",
      "642/642 - 0s - 695us/step - loss: 4.1221 - rmse: 2.0046 - val_loss: 3.0441 - val_rmse: 1.7170\n",
      "Epoch 32/100\n",
      "642/642 - 0s - 689us/step - loss: 4.1398 - rmse: 2.0109 - val_loss: 2.9984 - val_rmse: 1.7033\n",
      "Epoch 33/100\n",
      "642/642 - 0s - 697us/step - loss: 4.0493 - rmse: 1.9889 - val_loss: 2.9991 - val_rmse: 1.7036\n",
      "Epoch 34/100\n",
      "642/642 - 0s - 692us/step - loss: 4.0612 - rmse: 1.9921 - val_loss: 2.9000 - val_rmse: 1.6752\n",
      "Epoch 35/100\n",
      "642/642 - 0s - 694us/step - loss: 4.0620 - rmse: 1.9926 - val_loss: 3.0333 - val_rmse: 1.7140\n",
      "Epoch 36/100\n",
      "642/642 - 0s - 697us/step - loss: 4.0597 - rmse: 1.9917 - val_loss: 2.8784 - val_rmse: 1.6698\n",
      "Epoch 37/100\n",
      "642/642 - 0s - 705us/step - loss: 3.9773 - rmse: 1.9700 - val_loss: 3.0784 - val_rmse: 1.7296\n",
      "Epoch 38/100\n",
      "642/642 - 0s - 694us/step - loss: 4.0064 - rmse: 1.9775 - val_loss: 2.9259 - val_rmse: 1.6823\n",
      "Epoch 39/100\n",
      "642/642 - 0s - 693us/step - loss: 3.9286 - rmse: 1.9593 - val_loss: 2.9324 - val_rmse: 1.6883\n",
      "Epoch 40/100\n",
      "642/642 - 0s - 697us/step - loss: 3.9295 - rmse: 1.9592 - val_loss: 2.8787 - val_rmse: 1.6698\n",
      "Epoch 41/100\n",
      "642/642 - 0s - 695us/step - loss: 3.9279 - rmse: 1.9596 - val_loss: 2.9850 - val_rmse: 1.6997\n",
      "Epoch 42/100\n",
      "642/642 - 0s - 697us/step - loss: 3.9224 - rmse: 1.9595 - val_loss: 2.7989 - val_rmse: 1.6478\n",
      "Epoch 43/100\n",
      "642/642 - 0s - 691us/step - loss: 3.9302 - rmse: 1.9594 - val_loss: 2.8402 - val_rmse: 1.6574\n",
      "Epoch 44/100\n",
      "642/642 - 0s - 694us/step - loss: 3.8707 - rmse: 1.9432 - val_loss: 2.8622 - val_rmse: 1.6648\n",
      "Epoch 45/100\n",
      "642/642 - 0s - 697us/step - loss: 3.8393 - rmse: 1.9376 - val_loss: 2.7746 - val_rmse: 1.6399\n",
      "Epoch 46/100\n",
      "642/642 - 0s - 694us/step - loss: 3.8364 - rmse: 1.9342 - val_loss: 2.8291 - val_rmse: 1.6539\n",
      "Epoch 47/100\n",
      "642/642 - 0s - 696us/step - loss: 3.8578 - rmse: 1.9425 - val_loss: 2.8367 - val_rmse: 1.6562\n",
      "Epoch 48/100\n",
      "642/642 - 0s - 693us/step - loss: 3.8331 - rmse: 1.9361 - val_loss: 2.9037 - val_rmse: 1.6764\n",
      "Epoch 49/100\n",
      "642/642 - 0s - 696us/step - loss: 3.8046 - rmse: 1.9286 - val_loss: 2.8287 - val_rmse: 1.6529\n",
      "Epoch 50/100\n",
      "642/642 - 0s - 689us/step - loss: 3.7527 - rmse: 1.9127 - val_loss: 2.8625 - val_rmse: 1.6653\n",
      "Epoch 51/100\n",
      "642/642 - 0s - 692us/step - loss: 3.7767 - rmse: 1.9180 - val_loss: 2.8536 - val_rmse: 1.6591\n",
      "Epoch 52/100\n",
      "642/642 - 0s - 692us/step - loss: 3.7636 - rmse: 1.9148 - val_loss: 2.7602 - val_rmse: 1.6341\n",
      "Epoch 53/100\n",
      "642/642 - 0s - 721us/step - loss: 3.7270 - rmse: 1.9072 - val_loss: 2.7859 - val_rmse: 1.6449\n",
      "Epoch 54/100\n",
      "642/642 - 0s - 699us/step - loss: 3.7231 - rmse: 1.9049 - val_loss: 2.7092 - val_rmse: 1.6195\n",
      "Epoch 55/100\n",
      "642/642 - 0s - 698us/step - loss: 3.7327 - rmse: 1.9095 - val_loss: 2.7403 - val_rmse: 1.6287\n",
      "Epoch 56/100\n",
      "642/642 - 0s - 693us/step - loss: 3.6862 - rmse: 1.8980 - val_loss: 2.7343 - val_rmse: 1.6279\n",
      "Epoch 57/100\n",
      "642/642 - 0s - 698us/step - loss: 3.6894 - rmse: 1.8984 - val_loss: 2.6985 - val_rmse: 1.6165\n",
      "Epoch 58/100\n",
      "642/642 - 0s - 696us/step - loss: 3.7053 - rmse: 1.8986 - val_loss: 2.7734 - val_rmse: 1.6397\n",
      "Epoch 59/100\n",
      "642/642 - 0s - 690us/step - loss: 3.7311 - rmse: 1.9077 - val_loss: 2.7282 - val_rmse: 1.6262\n",
      "Epoch 60/100\n",
      "642/642 - 0s - 700us/step - loss: 3.6466 - rmse: 1.8874 - val_loss: 2.7511 - val_rmse: 1.6331\n",
      "Epoch 61/100\n",
      "642/642 - 0s - 694us/step - loss: 3.6231 - rmse: 1.8800 - val_loss: 2.7539 - val_rmse: 1.6341\n",
      "Epoch 62/100\n",
      "642/642 - 0s - 699us/step - loss: 3.6807 - rmse: 1.8958 - val_loss: 2.6211 - val_rmse: 1.5967\n",
      "Epoch 63/100\n",
      "642/642 - 0s - 693us/step - loss: 3.6231 - rmse: 1.8806 - val_loss: 2.7327 - val_rmse: 1.6264\n",
      "Epoch 64/100\n",
      "642/642 - 0s - 697us/step - loss: 3.6051 - rmse: 1.8780 - val_loss: 2.6065 - val_rmse: 1.5901\n",
      "Epoch 65/100\n",
      "642/642 - 0s - 696us/step - loss: 3.6251 - rmse: 1.8835 - val_loss: 2.6593 - val_rmse: 1.6059\n",
      "Epoch 66/100\n",
      "642/642 - 0s - 693us/step - loss: 3.5601 - rmse: 1.8659 - val_loss: 2.7291 - val_rmse: 1.6251\n",
      "Epoch 67/100\n",
      "642/642 - 0s - 697us/step - loss: 3.5777 - rmse: 1.8689 - val_loss: 2.6415 - val_rmse: 1.5998\n",
      "Epoch 68/100\n",
      "642/642 - 0s - 693us/step - loss: 3.5922 - rmse: 1.8755 - val_loss: 2.5835 - val_rmse: 1.5833\n",
      "Epoch 69/100\n",
      "642/642 - 0s - 694us/step - loss: 3.5786 - rmse: 1.8655 - val_loss: 2.6449 - val_rmse: 1.6014\n",
      "Epoch 70/100\n",
      "642/642 - 0s - 691us/step - loss: 3.5361 - rmse: 1.8579 - val_loss: 2.6339 - val_rmse: 1.5994\n",
      "Epoch 71/100\n",
      "642/642 - 0s - 730us/step - loss: 3.5242 - rmse: 1.8549 - val_loss: 2.5793 - val_rmse: 1.5821\n",
      "Epoch 72/100\n",
      "642/642 - 0s - 692us/step - loss: 3.5334 - rmse: 1.8579 - val_loss: 2.6127 - val_rmse: 1.5915\n",
      "Epoch 73/100\n",
      "642/642 - 0s - 700us/step - loss: 3.5667 - rmse: 1.8654 - val_loss: 2.5814 - val_rmse: 1.5836\n",
      "Epoch 74/100\n",
      "642/642 - 0s - 698us/step - loss: 3.5275 - rmse: 1.8543 - val_loss: 2.6080 - val_rmse: 1.5893\n",
      "Epoch 75/100\n",
      "642/642 - 0s - 693us/step - loss: 3.5501 - rmse: 1.8623 - val_loss: 2.6699 - val_rmse: 1.6096\n",
      "Epoch 76/100\n",
      "642/642 - 0s - 696us/step - loss: 3.4696 - rmse: 1.8422 - val_loss: 2.5882 - val_rmse: 1.5838\n",
      "Epoch 77/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4841 - rmse: 1.8441 - val_loss: 2.5422 - val_rmse: 1.5692\n",
      "Epoch 78/100\n",
      "642/642 - 0s - 698us/step - loss: 3.5019 - rmse: 1.8500 - val_loss: 2.6559 - val_rmse: 1.6055\n",
      "Epoch 79/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4569 - rmse: 1.8358 - val_loss: 2.6113 - val_rmse: 1.5903\n",
      "Epoch 80/100\n",
      "642/642 - 0s - 702us/step - loss: 3.4825 - rmse: 1.8448 - val_loss: 2.5413 - val_rmse: 1.5702\n",
      "Epoch 81/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4574 - rmse: 1.8363 - val_loss: 2.5880 - val_rmse: 1.5851\n",
      "Epoch 82/100\n",
      "642/642 - 0s - 696us/step - loss: 3.4677 - rmse: 1.8411 - val_loss: 2.5164 - val_rmse: 1.5620\n",
      "Epoch 83/100\n",
      "642/642 - 0s - 697us/step - loss: 3.4674 - rmse: 1.8415 - val_loss: 2.5095 - val_rmse: 1.5615\n",
      "Epoch 84/100\n",
      "642/642 - 0s - 693us/step - loss: 3.4593 - rmse: 1.8364 - val_loss: 2.6381 - val_rmse: 1.6003\n",
      "Epoch 85/100\n",
      "642/642 - 0s - 693us/step - loss: 3.4460 - rmse: 1.8328 - val_loss: 2.4786 - val_rmse: 1.5503\n",
      "Epoch 86/100\n",
      "642/642 - 0s - 690us/step - loss: 3.4496 - rmse: 1.8354 - val_loss: 2.4853 - val_rmse: 1.5520\n",
      "Epoch 87/100\n",
      "642/642 - 0s - 696us/step - loss: 3.4424 - rmse: 1.8320 - val_loss: 2.5738 - val_rmse: 1.5803\n",
      "Epoch 88/100\n",
      "642/642 - 0s - 693us/step - loss: 3.4528 - rmse: 1.8361 - val_loss: 2.4929 - val_rmse: 1.5559\n",
      "Epoch 89/100\n",
      "642/642 - 0s - 695us/step - loss: 3.4125 - rmse: 1.8249 - val_loss: 2.6456 - val_rmse: 1.6009\n",
      "Epoch 90/100\n",
      "642/642 - 0s - 694us/step - loss: 3.3841 - rmse: 1.8181 - val_loss: 2.4469 - val_rmse: 1.5410\n",
      "Epoch 91/100\n",
      "642/642 - 0s - 696us/step - loss: 3.4001 - rmse: 1.8197 - val_loss: 2.5009 - val_rmse: 1.5595\n",
      "Epoch 92/100\n",
      "642/642 - 0s - 695us/step - loss: 3.3829 - rmse: 1.8165 - val_loss: 2.5101 - val_rmse: 1.5613\n",
      "Epoch 93/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4241 - rmse: 1.8276 - val_loss: 2.5576 - val_rmse: 1.5749\n",
      "Epoch 94/100\n",
      "642/642 - 0s - 695us/step - loss: 3.3792 - rmse: 1.8153 - val_loss: 2.4601 - val_rmse: 1.5443\n",
      "Epoch 95/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4056 - rmse: 1.8235 - val_loss: 2.4625 - val_rmse: 1.5464\n",
      "Epoch 96/100\n",
      "642/642 - 0s - 694us/step - loss: 3.4134 - rmse: 1.8260 - val_loss: 2.4167 - val_rmse: 1.5306\n",
      "Epoch 97/100\n",
      "642/642 - 0s - 695us/step - loss: 3.3650 - rmse: 1.8125 - val_loss: 2.4746 - val_rmse: 1.5485\n",
      "Epoch 98/100\n",
      "642/642 - 0s - 697us/step - loss: 3.3591 - rmse: 1.8110 - val_loss: 2.5197 - val_rmse: 1.5637\n",
      "Epoch 99/100\n",
      "642/642 - 0s - 695us/step - loss: 3.3412 - rmse: 1.8066 - val_loss: 2.4353 - val_rmse: 1.5390\n",
      "Epoch 100/100\n",
      "642/642 - 0s - 699us/step - loss: 3.3944 - rmse: 1.8207 - val_loss: 2.4784 - val_rmse: 1.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642/642 - 0s - 612us/step - loss: 3.0483 - rmse: 3.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 - 0s - 745us/step - loss: 2.9128 - rmse: 3.9581\n",
      "129/129 - 0s - 875us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 - 0s - 694us/step - loss: 2.9396 - rmse: 3.8885\n",
      "129/129 - 0s - 860us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 - 0s - 677us/step - loss: 3.1033 - rmse: 3.9749\n",
      "129/129 - 0s - 881us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 - 0s - 682us/step - loss: 2.9510 - rmse: 3.8528\n",
      "129/129 - 0s - 868us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 - 0s - 682us/step - loss: 3.1908 - rmse: 3.9328\n",
      "129/129 - 0s - 871us/step\n",
      "00:47:23 - p05 - Predicting -\n",
      "9/9 - 0s - 12ms/step\n",
      "00:47:24 - p05 - Done -\n",
      "00:47:24 - p06 - Predicting for patient p06\n",
      "00:47:24 - p06 - Transforming the data -\n",
      "00:47:24 - p06 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 - 1s - 2ms/step - loss: 46.2089 - rmse: 6.3768 - val_loss: 6.8975 - val_rmse: 2.5897\n",
      "Epoch 2/100\n",
      "585/585 - 0s - 697us/step - loss: 10.4250 - rmse: 3.1870 - val_loss: 5.6151 - val_rmse: 2.3349\n",
      "Epoch 3/100\n",
      "585/585 - 0s - 693us/step - loss: 9.0493 - rmse: 2.9722 - val_loss: 5.4505 - val_rmse: 2.2982\n",
      "Epoch 4/100\n",
      "585/585 - 0s - 693us/step - loss: 8.4411 - rmse: 2.8663 - val_loss: 5.1233 - val_rmse: 2.2289\n",
      "Epoch 5/100\n",
      "585/585 - 0s - 690us/step - loss: 8.0323 - rmse: 2.8001 - val_loss: 5.1870 - val_rmse: 2.2458\n",
      "Epoch 6/100\n",
      "585/585 - 0s - 692us/step - loss: 7.6550 - rmse: 2.7302 - val_loss: 5.0468 - val_rmse: 2.2115\n",
      "Epoch 7/100\n",
      "585/585 - 0s - 689us/step - loss: 7.3673 - rmse: 2.6802 - val_loss: 4.7827 - val_rmse: 2.1557\n",
      "Epoch 8/100\n",
      "585/585 - 0s - 690us/step - loss: 7.3587 - rmse: 2.6714 - val_loss: 4.9569 - val_rmse: 2.1976\n",
      "Epoch 9/100\n",
      "585/585 - 0s - 694us/step - loss: 7.1305 - rmse: 2.6349 - val_loss: 4.7574 - val_rmse: 2.1512\n",
      "Epoch 10/100\n",
      "585/585 - 0s - 691us/step - loss: 7.0909 - rmse: 2.6288 - val_loss: 4.9103 - val_rmse: 2.1895\n",
      "Epoch 11/100\n",
      "585/585 - 0s - 685us/step - loss: 7.1291 - rmse: 2.6330 - val_loss: 4.7054 - val_rmse: 2.1420\n",
      "Epoch 12/100\n",
      "585/585 - 1s - 1ms/step - loss: 6.8470 - rmse: 2.5828 - val_loss: 4.5278 - val_rmse: 2.1006\n",
      "Epoch 13/100\n",
      "585/585 - 0s - 710us/step - loss: 6.9190 - rmse: 2.5915 - val_loss: 4.4996 - val_rmse: 2.0902\n",
      "Epoch 14/100\n",
      "585/585 - 0s - 686us/step - loss: 6.7082 - rmse: 2.5598 - val_loss: 4.6614 - val_rmse: 2.1315\n",
      "Epoch 15/100\n",
      "585/585 - 0s - 692us/step - loss: 6.6963 - rmse: 2.5503 - val_loss: 4.4366 - val_rmse: 2.0779\n",
      "Epoch 16/100\n",
      "585/585 - 0s - 689us/step - loss: 6.5220 - rmse: 2.5224 - val_loss: 4.6239 - val_rmse: 2.1242\n",
      "Epoch 17/100\n",
      "585/585 - 0s - 697us/step - loss: 6.5203 - rmse: 2.5188 - val_loss: 4.5783 - val_rmse: 2.1144\n",
      "Epoch 18/100\n",
      "585/585 - 0s - 687us/step - loss: 6.5310 - rmse: 2.5201 - val_loss: 4.3967 - val_rmse: 2.0728\n",
      "Epoch 19/100\n",
      "585/585 - 0s - 685us/step - loss: 6.5746 - rmse: 2.5256 - val_loss: 4.4692 - val_rmse: 2.0925\n",
      "Epoch 20/100\n",
      "585/585 - 0s - 690us/step - loss: 6.4549 - rmse: 2.5032 - val_loss: 4.3569 - val_rmse: 2.0609\n",
      "Epoch 21/100\n",
      "585/585 - 0s - 691us/step - loss: 6.3161 - rmse: 2.4776 - val_loss: 4.1716 - val_rmse: 2.0168\n",
      "Epoch 22/100\n",
      "585/585 - 0s - 693us/step - loss: 6.4209 - rmse: 2.4964 - val_loss: 4.3146 - val_rmse: 2.0519\n",
      "Epoch 23/100\n",
      "585/585 - 0s - 690us/step - loss: 6.4601 - rmse: 2.5056 - val_loss: 4.2725 - val_rmse: 2.0456\n",
      "Epoch 24/100\n",
      "585/585 - 0s - 688us/step - loss: 6.2645 - rmse: 2.4699 - val_loss: 4.1225 - val_rmse: 2.0051\n",
      "Epoch 25/100\n",
      "585/585 - 0s - 693us/step - loss: 6.1891 - rmse: 2.4523 - val_loss: 4.1990 - val_rmse: 2.0253\n",
      "Epoch 26/100\n",
      "585/585 - 0s - 694us/step - loss: 6.1715 - rmse: 2.4523 - val_loss: 4.1150 - val_rmse: 2.0028\n",
      "Epoch 27/100\n",
      "585/585 - 0s - 693us/step - loss: 6.1270 - rmse: 2.4443 - val_loss: 4.2111 - val_rmse: 2.0290\n",
      "Epoch 28/100\n",
      "585/585 - 0s - 696us/step - loss: 6.0766 - rmse: 2.4277 - val_loss: 4.1030 - val_rmse: 1.9994\n",
      "Epoch 29/100\n",
      "585/585 - 0s - 695us/step - loss: 6.0951 - rmse: 2.4385 - val_loss: 4.0110 - val_rmse: 1.9788\n",
      "Epoch 30/100\n",
      "585/585 - 0s - 694us/step - loss: 6.0407 - rmse: 2.4261 - val_loss: 3.9804 - val_rmse: 1.9729\n",
      "Epoch 31/100\n",
      "585/585 - 0s - 691us/step - loss: 6.1455 - rmse: 2.4448 - val_loss: 4.1431 - val_rmse: 2.0131\n",
      "Epoch 32/100\n",
      "585/585 - 0s - 700us/step - loss: 6.0803 - rmse: 2.4320 - val_loss: 4.0125 - val_rmse: 1.9789\n",
      "Epoch 33/100\n",
      "585/585 - 0s - 692us/step - loss: 5.9207 - rmse: 2.3979 - val_loss: 4.0559 - val_rmse: 1.9917\n",
      "Epoch 34/100\n",
      "585/585 - 0s - 729us/step - loss: 5.9763 - rmse: 2.4099 - val_loss: 4.0186 - val_rmse: 1.9824\n",
      "Epoch 35/100\n",
      "585/585 - 0s - 703us/step - loss: 6.0214 - rmse: 2.4174 - val_loss: 3.9055 - val_rmse: 1.9537\n",
      "Epoch 36/100\n",
      "585/585 - 0s - 694us/step - loss: 5.8398 - rmse: 2.3841 - val_loss: 3.9871 - val_rmse: 1.9760\n",
      "Epoch 37/100\n",
      "585/585 - 0s - 694us/step - loss: 5.7635 - rmse: 2.3659 - val_loss: 3.8687 - val_rmse: 1.9455\n",
      "Epoch 38/100\n",
      "585/585 - 0s - 694us/step - loss: 5.7046 - rmse: 2.3557 - val_loss: 3.9594 - val_rmse: 1.9696\n",
      "Epoch 39/100\n",
      "585/585 - 0s - 695us/step - loss: 5.7063 - rmse: 2.3548 - val_loss: 3.8964 - val_rmse: 1.9509\n",
      "Epoch 40/100\n",
      "585/585 - 0s - 687us/step - loss: 5.6869 - rmse: 2.3523 - val_loss: 3.8394 - val_rmse: 1.9362\n",
      "Epoch 41/100\n",
      "585/585 - 0s - 692us/step - loss: 5.7267 - rmse: 2.3618 - val_loss: 3.8060 - val_rmse: 1.9269\n",
      "Epoch 42/100\n",
      "585/585 - 0s - 692us/step - loss: 5.8161 - rmse: 2.3772 - val_loss: 3.7771 - val_rmse: 1.9211\n",
      "Epoch 43/100\n",
      "585/585 - 0s - 776us/step - loss: 5.7642 - rmse: 2.3681 - val_loss: 4.0123 - val_rmse: 1.9811\n",
      "Epoch 44/100\n",
      "585/585 - 0s - 692us/step - loss: 5.5373 - rmse: 2.3200 - val_loss: 3.7204 - val_rmse: 1.9066\n",
      "Epoch 45/100\n",
      "585/585 - 0s - 692us/step - loss: 5.5853 - rmse: 2.3312 - val_loss: 3.6852 - val_rmse: 1.8964\n",
      "Epoch 46/100\n",
      "585/585 - 0s - 687us/step - loss: 5.4361 - rmse: 2.3025 - val_loss: 3.6892 - val_rmse: 1.8977\n",
      "Epoch 47/100\n",
      "585/585 - 0s - 693us/step - loss: 5.5206 - rmse: 2.3170 - val_loss: 3.7661 - val_rmse: 1.9182\n",
      "Epoch 48/100\n",
      "585/585 - 0s - 694us/step - loss: 5.5831 - rmse: 2.3331 - val_loss: 3.6798 - val_rmse: 1.8939\n",
      "Epoch 49/100\n",
      "585/585 - 0s - 690us/step - loss: 5.4924 - rmse: 2.3129 - val_loss: 3.7908 - val_rmse: 1.9242\n",
      "Epoch 50/100\n",
      "585/585 - 0s - 691us/step - loss: 5.4221 - rmse: 2.2960 - val_loss: 3.7427 - val_rmse: 1.9119\n",
      "Epoch 51/100\n",
      "585/585 - 0s - 688us/step - loss: 5.4526 - rmse: 2.3032 - val_loss: 3.6158 - val_rmse: 1.8743\n",
      "Epoch 52/100\n",
      "585/585 - 0s - 690us/step - loss: 5.4469 - rmse: 2.2997 - val_loss: 3.6282 - val_rmse: 1.8808\n",
      "Epoch 53/100\n",
      "585/585 - 0s - 690us/step - loss: 5.3534 - rmse: 2.2830 - val_loss: 3.6089 - val_rmse: 1.8763\n",
      "Epoch 54/100\n",
      "585/585 - 0s - 692us/step - loss: 5.4390 - rmse: 2.3035 - val_loss: 3.6181 - val_rmse: 1.8790\n",
      "Epoch 55/100\n",
      "585/585 - 0s - 691us/step - loss: 5.4899 - rmse: 2.3136 - val_loss: 3.7319 - val_rmse: 1.9068\n",
      "Epoch 56/100\n",
      "585/585 - 0s - 688us/step - loss: 5.3183 - rmse: 2.2755 - val_loss: 3.7599 - val_rmse: 1.9152\n",
      "Epoch 57/100\n",
      "585/585 - 0s - 687us/step - loss: 5.3020 - rmse: 2.2699 - val_loss: 3.5440 - val_rmse: 1.8595\n",
      "Epoch 58/100\n",
      "585/585 - 0s - 695us/step - loss: 5.3042 - rmse: 2.2712 - val_loss: 3.4885 - val_rmse: 1.8454\n",
      "Epoch 59/100\n",
      "585/585 - 0s - 699us/step - loss: 5.4054 - rmse: 2.2945 - val_loss: 3.5848 - val_rmse: 1.8716\n",
      "Epoch 60/100\n",
      "585/585 - 0s - 688us/step - loss: 5.3372 - rmse: 2.2783 - val_loss: 3.4401 - val_rmse: 1.8305\n",
      "Epoch 61/100\n",
      "585/585 - 0s - 688us/step - loss: 5.3475 - rmse: 2.2798 - val_loss: 3.4404 - val_rmse: 1.8324\n",
      "Epoch 62/100\n",
      "585/585 - 0s - 729us/step - loss: 5.2643 - rmse: 2.2625 - val_loss: 3.5161 - val_rmse: 1.8500\n",
      "Epoch 63/100\n",
      "585/585 - 0s - 693us/step - loss: 5.2239 - rmse: 2.2579 - val_loss: 3.5206 - val_rmse: 1.8547\n",
      "Epoch 64/100\n",
      "585/585 - 1s - 925us/step - loss: 5.2778 - rmse: 2.2622 - val_loss: 3.4728 - val_rmse: 1.8415\n",
      "Epoch 65/100\n",
      "585/585 - 0s - 694us/step - loss: 5.2457 - rmse: 2.2584 - val_loss: 3.4467 - val_rmse: 1.8341\n",
      "Epoch 66/100\n",
      "585/585 - 0s - 692us/step - loss: 5.1091 - rmse: 2.2285 - val_loss: 3.4411 - val_rmse: 1.8334\n",
      "Epoch 67/100\n",
      "585/585 - 0s - 694us/step - loss: 5.2429 - rmse: 2.2549 - val_loss: 3.3673 - val_rmse: 1.8139\n",
      "Epoch 68/100\n",
      "585/585 - 0s - 691us/step - loss: 5.1543 - rmse: 2.2379 - val_loss: 3.3027 - val_rmse: 1.7959\n",
      "Epoch 69/100\n",
      "585/585 - 0s - 694us/step - loss: 5.2074 - rmse: 2.2477 - val_loss: 3.5453 - val_rmse: 1.8608\n",
      "Epoch 70/100\n",
      "585/585 - 0s - 693us/step - loss: 5.1701 - rmse: 2.2427 - val_loss: 3.5285 - val_rmse: 1.8590\n",
      "Epoch 71/100\n",
      "585/585 - 0s - 690us/step - loss: 5.1771 - rmse: 2.2431 - val_loss: 3.4583 - val_rmse: 1.8383\n",
      "Epoch 72/100\n",
      "585/585 - 0s - 691us/step - loss: 5.1719 - rmse: 2.2446 - val_loss: 3.3201 - val_rmse: 1.8000\n",
      "Epoch 73/100\n",
      "585/585 - 0s - 689us/step - loss: 5.0080 - rmse: 2.2075 - val_loss: 3.4506 - val_rmse: 1.8383\n",
      "Epoch 74/100\n",
      "585/585 - 0s - 701us/step - loss: 5.2050 - rmse: 2.2504 - val_loss: 3.3820 - val_rmse: 1.8166\n",
      "Epoch 75/100\n",
      "585/585 - 0s - 697us/step - loss: 5.0215 - rmse: 2.2101 - val_loss: 3.4418 - val_rmse: 1.8350\n",
      "Epoch 76/100\n",
      "585/585 - 0s - 693us/step - loss: 5.1808 - rmse: 2.2416 - val_loss: 3.3599 - val_rmse: 1.8127\n",
      "Epoch 77/100\n",
      "585/585 - 0s - 690us/step - loss: 5.0558 - rmse: 2.2156 - val_loss: 3.3122 - val_rmse: 1.7994\n",
      "Epoch 78/100\n",
      "585/585 - 0s - 688us/step - loss: 5.0678 - rmse: 2.2218 - val_loss: 3.4385 - val_rmse: 1.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 - 0s - 637us/step - loss: 4.4159 - rmse: 5.3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 - 0s - 822us/step - loss: 4.5176 - rmse: 5.5332\n",
      "117/117 - 0s - 943us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 - 1s - 1ms/step - loss: 4.4719 - rmse: 5.4493\n",
      "117/117 - 0s - 931us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 - 0s - 717us/step - loss: 4.2834 - rmse: 5.1046\n",
      "117/117 - 0s - 998us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 - 0s - 712us/step - loss: 4.4244 - rmse: 5.1918\n",
      "117/117 - 0s - 950us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 - 0s - 714us/step - loss: 4.4207 - rmse: 5.4091\n",
      "117/117 - 0s - 950us/step\n",
      "00:49:23 - p06 - Predicting -\n",
      "8/8 - 0s - 11ms/step\n",
      "00:49:23 - p06 - Done -\n",
      "00:49:23 - p10 - Predicting for patient p10\n",
      "00:49:23 - p10 - Transforming the data -\n",
      "00:49:23 - p10 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061/1061 - 2s - 2ms/step - loss: 13.2283 - rmse: 3.2532 - val_loss: 2.4572 - val_rmse: 1.5468\n",
      "Epoch 2/100\n",
      "1061/1061 - 1s - 683us/step - loss: 3.5485 - rmse: 1.8605 - val_loss: 2.2874 - val_rmse: 1.4914\n",
      "Epoch 3/100\n",
      "1061/1061 - 1s - 675us/step - loss: 3.0754 - rmse: 1.7309 - val_loss: 2.2132 - val_rmse: 1.4657\n",
      "Epoch 4/100\n",
      "1061/1061 - 1s - 676us/step - loss: 2.8544 - rmse: 1.6679 - val_loss: 2.1753 - val_rmse: 1.4523\n",
      "Epoch 5/100\n",
      "1061/1061 - 1s - 676us/step - loss: 2.7619 - rmse: 1.6382 - val_loss: 2.1363 - val_rmse: 1.4387\n",
      "Epoch 6/100\n",
      "1061/1061 - 1s - 672us/step - loss: 2.6914 - rmse: 1.6166 - val_loss: 2.1546 - val_rmse: 1.4430\n",
      "Epoch 7/100\n",
      "1061/1061 - 1s - 672us/step - loss: 2.6148 - rmse: 1.5946 - val_loss: 2.0892 - val_rmse: 1.4225\n",
      "Epoch 8/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.5649 - rmse: 1.5804 - val_loss: 2.0883 - val_rmse: 1.4221\n",
      "Epoch 9/100\n",
      "1061/1061 - 1s - 677us/step - loss: 2.5027 - rmse: 1.5597 - val_loss: 2.0408 - val_rmse: 1.4069\n",
      "Epoch 10/100\n",
      "1061/1061 - 1s - 674us/step - loss: 2.4730 - rmse: 1.5517 - val_loss: 2.0026 - val_rmse: 1.3939\n",
      "Epoch 11/100\n",
      "1061/1061 - 1s - 674us/step - loss: 2.4215 - rmse: 1.5337 - val_loss: 1.9930 - val_rmse: 1.3900\n",
      "Epoch 12/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.3881 - rmse: 1.5245 - val_loss: 1.9761 - val_rmse: 1.3846\n",
      "Epoch 13/100\n",
      "1061/1061 - 1s - 674us/step - loss: 2.3426 - rmse: 1.5089 - val_loss: 1.9477 - val_rmse: 1.3756\n",
      "Epoch 14/100\n",
      "1061/1061 - 1s - 678us/step - loss: 2.3255 - rmse: 1.5031 - val_loss: 1.9164 - val_rmse: 1.3650\n",
      "Epoch 15/100\n",
      "1061/1061 - 1s - 671us/step - loss: 2.2973 - rmse: 1.4945 - val_loss: 1.9717 - val_rmse: 1.3818\n",
      "Epoch 16/100\n",
      "1061/1061 - 1s - 677us/step - loss: 2.2914 - rmse: 1.4917 - val_loss: 1.9317 - val_rmse: 1.3691\n",
      "Epoch 17/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.2453 - rmse: 1.4754 - val_loss: 1.9051 - val_rmse: 1.3588\n",
      "Epoch 18/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.2308 - rmse: 1.4717 - val_loss: 1.8823 - val_rmse: 1.3510\n",
      "Epoch 19/100\n",
      "1061/1061 - 1s - 676us/step - loss: 2.2021 - rmse: 1.4623 - val_loss: 1.8745 - val_rmse: 1.3502\n",
      "Epoch 20/100\n",
      "1061/1061 - 1s - 677us/step - loss: 2.1797 - rmse: 1.4553 - val_loss: 1.8710 - val_rmse: 1.3469\n",
      "Epoch 21/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.1566 - rmse: 1.4462 - val_loss: 1.8306 - val_rmse: 1.3330\n",
      "Epoch 22/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.1588 - rmse: 1.4480 - val_loss: 1.8294 - val_rmse: 1.3321\n",
      "Epoch 23/100\n",
      "1061/1061 - 1s - 673us/step - loss: 2.1353 - rmse: 1.4397 - val_loss: 1.8135 - val_rmse: 1.3275\n",
      "Epoch 24/100\n",
      "1061/1061 - 1s - 686us/step - loss: 2.1165 - rmse: 1.4336 - val_loss: 1.8086 - val_rmse: 1.3254\n",
      "Epoch 25/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.1050 - rmse: 1.4294 - val_loss: 1.7944 - val_rmse: 1.3196\n",
      "Epoch 26/100\n",
      "1061/1061 - 1s - 677us/step - loss: 2.0908 - rmse: 1.4248 - val_loss: 1.8373 - val_rmse: 1.3344\n",
      "Epoch 27/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.0656 - rmse: 1.4159 - val_loss: 1.7724 - val_rmse: 1.3117\n",
      "Epoch 28/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.0505 - rmse: 1.4094 - val_loss: 1.7935 - val_rmse: 1.3184\n",
      "Epoch 29/100\n",
      "1061/1061 - 1s - 676us/step - loss: 2.0357 - rmse: 1.4061 - val_loss: 1.7652 - val_rmse: 1.3091\n",
      "Epoch 30/100\n",
      "1061/1061 - 1s - 671us/step - loss: 2.0405 - rmse: 1.4089 - val_loss: 1.7467 - val_rmse: 1.3020\n",
      "Epoch 31/100\n",
      "1061/1061 - 1s - 671us/step - loss: 2.0142 - rmse: 1.3991 - val_loss: 1.7489 - val_rmse: 1.3025\n",
      "Epoch 32/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.9974 - rmse: 1.3935 - val_loss: 1.7484 - val_rmse: 1.3028\n",
      "Epoch 33/100\n",
      "1061/1061 - 1s - 676us/step - loss: 2.0051 - rmse: 1.3965 - val_loss: 1.7398 - val_rmse: 1.2994\n",
      "Epoch 34/100\n",
      "1061/1061 - 1s - 675us/step - loss: 2.0000 - rmse: 1.3922 - val_loss: 1.7206 - val_rmse: 1.2923\n",
      "Epoch 35/100\n",
      "1061/1061 - 1s - 674us/step - loss: 1.9830 - rmse: 1.3898 - val_loss: 1.7124 - val_rmse: 1.2894\n",
      "Epoch 36/100\n",
      "1061/1061 - 1s - 678us/step - loss: 1.9982 - rmse: 1.3920 - val_loss: 1.6990 - val_rmse: 1.2844\n",
      "Epoch 37/100\n",
      "1061/1061 - 1s - 693us/step - loss: 1.9738 - rmse: 1.3841 - val_loss: 1.7020 - val_rmse: 1.2856\n",
      "Epoch 38/100\n",
      "1061/1061 - 1s - 672us/step - loss: 1.9644 - rmse: 1.3791 - val_loss: 1.6959 - val_rmse: 1.2842\n",
      "Epoch 39/100\n",
      "1061/1061 - 1s - 672us/step - loss: 1.9670 - rmse: 1.3819 - val_loss: 1.7025 - val_rmse: 1.2841\n",
      "Epoch 40/100\n",
      "1061/1061 - 1s - 667us/step - loss: 1.9560 - rmse: 1.3795 - val_loss: 1.6964 - val_rmse: 1.2818\n",
      "Epoch 41/100\n",
      "1061/1061 - 1s - 674us/step - loss: 1.9412 - rmse: 1.3742 - val_loss: 1.6674 - val_rmse: 1.2706\n",
      "Epoch 42/100\n",
      "1061/1061 - 1s - 672us/step - loss: 1.9435 - rmse: 1.3741 - val_loss: 1.6722 - val_rmse: 1.2730\n",
      "Epoch 43/100\n",
      "1061/1061 - 1s - 670us/step - loss: 1.9372 - rmse: 1.3725 - val_loss: 1.6386 - val_rmse: 1.2617\n",
      "Epoch 44/100\n",
      "1061/1061 - 1s - 672us/step - loss: 1.9205 - rmse: 1.3664 - val_loss: 1.6431 - val_rmse: 1.2628\n",
      "Epoch 45/100\n",
      "1061/1061 - 1s - 693us/step - loss: 1.9347 - rmse: 1.3717 - val_loss: 1.6626 - val_rmse: 1.2690\n",
      "Epoch 46/100\n",
      "1061/1061 - 1s - 674us/step - loss: 1.9242 - rmse: 1.3684 - val_loss: 1.6549 - val_rmse: 1.2671\n",
      "Epoch 47/100\n",
      "1061/1061 - 1s - 673us/step - loss: 1.9183 - rmse: 1.3648 - val_loss: 1.6277 - val_rmse: 1.2578\n",
      "Epoch 48/100\n",
      "1061/1061 - 1s - 671us/step - loss: 1.9183 - rmse: 1.3647 - val_loss: 1.6248 - val_rmse: 1.2562\n",
      "Epoch 49/100\n",
      "1061/1061 - 1s - 681us/step - loss: 1.8954 - rmse: 1.3547 - val_loss: 1.6234 - val_rmse: 1.2559\n",
      "Epoch 50/100\n",
      "1061/1061 - 1s - 673us/step - loss: 1.8986 - rmse: 1.3587 - val_loss: 1.6537 - val_rmse: 1.2665\n",
      "Epoch 51/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8901 - rmse: 1.3563 - val_loss: 1.5784 - val_rmse: 1.2392\n",
      "Epoch 52/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8867 - rmse: 1.3545 - val_loss: 1.5903 - val_rmse: 1.2437\n",
      "Epoch 53/100\n",
      "1061/1061 - 1s - 688us/step - loss: 1.8839 - rmse: 1.3537 - val_loss: 1.6066 - val_rmse: 1.2483\n",
      "Epoch 54/100\n",
      "1061/1061 - 1s - 675us/step - loss: 1.8890 - rmse: 1.3557 - val_loss: 1.5896 - val_rmse: 1.2430\n",
      "Epoch 55/100\n",
      "1061/1061 - 1s - 674us/step - loss: 1.8688 - rmse: 1.3486 - val_loss: 1.5933 - val_rmse: 1.2440\n",
      "Epoch 56/100\n",
      "1061/1061 - 1s - 673us/step - loss: 1.8709 - rmse: 1.3481 - val_loss: 1.5740 - val_rmse: 1.2364\n",
      "Epoch 57/100\n",
      "1061/1061 - 1s - 678us/step - loss: 1.8656 - rmse: 1.3472 - val_loss: 1.5909 - val_rmse: 1.2415\n",
      "Epoch 58/100\n",
      "1061/1061 - 1s - 675us/step - loss: 1.8680 - rmse: 1.3468 - val_loss: 1.5929 - val_rmse: 1.2431\n",
      "Epoch 59/100\n",
      "1061/1061 - 1s - 690us/step - loss: 1.8700 - rmse: 1.3488 - val_loss: 1.5808 - val_rmse: 1.2373\n",
      "Epoch 60/100\n",
      "1061/1061 - 1s - 678us/step - loss: 1.8622 - rmse: 1.3461 - val_loss: 1.5600 - val_rmse: 1.2307\n",
      "Epoch 61/100\n",
      "1061/1061 - 1s - 675us/step - loss: 1.8709 - rmse: 1.3484 - val_loss: 1.5849 - val_rmse: 1.2397\n",
      "Epoch 62/100\n",
      "1061/1061 - 1s - 680us/step - loss: 1.8616 - rmse: 1.3447 - val_loss: 1.5423 - val_rmse: 1.2242\n",
      "Epoch 63/100\n",
      "1061/1061 - 1s - 676us/step - loss: 1.8692 - rmse: 1.3477 - val_loss: 1.5558 - val_rmse: 1.2294\n",
      "Epoch 64/100\n",
      "1061/1061 - 1s - 676us/step - loss: 1.8595 - rmse: 1.3445 - val_loss: 1.5558 - val_rmse: 1.2289\n",
      "Epoch 65/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8432 - rmse: 1.3386 - val_loss: 1.5790 - val_rmse: 1.2377\n",
      "Epoch 66/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8433 - rmse: 1.3387 - val_loss: 1.5477 - val_rmse: 1.2249\n",
      "Epoch 67/100\n",
      "1061/1061 - 1s - 686us/step - loss: 1.8501 - rmse: 1.3399 - val_loss: 1.5452 - val_rmse: 1.2239\n",
      "Epoch 68/100\n",
      "1061/1061 - 1s - 675us/step - loss: 1.8381 - rmse: 1.3368 - val_loss: 1.5608 - val_rmse: 1.2300\n",
      "Epoch 69/100\n",
      "1061/1061 - 1s - 675us/step - loss: 1.8267 - rmse: 1.3326 - val_loss: 1.5588 - val_rmse: 1.2295\n",
      "Epoch 70/100\n",
      "1061/1061 - 1s - 678us/step - loss: 1.8456 - rmse: 1.3392 - val_loss: 1.5373 - val_rmse: 1.2214\n",
      "Epoch 71/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8370 - rmse: 1.3370 - val_loss: 1.5396 - val_rmse: 1.2220\n",
      "Epoch 72/100\n",
      "1061/1061 - 1s - 677us/step - loss: 1.8254 - rmse: 1.3319 - val_loss: 1.5124 - val_rmse: 1.2124\n",
      "Epoch 73/100\n",
      "1061/1061 - 1s - 688us/step - loss: 1.8266 - rmse: 1.3317 - val_loss: 1.5286 - val_rmse: 1.2180\n",
      "Epoch 74/100\n",
      "1061/1061 - 1s - 680us/step - loss: 1.8368 - rmse: 1.3367 - val_loss: 1.5208 - val_rmse: 1.2147\n",
      "Epoch 75/100\n",
      "1061/1061 - 1s - 686us/step - loss: 1.8180 - rmse: 1.3295 - val_loss: 1.5013 - val_rmse: 1.2078\n",
      "Epoch 76/100\n",
      "1061/1061 - 1s - 681us/step - loss: 1.8242 - rmse: 1.3323 - val_loss: 1.5134 - val_rmse: 1.2116\n",
      "Epoch 77/100\n",
      "1061/1061 - 1s - 679us/step - loss: 1.8127 - rmse: 1.3260 - val_loss: 1.4749 - val_rmse: 1.1971\n",
      "Epoch 78/100\n",
      "1061/1061 - 1s - 693us/step - loss: 1.8315 - rmse: 1.3342 - val_loss: 1.5091 - val_rmse: 1.2097\n",
      "Epoch 79/100\n",
      "1061/1061 - 1s - 681us/step - loss: 1.8174 - rmse: 1.3282 - val_loss: 1.5201 - val_rmse: 1.2135\n",
      "Epoch 80/100\n",
      "1061/1061 - 1s - 678us/step - loss: 1.8151 - rmse: 1.3279 - val_loss: 1.5133 - val_rmse: 1.2125\n",
      "Epoch 81/100\n",
      "1061/1061 - 1s - 672us/step - loss: 1.8137 - rmse: 1.3277 - val_loss: 1.4815 - val_rmse: 1.1998\n",
      "Epoch 82/100\n",
      "1061/1061 - 1s - 683us/step - loss: 1.7891 - rmse: 1.3194 - val_loss: 1.4924 - val_rmse: 1.2039\n",
      "Epoch 83/100\n",
      "1061/1061 - 1s - 679us/step - loss: 1.8218 - rmse: 1.3306 - val_loss: 1.4997 - val_rmse: 1.2059\n",
      "Epoch 84/100\n",
      "1061/1061 - 1s - 681us/step - loss: 1.7997 - rmse: 1.3238 - val_loss: 1.4961 - val_rmse: 1.2045\n",
      "Epoch 85/100\n",
      "1061/1061 - 1s - 679us/step - loss: 1.7977 - rmse: 1.3223 - val_loss: 1.5054 - val_rmse: 1.2087\n",
      "Epoch 86/100\n",
      "1061/1061 - 1s - 680us/step - loss: 1.7914 - rmse: 1.3201 - val_loss: 1.4817 - val_rmse: 1.1987\n",
      "Epoch 87/100\n",
      "1061/1061 - 1s - 680us/step - loss: 1.8119 - rmse: 1.3275 - val_loss: 1.4893 - val_rmse: 1.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061/1061 - 1s - 511us/step - loss: 1.6978 - rmse: 2.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 - 0s - 578us/step - loss: 1.8399 - rmse: 2.1007\n",
      "213/213 - 0s - 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 - 0s - 541us/step - loss: 1.7410 - rmse: 2.0912\n",
      "213/213 - 0s - 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 - 0s - 541us/step - loss: 1.7590 - rmse: 2.0907\n",
      "213/213 - 0s - 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 - 0s - 541us/step - loss: 1.6458 - rmse: 1.9772\n",
      "213/213 - 0s - 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849/849 - 0s - 542us/step - loss: 1.5393 - rmse: 1.9038\n",
      "213/213 - 0s - 641us/step\n",
      "00:52:50 - p10 - Predicting -\n",
      "6/6 - 0s - 15ms/step\n",
      "00:52:50 - p10 - Done -\n",
      "00:52:50 - p11 - Predicting for patient p11\n",
      "00:52:50 - p11 - Transforming the data -\n",
      "00:52:50 - p11 - Fitting the model -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1094 - 2s - 2ms/step - loss: 26.4577 - rmse: 4.5938 - val_loss: 4.6296 - val_rmse: 2.1306\n",
      "Epoch 2/100\n",
      "1094/1094 - 1s - 671us/step - loss: 6.9198 - rmse: 2.6048 - val_loss: 4.1708 - val_rmse: 2.0231\n",
      "Epoch 3/100\n",
      "1094/1094 - 1s - 673us/step - loss: 6.0115 - rmse: 2.4263 - val_loss: 4.0868 - val_rmse: 2.0033\n",
      "Epoch 4/100\n",
      "1094/1094 - 1s - 669us/step - loss: 5.6183 - rmse: 2.3468 - val_loss: 3.9274 - val_rmse: 1.9627\n",
      "Epoch 5/100\n",
      "1094/1094 - 1s - 674us/step - loss: 5.3377 - rmse: 2.2853 - val_loss: 3.9021 - val_rmse: 1.9564\n",
      "Epoch 6/100\n",
      "1094/1094 - 1s - 673us/step - loss: 5.2257 - rmse: 2.2624 - val_loss: 3.8308 - val_rmse: 1.9386\n",
      "Epoch 7/100\n",
      "1094/1094 - 1s - 670us/step - loss: 5.0892 - rmse: 2.2332 - val_loss: 3.8040 - val_rmse: 1.9311\n",
      "Epoch 8/100\n",
      "1094/1094 - 1s - 673us/step - loss: 5.0096 - rmse: 2.2167 - val_loss: 3.7001 - val_rmse: 1.9041\n",
      "Epoch 9/100\n",
      "1094/1094 - 1s - 674us/step - loss: 4.9132 - rmse: 2.1923 - val_loss: 3.7342 - val_rmse: 1.9127\n",
      "Epoch 10/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.8665 - rmse: 2.1818 - val_loss: 3.6975 - val_rmse: 1.9040\n",
      "Epoch 11/100\n",
      "1094/1094 - 1s - 676us/step - loss: 4.7972 - rmse: 2.1653 - val_loss: 3.6322 - val_rmse: 1.8863\n",
      "Epoch 12/100\n",
      "1094/1094 - 1s - 675us/step - loss: 4.6744 - rmse: 2.1395 - val_loss: 3.5643 - val_rmse: 1.8682\n",
      "Epoch 13/100\n",
      "1094/1094 - 1s - 673us/step - loss: 4.6053 - rmse: 2.1214 - val_loss: 3.5283 - val_rmse: 1.8598\n",
      "Epoch 14/100\n",
      "1094/1094 - 1s - 673us/step - loss: 4.5904 - rmse: 2.1215 - val_loss: 3.4855 - val_rmse: 1.8482\n",
      "Epoch 15/100\n",
      "1094/1094 - 1s - 668us/step - loss: 4.5562 - rmse: 2.1094 - val_loss: 3.5039 - val_rmse: 1.8535\n",
      "Epoch 16/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.5096 - rmse: 2.1015 - val_loss: 3.4679 - val_rmse: 1.8431\n",
      "Epoch 17/100\n",
      "1094/1094 - 1s - 669us/step - loss: 4.4431 - rmse: 2.0833 - val_loss: 3.4423 - val_rmse: 1.8361\n",
      "Epoch 18/100\n",
      "1094/1094 - 1s - 675us/step - loss: 4.4215 - rmse: 2.0792 - val_loss: 3.3946 - val_rmse: 1.8241\n",
      "Epoch 19/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.3779 - rmse: 2.0705 - val_loss: 3.4172 - val_rmse: 1.8298\n",
      "Epoch 20/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.3294 - rmse: 2.0583 - val_loss: 3.3562 - val_rmse: 1.8124\n",
      "Epoch 21/100\n",
      "1094/1094 - 1s - 669us/step - loss: 4.2988 - rmse: 2.0513 - val_loss: 3.3953 - val_rmse: 1.8240\n",
      "Epoch 22/100\n",
      "1094/1094 - 1s - 673us/step - loss: 4.2529 - rmse: 2.0386 - val_loss: 3.3133 - val_rmse: 1.8015\n",
      "Epoch 23/100\n",
      "1094/1094 - 1s - 670us/step - loss: 4.1821 - rmse: 2.0235 - val_loss: 3.3537 - val_rmse: 1.8129\n",
      "Epoch 24/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.1946 - rmse: 2.0235 - val_loss: 3.3303 - val_rmse: 1.8064\n",
      "Epoch 25/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.1235 - rmse: 2.0097 - val_loss: 3.3461 - val_rmse: 1.8103\n",
      "Epoch 26/100\n",
      "1094/1094 - 1s - 671us/step - loss: 4.1674 - rmse: 2.0179 - val_loss: 3.3112 - val_rmse: 1.8010\n",
      "Epoch 27/100\n",
      "1094/1094 - 1s - 667us/step - loss: 4.1018 - rmse: 2.0018 - val_loss: 3.2982 - val_rmse: 1.7977\n",
      "Epoch 28/100\n",
      "1094/1094 - 1s - 683us/step - loss: 4.0962 - rmse: 2.0005 - val_loss: 3.2409 - val_rmse: 1.7817\n",
      "Epoch 29/100\n",
      "1094/1094 - 1s - 684us/step - loss: 4.1066 - rmse: 2.0041 - val_loss: 3.2269 - val_rmse: 1.7775\n",
      "Epoch 30/100\n",
      "1094/1094 - 1s - 676us/step - loss: 4.0200 - rmse: 1.9846 - val_loss: 3.2665 - val_rmse: 1.7879\n",
      "Epoch 31/100\n",
      "1094/1094 - 1s - 672us/step - loss: 4.0191 - rmse: 1.9850 - val_loss: 3.2883 - val_rmse: 1.7936\n",
      "Epoch 32/100\n",
      "1094/1094 - 1s - 680us/step - loss: 3.9848 - rmse: 1.9751 - val_loss: 3.2419 - val_rmse: 1.7819\n",
      "Epoch 33/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.9579 - rmse: 1.9654 - val_loss: 3.2036 - val_rmse: 1.7709\n",
      "Epoch 34/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.9553 - rmse: 1.9648 - val_loss: 3.2127 - val_rmse: 1.7738\n",
      "Epoch 35/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.9319 - rmse: 1.9602 - val_loss: 3.1510 - val_rmse: 1.7562\n",
      "Epoch 36/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.9118 - rmse: 1.9573 - val_loss: 3.1406 - val_rmse: 1.7536\n",
      "Epoch 37/100\n",
      "1094/1094 - 1s - 677us/step - loss: 3.8554 - rmse: 1.9401 - val_loss: 3.1091 - val_rmse: 1.7449\n",
      "Epoch 38/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.8562 - rmse: 1.9433 - val_loss: 3.1731 - val_rmse: 1.7629\n",
      "Epoch 39/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.8157 - rmse: 1.9329 - val_loss: 3.1110 - val_rmse: 1.7450\n",
      "Epoch 40/100\n",
      "1094/1094 - 1s - 702us/step - loss: 3.8636 - rmse: 1.9445 - val_loss: 3.1262 - val_rmse: 1.7487\n",
      "Epoch 41/100\n",
      "1094/1094 - 1s - 680us/step - loss: 3.8229 - rmse: 1.9332 - val_loss: 3.0895 - val_rmse: 1.7382\n",
      "Epoch 42/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.8058 - rmse: 1.9301 - val_loss: 3.0934 - val_rmse: 1.7403\n",
      "Epoch 43/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.7861 - rmse: 1.9223 - val_loss: 3.1020 - val_rmse: 1.7422\n",
      "Epoch 44/100\n",
      "1094/1094 - 1s - 678us/step - loss: 3.8043 - rmse: 1.9298 - val_loss: 3.0973 - val_rmse: 1.7415\n",
      "Epoch 45/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.7884 - rmse: 1.9234 - val_loss: 3.0595 - val_rmse: 1.7313\n",
      "Epoch 46/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.7655 - rmse: 1.9178 - val_loss: 3.0595 - val_rmse: 1.7312\n",
      "Epoch 47/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.7512 - rmse: 1.9143 - val_loss: 3.0796 - val_rmse: 1.7365\n",
      "Epoch 48/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.7230 - rmse: 1.9062 - val_loss: 3.0368 - val_rmse: 1.7237\n",
      "Epoch 49/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.7325 - rmse: 1.9112 - val_loss: 3.0316 - val_rmse: 1.7233\n",
      "Epoch 50/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.7028 - rmse: 1.9014 - val_loss: 3.0060 - val_rmse: 1.7156\n",
      "Epoch 51/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.7006 - rmse: 1.9012 - val_loss: 3.0391 - val_rmse: 1.7250\n",
      "Epoch 52/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.7113 - rmse: 1.9038 - val_loss: 3.0141 - val_rmse: 1.7177\n",
      "Epoch 53/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.6740 - rmse: 1.8968 - val_loss: 2.9766 - val_rmse: 1.7062\n",
      "Epoch 54/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.6685 - rmse: 1.8955 - val_loss: 2.9572 - val_rmse: 1.7009\n",
      "Epoch 55/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.6465 - rmse: 1.8874 - val_loss: 3.0026 - val_rmse: 1.7137\n",
      "Epoch 56/100\n",
      "1094/1094 - 1s - 677us/step - loss: 3.6687 - rmse: 1.8934 - val_loss: 2.9781 - val_rmse: 1.7064\n",
      "Epoch 57/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.6319 - rmse: 1.8849 - val_loss: 2.9455 - val_rmse: 1.6977\n",
      "Epoch 58/100\n",
      "1094/1094 - 1s - 670us/step - loss: 3.6588 - rmse: 1.8926 - val_loss: 3.0063 - val_rmse: 1.7150\n",
      "Epoch 59/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.6404 - rmse: 1.8876 - val_loss: 3.0067 - val_rmse: 1.7162\n",
      "Epoch 60/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5925 - rmse: 1.8746 - val_loss: 2.9507 - val_rmse: 1.6996\n",
      "Epoch 61/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.6236 - rmse: 1.8829 - val_loss: 2.9751 - val_rmse: 1.7069\n",
      "Epoch 62/100\n",
      "1094/1094 - 1s - 670us/step - loss: 3.5970 - rmse: 1.8753 - val_loss: 2.8946 - val_rmse: 1.6829\n",
      "Epoch 63/100\n",
      "1094/1094 - 1s - 682us/step - loss: 3.5821 - rmse: 1.8715 - val_loss: 2.9172 - val_rmse: 1.6896\n",
      "Epoch 64/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.6192 - rmse: 1.8838 - val_loss: 2.9377 - val_rmse: 1.6960\n",
      "Epoch 65/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.6046 - rmse: 1.8761 - val_loss: 2.9709 - val_rmse: 1.7058\n",
      "Epoch 66/100\n",
      "1094/1094 - 1s - 677us/step - loss: 3.5610 - rmse: 1.8677 - val_loss: 2.8907 - val_rmse: 1.6807\n",
      "Epoch 67/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5595 - rmse: 1.8637 - val_loss: 2.9378 - val_rmse: 1.6948\n",
      "Epoch 68/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.5710 - rmse: 1.8671 - val_loss: 2.9341 - val_rmse: 1.6946\n",
      "Epoch 69/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.5873 - rmse: 1.8752 - val_loss: 2.9745 - val_rmse: 1.7060\n",
      "Epoch 70/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.5478 - rmse: 1.8632 - val_loss: 2.8697 - val_rmse: 1.6751\n",
      "Epoch 71/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5605 - rmse: 1.8661 - val_loss: 2.9064 - val_rmse: 1.6874\n",
      "Epoch 72/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.5480 - rmse: 1.8636 - val_loss: 2.9177 - val_rmse: 1.6905\n",
      "Epoch 73/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5182 - rmse: 1.8563 - val_loss: 2.9750 - val_rmse: 1.7072\n",
      "Epoch 74/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5482 - rmse: 1.8617 - val_loss: 2.8890 - val_rmse: 1.6819\n",
      "Epoch 75/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5260 - rmse: 1.8566 - val_loss: 2.8860 - val_rmse: 1.6806\n",
      "Epoch 76/100\n",
      "1094/1094 - 1s - 672us/step - loss: 3.4995 - rmse: 1.8511 - val_loss: 2.8527 - val_rmse: 1.6702\n",
      "Epoch 77/100\n",
      "1094/1094 - 1s - 681us/step - loss: 3.5167 - rmse: 1.8558 - val_loss: 2.8611 - val_rmse: 1.6724\n",
      "Epoch 78/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.5232 - rmse: 1.8562 - val_loss: 2.8317 - val_rmse: 1.6643\n",
      "Epoch 79/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.5306 - rmse: 1.8577 - val_loss: 2.8082 - val_rmse: 1.6575\n",
      "Epoch 80/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.4971 - rmse: 1.8485 - val_loss: 2.8052 - val_rmse: 1.6569\n",
      "Epoch 81/100\n",
      "1094/1094 - 1s - 685us/step - loss: 3.5099 - rmse: 1.8526 - val_loss: 2.8484 - val_rmse: 1.6692\n",
      "Epoch 82/100\n",
      "1094/1094 - 1s - 678us/step - loss: 3.5083 - rmse: 1.8513 - val_loss: 2.8843 - val_rmse: 1.6806\n",
      "Epoch 83/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.4819 - rmse: 1.8453 - val_loss: 2.8340 - val_rmse: 1.6658\n",
      "Epoch 84/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.4989 - rmse: 1.8505 - val_loss: 2.8932 - val_rmse: 1.6830\n",
      "Epoch 85/100\n",
      "1094/1094 - 1s - 671us/step - loss: 3.5239 - rmse: 1.8562 - val_loss: 2.8373 - val_rmse: 1.6668\n",
      "Epoch 86/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.5090 - rmse: 1.8519 - val_loss: 2.8027 - val_rmse: 1.6559\n",
      "Epoch 87/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.5041 - rmse: 1.8496 - val_loss: 2.7890 - val_rmse: 1.6520\n",
      "Epoch 88/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.4742 - rmse: 1.8419 - val_loss: 2.8362 - val_rmse: 1.6660\n",
      "Epoch 89/100\n",
      "1094/1094 - 1s - 673us/step - loss: 3.5112 - rmse: 1.8533 - val_loss: 2.8436 - val_rmse: 1.6685\n",
      "Epoch 90/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.4993 - rmse: 1.8507 - val_loss: 2.8612 - val_rmse: 1.6741\n",
      "Epoch 91/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.4680 - rmse: 1.8436 - val_loss: 2.7656 - val_rmse: 1.6448\n",
      "Epoch 92/100\n",
      "1094/1094 - 1s - 670us/step - loss: 3.4651 - rmse: 1.8409 - val_loss: 2.8336 - val_rmse: 1.6664\n",
      "Epoch 93/100\n",
      "1094/1094 - 1s - 671us/step - loss: 3.4715 - rmse: 1.8423 - val_loss: 2.7972 - val_rmse: 1.6544\n",
      "Epoch 94/100\n",
      "1094/1094 - 1s - 674us/step - loss: 3.4531 - rmse: 1.8394 - val_loss: 2.8188 - val_rmse: 1.6617\n",
      "Epoch 95/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.4879 - rmse: 1.8484 - val_loss: 2.8087 - val_rmse: 1.6589\n",
      "Epoch 96/100\n",
      "1094/1094 - 1s - 670us/step - loss: 3.4686 - rmse: 1.8399 - val_loss: 2.8502 - val_rmse: 1.6716\n",
      "Epoch 97/100\n",
      "1094/1094 - 1s - 677us/step - loss: 3.4443 - rmse: 1.8339 - val_loss: 2.7953 - val_rmse: 1.6547\n",
      "Epoch 98/100\n",
      "1094/1094 - 1s - 676us/step - loss: 3.4347 - rmse: 1.8338 - val_loss: 2.7643 - val_rmse: 1.6445\n",
      "Epoch 99/100\n",
      "1094/1094 - 1s - 704us/step - loss: 3.4663 - rmse: 1.8409 - val_loss: 2.7286 - val_rmse: 1.6343\n",
      "Epoch 100/100\n",
      "1094/1094 - 1s - 675us/step - loss: 3.4245 - rmse: 1.8291 - val_loss: 2.8329 - val_rmse: 1.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 - 1s - 500us/step - loss: 3.1701 - rmse: 3.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 - 1s - 574us/step - loss: 3.2557 - rmse: 3.4805\n",
      "219/219 - 0s - 642us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 - 0s - 539us/step - loss: 3.0308 - rmse: 3.3875\n",
      "219/219 - 0s - 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 - 0s - 537us/step - loss: 3.1349 - rmse: 3.3648\n",
      "219/219 - 0s - 642us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 - 0s - 536us/step - loss: 3.1919 - rmse: 3.4550\n",
      "219/219 - 0s - 634us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 - 0s - 534us/step - loss: 3.2664 - rmse: 3.5159\n",
      "219/219 - 0s - 2ms/step\n",
      "00:56:35 - p11 - Predicting -\n",
      "7/7 - 0s - 17ms/step\n",
      "00:56:36 - p11 - Done -\n",
      "00:56:36 - p12 - Predicting for patient p12\n",
      "00:56:36 - p12 - Transforming the data -\n",
      "00:56:36 - p12 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213/1213 - 2s - 2ms/step - loss: 19.1841 - rmse: 3.8842 - val_loss: 3.0917 - val_rmse: 1.7349\n",
      "Epoch 2/100\n",
      "1213/1213 - 1s - 675us/step - loss: 5.2041 - rmse: 2.2510 - val_loss: 2.8614 - val_rmse: 1.6713\n",
      "Epoch 3/100\n",
      "1213/1213 - 1s - 671us/step - loss: 4.6715 - rmse: 2.1317 - val_loss: 2.8541 - val_rmse: 1.6700\n",
      "Epoch 4/100\n",
      "1213/1213 - 1s - 672us/step - loss: 4.3557 - rmse: 2.0582 - val_loss: 2.9200 - val_rmse: 1.6884\n",
      "Epoch 5/100\n",
      "1213/1213 - 1s - 671us/step - loss: 4.2571 - rmse: 2.0333 - val_loss: 2.6011 - val_rmse: 1.5940\n",
      "Epoch 6/100\n",
      "1213/1213 - 1s - 669us/step - loss: 4.1029 - rmse: 1.9978 - val_loss: 2.6442 - val_rmse: 1.6080\n",
      "Epoch 7/100\n",
      "1213/1213 - 1s - 673us/step - loss: 4.0572 - rmse: 1.9891 - val_loss: 2.5632 - val_rmse: 1.5827\n",
      "Epoch 8/100\n",
      "1213/1213 - 1s - 673us/step - loss: 3.9185 - rmse: 1.9518 - val_loss: 2.5716 - val_rmse: 1.5848\n",
      "Epoch 9/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.8590 - rmse: 1.9372 - val_loss: 2.4971 - val_rmse: 1.5608\n",
      "Epoch 10/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.7659 - rmse: 1.9147 - val_loss: 2.4744 - val_rmse: 1.5548\n",
      "Epoch 11/100\n",
      "1213/1213 - 1s - 671us/step - loss: 3.6898 - rmse: 1.8952 - val_loss: 2.5179 - val_rmse: 1.5690\n",
      "Epoch 12/100\n",
      "1213/1213 - 1s - 671us/step - loss: 3.6778 - rmse: 1.8905 - val_loss: 2.4418 - val_rmse: 1.5438\n",
      "Epoch 13/100\n",
      "1213/1213 - 1s - 673us/step - loss: 3.6580 - rmse: 1.8860 - val_loss: 2.4552 - val_rmse: 1.5492\n",
      "Epoch 14/100\n",
      "1213/1213 - 1s - 673us/step - loss: 3.5686 - rmse: 1.8636 - val_loss: 2.3518 - val_rmse: 1.5163\n",
      "Epoch 15/100\n",
      "1213/1213 - 1s - 675us/step - loss: 3.5229 - rmse: 1.8482 - val_loss: 2.4044 - val_rmse: 1.5319\n",
      "Epoch 16/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.4904 - rmse: 1.8440 - val_loss: 2.4222 - val_rmse: 1.5386\n",
      "Epoch 17/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.4154 - rmse: 1.8224 - val_loss: 2.3680 - val_rmse: 1.5198\n",
      "Epoch 18/100\n",
      "1213/1213 - 1s - 694us/step - loss: 3.3851 - rmse: 1.8156 - val_loss: 2.3557 - val_rmse: 1.5179\n",
      "Epoch 19/100\n",
      "1213/1213 - 1s - 673us/step - loss: 3.3732 - rmse: 1.8108 - val_loss: 2.4208 - val_rmse: 1.5371\n",
      "Epoch 20/100\n",
      "1213/1213 - 1s - 671us/step - loss: 3.3199 - rmse: 1.7950 - val_loss: 2.3246 - val_rmse: 1.5068\n",
      "Epoch 21/100\n",
      "1213/1213 - 1s - 667us/step - loss: 3.3320 - rmse: 1.8006 - val_loss: 2.2989 - val_rmse: 1.4982\n",
      "Epoch 22/100\n",
      "1213/1213 - 1s - 673us/step - loss: 3.2721 - rmse: 1.7844 - val_loss: 2.2660 - val_rmse: 1.4884\n",
      "Epoch 23/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.2564 - rmse: 1.7781 - val_loss: 2.2903 - val_rmse: 1.4949\n",
      "Epoch 24/100\n",
      "1213/1213 - 1s - 667us/step - loss: 3.2385 - rmse: 1.7750 - val_loss: 2.2437 - val_rmse: 1.4802\n",
      "Epoch 25/100\n",
      "1213/1213 - 1s - 668us/step - loss: 3.2491 - rmse: 1.7766 - val_loss: 2.2915 - val_rmse: 1.4963\n",
      "Epoch 26/100\n",
      "1213/1213 - 1s - 671us/step - loss: 3.2106 - rmse: 1.7647 - val_loss: 2.2539 - val_rmse: 1.4843\n",
      "Epoch 27/100\n",
      "1213/1213 - 1s - 672us/step - loss: 3.1678 - rmse: 1.7552 - val_loss: 2.2160 - val_rmse: 1.4708\n",
      "Epoch 28/100\n",
      "1213/1213 - 1s - 668us/step - loss: 3.1462 - rmse: 1.7479 - val_loss: 2.2291 - val_rmse: 1.4755\n",
      "Epoch 29/100\n",
      "1213/1213 - 1s - 666us/step - loss: 3.1342 - rmse: 1.7424 - val_loss: 2.2037 - val_rmse: 1.4673\n",
      "Epoch 30/100\n",
      "1213/1213 - 1s - 664us/step - loss: 3.1460 - rmse: 1.7449 - val_loss: 2.2095 - val_rmse: 1.4694\n",
      "Epoch 31/100\n",
      "1213/1213 - 1s - 666us/step - loss: 3.0979 - rmse: 1.7351 - val_loss: 2.1784 - val_rmse: 1.4588\n",
      "Epoch 32/100\n",
      "1213/1213 - 1s - 674us/step - loss: 3.0633 - rmse: 1.7262 - val_loss: 2.1707 - val_rmse: 1.4556\n",
      "Epoch 33/100\n",
      "1213/1213 - 1s - 670us/step - loss: 3.0599 - rmse: 1.7240 - val_loss: 2.1816 - val_rmse: 1.4599\n",
      "Epoch 34/100\n",
      "1213/1213 - 1s - 670us/step - loss: 3.0770 - rmse: 1.7256 - val_loss: 2.1967 - val_rmse: 1.4647\n",
      "Epoch 35/100\n",
      "1213/1213 - 1s - 669us/step - loss: 3.0278 - rmse: 1.7140 - val_loss: 2.1830 - val_rmse: 1.4595\n",
      "Epoch 36/100\n",
      "1213/1213 - 1s - 676us/step - loss: 3.0429 - rmse: 1.7179 - val_loss: 2.1684 - val_rmse: 1.4558\n",
      "Epoch 37/100\n",
      "1213/1213 - 1s - 670us/step - loss: 3.0299 - rmse: 1.7146 - val_loss: 2.1711 - val_rmse: 1.4570\n",
      "Epoch 38/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.9825 - rmse: 1.7009 - val_loss: 2.1980 - val_rmse: 1.4646\n",
      "Epoch 39/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.9566 - rmse: 1.6971 - val_loss: 2.1632 - val_rmse: 1.4544\n",
      "Epoch 40/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.9569 - rmse: 1.6937 - val_loss: 2.1631 - val_rmse: 1.4539\n",
      "Epoch 41/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.9310 - rmse: 1.6880 - val_loss: 2.1305 - val_rmse: 1.4422\n",
      "Epoch 42/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.9674 - rmse: 1.6968 - val_loss: 2.1570 - val_rmse: 1.4511\n",
      "Epoch 43/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.9249 - rmse: 1.6865 - val_loss: 2.1452 - val_rmse: 1.4485\n",
      "Epoch 44/100\n",
      "1213/1213 - 1s - 681us/step - loss: 2.9404 - rmse: 1.6887 - val_loss: 2.1345 - val_rmse: 1.4445\n",
      "Epoch 45/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.8930 - rmse: 1.6805 - val_loss: 2.0844 - val_rmse: 1.4274\n",
      "Epoch 46/100\n",
      "1213/1213 - 1s - 679us/step - loss: 2.9139 - rmse: 1.6813 - val_loss: 2.1607 - val_rmse: 1.4530\n",
      "Epoch 47/100\n",
      "1213/1213 - 1s - 679us/step - loss: 2.8981 - rmse: 1.6785 - val_loss: 2.1130 - val_rmse: 1.4359\n",
      "Epoch 48/100\n",
      "1213/1213 - 1s - 675us/step - loss: 2.8899 - rmse: 1.6731 - val_loss: 2.0943 - val_rmse: 1.4312\n",
      "Epoch 49/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.8738 - rmse: 1.6712 - val_loss: 2.0722 - val_rmse: 1.4228\n",
      "Epoch 50/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.8773 - rmse: 1.6713 - val_loss: 2.1003 - val_rmse: 1.4323\n",
      "Epoch 51/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.8742 - rmse: 1.6724 - val_loss: 2.0877 - val_rmse: 1.4291\n",
      "Epoch 52/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.8535 - rmse: 1.6675 - val_loss: 2.0848 - val_rmse: 1.4281\n",
      "Epoch 53/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.8463 - rmse: 1.6637 - val_loss: 2.0787 - val_rmse: 1.4256\n",
      "Epoch 54/100\n",
      "1213/1213 - 1s - 676us/step - loss: 2.8342 - rmse: 1.6584 - val_loss: 2.0485 - val_rmse: 1.4155\n",
      "Epoch 55/100\n",
      "1213/1213 - 1s - 690us/step - loss: 2.8043 - rmse: 1.6512 - val_loss: 2.0927 - val_rmse: 1.4299\n",
      "Epoch 56/100\n",
      "1213/1213 - 1s - 681us/step - loss: 2.8125 - rmse: 1.6529 - val_loss: 2.0481 - val_rmse: 1.4148\n",
      "Epoch 57/100\n",
      "1213/1213 - 1s - 668us/step - loss: 2.8349 - rmse: 1.6603 - val_loss: 2.0517 - val_rmse: 1.4163\n",
      "Epoch 58/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.8206 - rmse: 1.6569 - val_loss: 2.0483 - val_rmse: 1.4151\n",
      "Epoch 59/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7889 - rmse: 1.6443 - val_loss: 2.0475 - val_rmse: 1.4160\n",
      "Epoch 60/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.7843 - rmse: 1.6430 - val_loss: 2.0639 - val_rmse: 1.4210\n",
      "Epoch 61/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.8019 - rmse: 1.6491 - val_loss: 2.0196 - val_rmse: 1.4051\n",
      "Epoch 62/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.8236 - rmse: 1.6526 - val_loss: 2.0302 - val_rmse: 1.4090\n",
      "Epoch 63/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.7617 - rmse: 1.6379 - val_loss: 2.0165 - val_rmse: 1.4045\n",
      "Epoch 64/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7769 - rmse: 1.6435 - val_loss: 2.0061 - val_rmse: 1.4007\n",
      "Epoch 65/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.7565 - rmse: 1.6345 - val_loss: 2.0403 - val_rmse: 1.4126\n",
      "Epoch 66/100\n",
      "1213/1213 - 1s - 677us/step - loss: 2.7716 - rmse: 1.6406 - val_loss: 1.9845 - val_rmse: 1.3924\n",
      "Epoch 67/100\n",
      "1213/1213 - 1s - 668us/step - loss: 2.7736 - rmse: 1.6408 - val_loss: 2.0684 - val_rmse: 1.4226\n",
      "Epoch 68/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.7440 - rmse: 1.6330 - val_loss: 2.0004 - val_rmse: 1.3992\n",
      "Epoch 69/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7405 - rmse: 1.6315 - val_loss: 2.0166 - val_rmse: 1.4040\n",
      "Epoch 70/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.7741 - rmse: 1.6445 - val_loss: 2.0084 - val_rmse: 1.4013\n",
      "Epoch 71/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7846 - rmse: 1.6427 - val_loss: 1.9912 - val_rmse: 1.3957\n",
      "Epoch 72/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.7306 - rmse: 1.6292 - val_loss: 1.9480 - val_rmse: 1.3799\n",
      "Epoch 73/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.7128 - rmse: 1.6228 - val_loss: 1.9855 - val_rmse: 1.3938\n",
      "Epoch 74/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7492 - rmse: 1.6339 - val_loss: 1.9806 - val_rmse: 1.3921\n",
      "Epoch 75/100\n",
      "1213/1213 - 1s - 675us/step - loss: 2.7509 - rmse: 1.6360 - val_loss: 1.9355 - val_rmse: 1.3758\n",
      "Epoch 76/100\n",
      "1213/1213 - 1s - 677us/step - loss: 2.7142 - rmse: 1.6231 - val_loss: 1.9452 - val_rmse: 1.3798\n",
      "Epoch 77/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.7207 - rmse: 1.6257 - val_loss: 1.9508 - val_rmse: 1.3817\n",
      "Epoch 78/100\n",
      "1213/1213 - 1s - 674us/step - loss: 2.7406 - rmse: 1.6293 - val_loss: 1.9284 - val_rmse: 1.3737\n",
      "Epoch 79/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.7239 - rmse: 1.6269 - val_loss: 1.9843 - val_rmse: 1.3940\n",
      "Epoch 80/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.7220 - rmse: 1.6250 - val_loss: 1.9618 - val_rmse: 1.3854\n",
      "Epoch 81/100\n",
      "1213/1213 - 1s - 670us/step - loss: 2.7197 - rmse: 1.6250 - val_loss: 1.9420 - val_rmse: 1.3783\n",
      "Epoch 82/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.7325 - rmse: 1.6260 - val_loss: 1.9551 - val_rmse: 1.3833\n",
      "Epoch 83/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.6925 - rmse: 1.6182 - val_loss: 1.9508 - val_rmse: 1.3821\n",
      "Epoch 84/100\n",
      "1213/1213 - 1s - 668us/step - loss: 2.6943 - rmse: 1.6209 - val_loss: 1.9533 - val_rmse: 1.3822\n",
      "Epoch 85/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.6837 - rmse: 1.6161 - val_loss: 1.9173 - val_rmse: 1.3689\n",
      "Epoch 86/100\n",
      "1213/1213 - 1s - 674us/step - loss: 2.7060 - rmse: 1.6231 - val_loss: 1.9587 - val_rmse: 1.3847\n",
      "Epoch 87/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.6776 - rmse: 1.6131 - val_loss: 1.9186 - val_rmse: 1.3698\n",
      "Epoch 88/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.6715 - rmse: 1.6106 - val_loss: 1.9524 - val_rmse: 1.3824\n",
      "Epoch 89/100\n",
      "1213/1213 - 1s - 674us/step - loss: 2.6884 - rmse: 1.6175 - val_loss: 1.9354 - val_rmse: 1.3761\n",
      "Epoch 90/100\n",
      "1213/1213 - 1s - 668us/step - loss: 2.7065 - rmse: 1.6232 - val_loss: 1.9297 - val_rmse: 1.3733\n",
      "Epoch 91/100\n",
      "1213/1213 - 1s - 677us/step - loss: 2.6867 - rmse: 1.6147 - val_loss: 1.9082 - val_rmse: 1.3663\n",
      "Epoch 92/100\n",
      "1213/1213 - 1s - 685us/step - loss: 2.6605 - rmse: 1.6077 - val_loss: 1.9168 - val_rmse: 1.3691\n",
      "Epoch 93/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.6617 - rmse: 1.6088 - val_loss: 1.9111 - val_rmse: 1.3669\n",
      "Epoch 94/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.6777 - rmse: 1.6133 - val_loss: 1.9277 - val_rmse: 1.3737\n",
      "Epoch 95/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.6932 - rmse: 1.6191 - val_loss: 1.9351 - val_rmse: 1.3756\n",
      "Epoch 96/100\n",
      "1213/1213 - 1s - 668us/step - loss: 2.6793 - rmse: 1.6142 - val_loss: 1.9122 - val_rmse: 1.3674\n",
      "Epoch 97/100\n",
      "1213/1213 - 1s - 671us/step - loss: 2.6663 - rmse: 1.6078 - val_loss: 1.9696 - val_rmse: 1.3887\n",
      "Epoch 98/100\n",
      "1213/1213 - 1s - 669us/step - loss: 2.6906 - rmse: 1.6163 - val_loss: 1.9479 - val_rmse: 1.3813\n",
      "Epoch 99/100\n",
      "1213/1213 - 1s - 673us/step - loss: 2.6510 - rmse: 1.6040 - val_loss: 1.8965 - val_rmse: 1.3621\n",
      "Epoch 100/100\n",
      "1213/1213 - 1s - 672us/step - loss: 2.6656 - rmse: 1.6067 - val_loss: 1.9110 - val_rmse: 1.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1213/1213 - 1s - 488us/step - loss: 2.3202 - rmse: 3.8296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 - 1s - 551us/step - loss: 2.3191 - rmse: 3.9013\n",
      "243/243 - 0s - 601us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 - 1s - 518us/step - loss: 2.4185 - rmse: 3.9084\n",
      "243/243 - 0s - 600us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 - 0s - 515us/step - loss: 2.2924 - rmse: 3.9309\n",
      "243/243 - 0s - 610us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 - 1s - 521us/step - loss: 2.2642 - rmse: 3.5497\n",
      "243/243 - 0s - 602us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 - 1s - 516us/step - loss: 2.3574 - rmse: 3.8803\n",
      "243/243 - 0s - 609us/step\n",
      "01:00:19 - p12 - Predicting -\n",
      "9/9 - 0s - 6ms/step\n",
      "01:00:19 - p12 - Done -\n",
      "01:00:19 - p15 - Predicting for patient p15\n",
      "01:00:19 - p15 - Transforming the data -\n",
      "01:00:19 - p15 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 - 1s - 3ms/step - loss: 42.7321 - rmse: 6.3079 - val_loss: 9.9988 - val_rmse: 3.1290\n",
      "Epoch 2/100\n",
      "425/425 - 0s - 727us/step - loss: 9.3010 - rmse: 3.0118 - val_loss: 5.1356 - val_rmse: 2.2399\n",
      "Epoch 3/100\n",
      "425/425 - 0s - 706us/step - loss: 7.6515 - rmse: 2.7357 - val_loss: 4.9813 - val_rmse: 2.2049\n",
      "Epoch 4/100\n",
      "425/425 - 0s - 758us/step - loss: 6.9147 - rmse: 2.6010 - val_loss: 4.7747 - val_rmse: 2.1605\n",
      "Epoch 5/100\n",
      "425/425 - 0s - 701us/step - loss: 6.4948 - rmse: 2.5227 - val_loss: 4.5501 - val_rmse: 2.1101\n",
      "Epoch 6/100\n",
      "425/425 - 0s - 747us/step - loss: 6.1754 - rmse: 2.4595 - val_loss: 4.6272 - val_rmse: 2.1271\n",
      "Epoch 7/100\n",
      "425/425 - 0s - 708us/step - loss: 5.8886 - rmse: 2.4026 - val_loss: 4.5008 - val_rmse: 2.0992\n",
      "Epoch 8/100\n",
      "425/425 - 0s - 700us/step - loss: 5.8865 - rmse: 2.4019 - val_loss: 4.5068 - val_rmse: 2.0989\n",
      "Epoch 9/100\n",
      "425/425 - 0s - 710us/step - loss: 5.7466 - rmse: 2.3700 - val_loss: 4.3468 - val_rmse: 2.0643\n",
      "Epoch 10/100\n",
      "425/425 - 0s - 698us/step - loss: 5.5686 - rmse: 2.3355 - val_loss: 4.3304 - val_rmse: 2.0607\n",
      "Epoch 11/100\n",
      "425/425 - 0s - 710us/step - loss: 5.4327 - rmse: 2.3076 - val_loss: 4.4450 - val_rmse: 2.0852\n",
      "Epoch 12/100\n",
      "425/425 - 0s - 709us/step - loss: 5.3437 - rmse: 2.2871 - val_loss: 4.2068 - val_rmse: 2.0302\n",
      "Epoch 13/100\n",
      "425/425 - 0s - 704us/step - loss: 5.2754 - rmse: 2.2721 - val_loss: 4.2021 - val_rmse: 2.0299\n",
      "Epoch 14/100\n",
      "425/425 - 0s - 707us/step - loss: 5.2604 - rmse: 2.2720 - val_loss: 4.2908 - val_rmse: 2.0482\n",
      "Epoch 15/100\n",
      "425/425 - 0s - 704us/step - loss: 5.1847 - rmse: 2.2515 - val_loss: 4.1247 - val_rmse: 2.0118\n",
      "Epoch 16/100\n",
      "425/425 - 0s - 711us/step - loss: 5.1043 - rmse: 2.2384 - val_loss: 4.1210 - val_rmse: 2.0082\n",
      "Epoch 17/100\n",
      "425/425 - 0s - 706us/step - loss: 5.1008 - rmse: 2.2356 - val_loss: 4.0855 - val_rmse: 2.0010\n",
      "Epoch 18/100\n",
      "425/425 - 0s - 715us/step - loss: 4.9902 - rmse: 2.2091 - val_loss: 3.9968 - val_rmse: 1.9805\n",
      "Epoch 19/100\n",
      "425/425 - 0s - 707us/step - loss: 5.0007 - rmse: 2.2143 - val_loss: 4.0658 - val_rmse: 1.9952\n",
      "Epoch 20/100\n",
      "425/425 - 0s - 702us/step - loss: 4.9587 - rmse: 2.2040 - val_loss: 3.9281 - val_rmse: 1.9620\n",
      "Epoch 21/100\n",
      "425/425 - 0s - 712us/step - loss: 4.8932 - rmse: 2.1903 - val_loss: 4.0632 - val_rmse: 1.9943\n",
      "Epoch 22/100\n",
      "425/425 - 0s - 704us/step - loss: 4.8520 - rmse: 2.1784 - val_loss: 3.8923 - val_rmse: 1.9528\n",
      "Epoch 23/100\n",
      "425/425 - 0s - 702us/step - loss: 4.8107 - rmse: 2.1691 - val_loss: 4.0126 - val_rmse: 1.9782\n",
      "Epoch 24/100\n",
      "425/425 - 0s - 708us/step - loss: 4.7228 - rmse: 2.1518 - val_loss: 3.9142 - val_rmse: 1.9559\n",
      "Epoch 25/100\n",
      "425/425 - 0s - 701us/step - loss: 4.7715 - rmse: 2.1586 - val_loss: 3.7876 - val_rmse: 1.9257\n",
      "Epoch 26/100\n",
      "425/425 - 0s - 708us/step - loss: 4.6963 - rmse: 2.1432 - val_loss: 3.7789 - val_rmse: 1.9243\n",
      "Epoch 27/100\n",
      "425/425 - 0s - 704us/step - loss: 4.6222 - rmse: 2.1308 - val_loss: 3.7391 - val_rmse: 1.9141\n",
      "Epoch 28/100\n",
      "425/425 - 0s - 699us/step - loss: 4.6822 - rmse: 2.1392 - val_loss: 3.7648 - val_rmse: 1.9183\n",
      "Epoch 29/100\n",
      "425/425 - 0s - 698us/step - loss: 4.6387 - rmse: 2.1287 - val_loss: 3.8383 - val_rmse: 1.9376\n",
      "Epoch 30/100\n",
      "425/425 - 0s - 703us/step - loss: 4.6083 - rmse: 2.1239 - val_loss: 3.6783 - val_rmse: 1.8993\n",
      "Epoch 31/100\n",
      "425/425 - 0s - 706us/step - loss: 4.6363 - rmse: 2.1279 - val_loss: 3.7354 - val_rmse: 1.9107\n",
      "Epoch 32/100\n",
      "425/425 - 0s - 708us/step - loss: 4.5765 - rmse: 2.1188 - val_loss: 3.5992 - val_rmse: 1.8773\n",
      "Epoch 33/100\n",
      "425/425 - 0s - 702us/step - loss: 4.4942 - rmse: 2.0991 - val_loss: 3.8141 - val_rmse: 1.9293\n",
      "Epoch 34/100\n",
      "425/425 - 0s - 713us/step - loss: 4.5183 - rmse: 2.1024 - val_loss: 3.6086 - val_rmse: 1.8804\n",
      "Epoch 35/100\n",
      "425/425 - 0s - 702us/step - loss: 4.4432 - rmse: 2.0849 - val_loss: 3.7172 - val_rmse: 1.9073\n",
      "Epoch 36/100\n",
      "425/425 - 0s - 707us/step - loss: 4.4340 - rmse: 2.0803 - val_loss: 3.5882 - val_rmse: 1.8750\n",
      "Epoch 37/100\n",
      "425/425 - 0s - 700us/step - loss: 4.3983 - rmse: 2.0749 - val_loss: 3.5885 - val_rmse: 1.8741\n",
      "Epoch 38/100\n",
      "425/425 - 0s - 709us/step - loss: 4.4197 - rmse: 2.0771 - val_loss: 3.6164 - val_rmse: 1.8795\n",
      "Epoch 39/100\n",
      "425/425 - 0s - 706us/step - loss: 4.4163 - rmse: 2.0765 - val_loss: 3.5514 - val_rmse: 1.8645\n",
      "Epoch 40/100\n",
      "425/425 - 0s - 712us/step - loss: 4.2987 - rmse: 2.0487 - val_loss: 3.4887 - val_rmse: 1.8481\n",
      "Epoch 41/100\n",
      "425/425 - 0s - 710us/step - loss: 4.3157 - rmse: 2.0555 - val_loss: 3.5034 - val_rmse: 1.8499\n",
      "Epoch 42/100\n",
      "425/425 - 0s - 701us/step - loss: 4.3163 - rmse: 2.0542 - val_loss: 3.4685 - val_rmse: 1.8403\n",
      "Epoch 43/100\n",
      "425/425 - 0s - 707us/step - loss: 4.2664 - rmse: 2.0435 - val_loss: 3.5006 - val_rmse: 1.8502\n",
      "Epoch 44/100\n",
      "425/425 - 0s - 706us/step - loss: 4.3024 - rmse: 2.0479 - val_loss: 3.5673 - val_rmse: 1.8674\n",
      "Epoch 45/100\n",
      "425/425 - 0s - 701us/step - loss: 4.2412 - rmse: 2.0366 - val_loss: 3.4340 - val_rmse: 1.8340\n",
      "Epoch 46/100\n",
      "425/425 - 0s - 707us/step - loss: 4.1871 - rmse: 2.0251 - val_loss: 3.4471 - val_rmse: 1.8351\n",
      "Epoch 47/100\n",
      "425/425 - 0s - 702us/step - loss: 4.2716 - rmse: 2.0461 - val_loss: 3.3732 - val_rmse: 1.8170\n",
      "Epoch 48/100\n",
      "425/425 - 0s - 708us/step - loss: 4.2276 - rmse: 2.0340 - val_loss: 3.3474 - val_rmse: 1.8090\n",
      "Epoch 49/100\n",
      "425/425 - 0s - 706us/step - loss: 4.2225 - rmse: 2.0312 - val_loss: 3.3770 - val_rmse: 1.8170\n",
      "Epoch 50/100\n",
      "425/425 - 0s - 707us/step - loss: 4.1850 - rmse: 2.0211 - val_loss: 3.4069 - val_rmse: 1.8245\n",
      "Epoch 51/100\n",
      "425/425 - 0s - 709us/step - loss: 4.1277 - rmse: 2.0100 - val_loss: 3.4149 - val_rmse: 1.8262\n",
      "Epoch 52/100\n",
      "425/425 - 0s - 699us/step - loss: 4.1959 - rmse: 2.0235 - val_loss: 3.5249 - val_rmse: 1.8536\n",
      "Epoch 53/100\n",
      "425/425 - 0s - 707us/step - loss: 4.1720 - rmse: 2.0206 - val_loss: 3.3602 - val_rmse: 1.8121\n",
      "Epoch 54/100\n",
      "425/425 - 0s - 706us/step - loss: 4.0834 - rmse: 1.9959 - val_loss: 3.3542 - val_rmse: 1.8116\n",
      "Epoch 55/100\n",
      "425/425 - 0s - 704us/step - loss: 4.1118 - rmse: 2.0052 - val_loss: 3.2819 - val_rmse: 1.7915\n",
      "Epoch 56/100\n",
      "425/425 - 0s - 709us/step - loss: 4.0185 - rmse: 1.9846 - val_loss: 3.3959 - val_rmse: 1.8213\n",
      "Epoch 57/100\n",
      "425/425 - 0s - 705us/step - loss: 4.0446 - rmse: 1.9895 - val_loss: 3.4280 - val_rmse: 1.8299\n",
      "Epoch 58/100\n",
      "425/425 - 0s - 707us/step - loss: 4.0682 - rmse: 1.9949 - val_loss: 3.2923 - val_rmse: 1.7932\n",
      "Epoch 59/100\n",
      "425/425 - 0s - 708us/step - loss: 4.0601 - rmse: 1.9908 - val_loss: 3.2565 - val_rmse: 1.7858\n",
      "Epoch 60/100\n",
      "425/425 - 0s - 700us/step - loss: 4.0397 - rmse: 1.9854 - val_loss: 3.2654 - val_rmse: 1.7851\n",
      "Epoch 61/100\n",
      "425/425 - 0s - 712us/step - loss: 3.9926 - rmse: 1.9775 - val_loss: 3.3508 - val_rmse: 1.8074\n",
      "Epoch 62/100\n",
      "425/425 - 0s - 697us/step - loss: 3.9953 - rmse: 1.9769 - val_loss: 3.3270 - val_rmse: 1.8035\n",
      "Epoch 63/100\n",
      "425/425 - 0s - 710us/step - loss: 3.9577 - rmse: 1.9681 - val_loss: 3.1944 - val_rmse: 1.7687\n",
      "Epoch 64/100\n",
      "425/425 - 0s - 715us/step - loss: 3.9845 - rmse: 1.9738 - val_loss: 3.1628 - val_rmse: 1.7594\n",
      "Epoch 65/100\n",
      "425/425 - 0s - 699us/step - loss: 4.0300 - rmse: 1.9863 - val_loss: 3.2195 - val_rmse: 1.7741\n",
      "Epoch 66/100\n",
      "425/425 - 0s - 708us/step - loss: 3.9720 - rmse: 1.9682 - val_loss: 3.1537 - val_rmse: 1.7572\n",
      "Epoch 67/100\n",
      "425/425 - 0s - 707us/step - loss: 3.9642 - rmse: 1.9667 - val_loss: 3.1410 - val_rmse: 1.7525\n",
      "Epoch 68/100\n",
      "425/425 - 0s - 707us/step - loss: 3.9309 - rmse: 1.9600 - val_loss: 3.1176 - val_rmse: 1.7455\n",
      "Epoch 69/100\n",
      "425/425 - 0s - 703us/step - loss: 3.8787 - rmse: 1.9467 - val_loss: 3.2028 - val_rmse: 1.7686\n",
      "Epoch 70/100\n",
      "425/425 - 0s - 700us/step - loss: 3.8772 - rmse: 1.9460 - val_loss: 3.1931 - val_rmse: 1.7668\n",
      "Epoch 71/100\n",
      "425/425 - 0s - 708us/step - loss: 3.8875 - rmse: 1.9506 - val_loss: 3.1452 - val_rmse: 1.7539\n",
      "Epoch 72/100\n",
      "425/425 - 0s - 703us/step - loss: 3.8898 - rmse: 1.9489 - val_loss: 3.1155 - val_rmse: 1.7438\n",
      "Epoch 73/100\n",
      "425/425 - 0s - 701us/step - loss: 3.8643 - rmse: 1.9406 - val_loss: 3.0893 - val_rmse: 1.7376\n",
      "Epoch 74/100\n",
      "425/425 - 0s - 705us/step - loss: 3.8592 - rmse: 1.9431 - val_loss: 3.1596 - val_rmse: 1.7565\n",
      "Epoch 75/100\n",
      "425/425 - 0s - 698us/step - loss: 3.9269 - rmse: 1.9580 - val_loss: 3.2112 - val_rmse: 1.7724\n",
      "Epoch 76/100\n",
      "425/425 - 0s - 703us/step - loss: 3.9286 - rmse: 1.9577 - val_loss: 3.1036 - val_rmse: 1.7415\n",
      "Epoch 77/100\n",
      "425/425 - 0s - 704us/step - loss: 3.8225 - rmse: 1.9330 - val_loss: 3.1258 - val_rmse: 1.7483\n",
      "Epoch 78/100\n",
      "425/425 - 0s - 707us/step - loss: 3.8538 - rmse: 1.9406 - val_loss: 3.0173 - val_rmse: 1.7180\n",
      "Epoch 79/100\n",
      "425/425 - 0s - 703us/step - loss: 3.8438 - rmse: 1.9395 - val_loss: 3.1260 - val_rmse: 1.7467\n",
      "Epoch 80/100\n",
      "425/425 - 0s - 700us/step - loss: 3.8156 - rmse: 1.9301 - val_loss: 3.0543 - val_rmse: 1.7270\n",
      "Epoch 81/100\n",
      "425/425 - 0s - 709us/step - loss: 3.8137 - rmse: 1.9302 - val_loss: 3.0528 - val_rmse: 1.7279\n",
      "Epoch 82/100\n",
      "425/425 - 0s - 701us/step - loss: 3.8155 - rmse: 1.9325 - val_loss: 3.0821 - val_rmse: 1.7363\n",
      "Epoch 83/100\n",
      "425/425 - 0s - 710us/step - loss: 3.7749 - rmse: 1.9206 - val_loss: 3.0045 - val_rmse: 1.7137\n",
      "Epoch 84/100\n",
      "425/425 - 0s - 711us/step - loss: 3.7100 - rmse: 1.9055 - val_loss: 3.0091 - val_rmse: 1.7147\n",
      "Epoch 85/100\n",
      "425/425 - 0s - 702us/step - loss: 3.7544 - rmse: 1.9179 - val_loss: 2.9450 - val_rmse: 1.6969\n",
      "Epoch 86/100\n",
      "425/425 - 0s - 704us/step - loss: 3.7523 - rmse: 1.9172 - val_loss: 3.0350 - val_rmse: 1.7228\n",
      "Epoch 87/100\n",
      "425/425 - 0s - 697us/step - loss: 3.7183 - rmse: 1.9052 - val_loss: 3.0757 - val_rmse: 1.7330\n",
      "Epoch 88/100\n",
      "425/425 - 0s - 706us/step - loss: 3.7443 - rmse: 1.9130 - val_loss: 3.0105 - val_rmse: 1.7165\n",
      "Epoch 89/100\n",
      "425/425 - 0s - 706us/step - loss: 3.7648 - rmse: 1.9153 - val_loss: 2.9867 - val_rmse: 1.7080\n",
      "Epoch 90/100\n",
      "425/425 - 0s - 702us/step - loss: 3.6704 - rmse: 1.8950 - val_loss: 2.9877 - val_rmse: 1.7093\n",
      "Epoch 91/100\n",
      "425/425 - 0s - 707us/step - loss: 3.7031 - rmse: 1.9022 - val_loss: 2.9670 - val_rmse: 1.7019\n",
      "Epoch 92/100\n",
      "425/425 - 0s - 696us/step - loss: 3.6697 - rmse: 1.8946 - val_loss: 2.9901 - val_rmse: 1.7085\n",
      "Epoch 93/100\n",
      "425/425 - 0s - 706us/step - loss: 3.7286 - rmse: 1.9085 - val_loss: 2.9791 - val_rmse: 1.7061\n",
      "Epoch 94/100\n",
      "425/425 - 0s - 703us/step - loss: 3.6644 - rmse: 1.8930 - val_loss: 2.8797 - val_rmse: 1.6786\n",
      "Epoch 95/100\n",
      "425/425 - 0s - 705us/step - loss: 3.6423 - rmse: 1.8850 - val_loss: 2.9253 - val_rmse: 1.6904\n",
      "Epoch 96/100\n",
      "425/425 - 0s - 709us/step - loss: 3.6735 - rmse: 1.8945 - val_loss: 2.9158 - val_rmse: 1.6890\n",
      "Epoch 97/100\n",
      "425/425 - 0s - 703us/step - loss: 3.7190 - rmse: 1.9048 - val_loss: 3.0467 - val_rmse: 1.7259\n",
      "Epoch 98/100\n",
      "425/425 - 0s - 709us/step - loss: 3.6278 - rmse: 1.8812 - val_loss: 3.0025 - val_rmse: 1.7127\n",
      "Epoch 99/100\n",
      "425/425 - 0s - 702us/step - loss: 3.6636 - rmse: 1.8907 - val_loss: 3.0404 - val_rmse: 1.7237\n",
      "Epoch 100/100\n",
      "425/425 - 0s - 708us/step - loss: 3.6997 - rmse: 1.8995 - val_loss: 2.9759 - val_rmse: 1.7057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 - 0s - 778us/step - loss: 3.3908 - rmse: 3.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 - 0s - 802us/step - loss: 3.2848 - rmse: 3.2871\n",
      "85/85 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 - 0s - 784us/step - loss: 3.4978 - rmse: 3.4875\n",
      "85/85 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 - 0s - 787us/step - loss: 3.4557 - rmse: 3.4600\n",
      "85/85 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 - 0s - 784us/step - loss: 3.4531 - rmse: 3.4532\n",
      "85/85 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 - 0s - 782us/step - loss: 3.3932 - rmse: 3.4690\n",
      "85/85 - 0s - 4ms/step\n",
      "01:02:06 - p15 - Predicting -\n",
      "10/10 - 0s - 7ms/step\n",
      "01:02:06 - p15 - Done -\n",
      "01:02:06 - p16 - Predicting for patient p16\n",
      "01:02:06 - p16 - Transforming the data -\n",
      "01:02:06 - p16 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 1s - 3ms/step - loss: 46.4418 - rmse: 6.6268 - val_loss: 12.4812 - val_rmse: 3.5035\n",
      "Epoch 2/100\n",
      "371/371 - 0s - 629us/step - loss: 7.7160 - rmse: 2.7348 - val_loss: 2.7801 - val_rmse: 1.6386\n",
      "Epoch 3/100\n",
      "371/371 - 0s - 612us/step - loss: 5.3894 - rmse: 2.3004 - val_loss: 2.6285 - val_rmse: 1.5992\n",
      "Epoch 4/100\n",
      "371/371 - 0s - 622us/step - loss: 4.6906 - rmse: 2.1480 - val_loss: 2.5740 - val_rmse: 1.5863\n",
      "Epoch 5/100\n",
      "371/371 - 0s - 634us/step - loss: 4.1759 - rmse: 2.0291 - val_loss: 2.5455 - val_rmse: 1.5742\n",
      "Epoch 6/100\n",
      "371/371 - 0s - 607us/step - loss: 3.8952 - rmse: 1.9561 - val_loss: 2.4301 - val_rmse: 1.5423\n",
      "Epoch 7/100\n",
      "371/371 - 0s - 635us/step - loss: 3.7097 - rmse: 1.9083 - val_loss: 2.3998 - val_rmse: 1.5342\n",
      "Epoch 8/100\n",
      "371/371 - 0s - 612us/step - loss: 3.5372 - rmse: 1.8624 - val_loss: 2.3497 - val_rmse: 1.5167\n",
      "Epoch 9/100\n",
      "371/371 - 0s - 618us/step - loss: 3.4075 - rmse: 1.8296 - val_loss: 2.2693 - val_rmse: 1.4932\n",
      "Epoch 10/100\n",
      "371/371 - 0s - 630us/step - loss: 3.2597 - rmse: 1.7909 - val_loss: 2.2426 - val_rmse: 1.4845\n",
      "Epoch 11/100\n",
      "371/371 - 0s - 616us/step - loss: 3.2154 - rmse: 1.7769 - val_loss: 2.2212 - val_rmse: 1.4761\n",
      "Epoch 12/100\n",
      "371/371 - 0s - 625us/step - loss: 3.1560 - rmse: 1.7600 - val_loss: 2.1888 - val_rmse: 1.4659\n",
      "Epoch 13/100\n",
      "371/371 - 0s - 608us/step - loss: 3.1179 - rmse: 1.7496 - val_loss: 2.1781 - val_rmse: 1.4628\n",
      "Epoch 14/100\n",
      "371/371 - 0s - 613us/step - loss: 3.0673 - rmse: 1.7338 - val_loss: 2.1249 - val_rmse: 1.4446\n",
      "Epoch 15/100\n",
      "371/371 - 0s - 608us/step - loss: 3.0489 - rmse: 1.7281 - val_loss: 2.1273 - val_rmse: 1.4444\n",
      "Epoch 16/100\n",
      "371/371 - 0s - 613us/step - loss: 2.9977 - rmse: 1.7154 - val_loss: 2.1212 - val_rmse: 1.4421\n",
      "Epoch 17/100\n",
      "371/371 - 0s - 607us/step - loss: 2.9700 - rmse: 1.7084 - val_loss: 2.0617 - val_rmse: 1.4237\n",
      "Epoch 18/100\n",
      "371/371 - 0s - 608us/step - loss: 2.9997 - rmse: 1.7156 - val_loss: 2.0567 - val_rmse: 1.4206\n",
      "Epoch 19/100\n",
      "371/371 - 0s - 610us/step - loss: 2.8861 - rmse: 1.6840 - val_loss: 2.0320 - val_rmse: 1.4127\n",
      "Epoch 20/100\n",
      "371/371 - 0s - 607us/step - loss: 2.9132 - rmse: 1.6901 - val_loss: 2.0332 - val_rmse: 1.4140\n",
      "Epoch 21/100\n",
      "371/371 - 0s - 612us/step - loss: 2.8413 - rmse: 1.6691 - val_loss: 2.0284 - val_rmse: 1.4122\n",
      "Epoch 22/100\n",
      "371/371 - 0s - 602us/step - loss: 2.8340 - rmse: 1.6673 - val_loss: 2.0232 - val_rmse: 1.4073\n",
      "Epoch 23/100\n",
      "371/371 - 0s - 633us/step - loss: 2.7457 - rmse: 1.6416 - val_loss: 2.0162 - val_rmse: 1.4072\n",
      "Epoch 24/100\n",
      "371/371 - 0s - 627us/step - loss: 2.7262 - rmse: 1.6365 - val_loss: 1.9597 - val_rmse: 1.3862\n",
      "Epoch 25/100\n",
      "371/371 - 0s - 629us/step - loss: 2.7113 - rmse: 1.6324 - val_loss: 1.9430 - val_rmse: 1.3784\n",
      "Epoch 26/100\n",
      "371/371 - 0s - 615us/step - loss: 2.6903 - rmse: 1.6274 - val_loss: 1.9821 - val_rmse: 1.3909\n",
      "Epoch 27/100\n",
      "371/371 - 0s - 623us/step - loss: 2.7125 - rmse: 1.6297 - val_loss: 1.9203 - val_rmse: 1.3716\n",
      "Epoch 28/100\n",
      "371/371 - 0s - 623us/step - loss: 2.6414 - rmse: 1.6087 - val_loss: 1.8750 - val_rmse: 1.3565\n",
      "Epoch 29/100\n",
      "371/371 - 0s - 620us/step - loss: 2.6592 - rmse: 1.6158 - val_loss: 1.8497 - val_rmse: 1.3482\n",
      "Epoch 30/100\n",
      "371/371 - 0s - 622us/step - loss: 2.5536 - rmse: 1.5830 - val_loss: 1.9168 - val_rmse: 1.3680\n",
      "Epoch 31/100\n",
      "371/371 - 0s - 612us/step - loss: 2.5523 - rmse: 1.5810 - val_loss: 1.9103 - val_rmse: 1.3663\n",
      "Epoch 32/100\n",
      "371/371 - 0s - 624us/step - loss: 2.5375 - rmse: 1.5764 - val_loss: 1.8130 - val_rmse: 1.3354\n",
      "Epoch 33/100\n",
      "371/371 - 0s - 617us/step - loss: 2.5562 - rmse: 1.5840 - val_loss: 1.8427 - val_rmse: 1.3463\n",
      "Epoch 34/100\n",
      "371/371 - 0s - 623us/step - loss: 2.4725 - rmse: 1.5585 - val_loss: 1.8068 - val_rmse: 1.3320\n",
      "Epoch 35/100\n",
      "371/371 - 0s - 619us/step - loss: 2.4755 - rmse: 1.5582 - val_loss: 1.8084 - val_rmse: 1.3298\n",
      "Epoch 36/100\n",
      "371/371 - 0s - 625us/step - loss: 2.4404 - rmse: 1.5462 - val_loss: 1.7927 - val_rmse: 1.3266\n",
      "Epoch 37/100\n",
      "371/371 - 0s - 621us/step - loss: 2.4092 - rmse: 1.5381 - val_loss: 1.7822 - val_rmse: 1.3196\n",
      "Epoch 38/100\n",
      "371/371 - 0s - 625us/step - loss: 2.3986 - rmse: 1.5352 - val_loss: 1.7095 - val_rmse: 1.2946\n",
      "Epoch 39/100\n",
      "371/371 - 0s - 615us/step - loss: 2.3512 - rmse: 1.5188 - val_loss: 1.7129 - val_rmse: 1.2978\n",
      "Epoch 40/100\n",
      "371/371 - 0s - 616us/step - loss: 2.3545 - rmse: 1.5201 - val_loss: 1.6872 - val_rmse: 1.2896\n",
      "Epoch 41/100\n",
      "371/371 - 0s - 626us/step - loss: 2.3399 - rmse: 1.5152 - val_loss: 1.7127 - val_rmse: 1.2977\n",
      "Epoch 42/100\n",
      "371/371 - 0s - 617us/step - loss: 2.3406 - rmse: 1.5144 - val_loss: 1.6862 - val_rmse: 1.2859\n",
      "Epoch 43/100\n",
      "371/371 - 0s - 620us/step - loss: 2.2873 - rmse: 1.4982 - val_loss: 1.6990 - val_rmse: 1.2905\n",
      "Epoch 44/100\n",
      "371/371 - 0s - 617us/step - loss: 2.2827 - rmse: 1.4954 - val_loss: 1.6897 - val_rmse: 1.2885\n",
      "Epoch 45/100\n",
      "371/371 - 0s - 624us/step - loss: 2.2489 - rmse: 1.4836 - val_loss: 1.6491 - val_rmse: 1.2720\n",
      "Epoch 46/100\n",
      "371/371 - 0s - 618us/step - loss: 2.2782 - rmse: 1.4949 - val_loss: 1.7694 - val_rmse: 1.3137\n",
      "Epoch 47/100\n",
      "371/371 - 0s - 622us/step - loss: 2.2137 - rmse: 1.4755 - val_loss: 1.6320 - val_rmse: 1.2645\n",
      "Epoch 48/100\n",
      "371/371 - 0s - 617us/step - loss: 2.2048 - rmse: 1.4697 - val_loss: 1.6154 - val_rmse: 1.2590\n",
      "Epoch 49/100\n",
      "371/371 - 0s - 623us/step - loss: 2.1997 - rmse: 1.4692 - val_loss: 1.6382 - val_rmse: 1.2660\n",
      "Epoch 50/100\n",
      "371/371 - 0s - 627us/step - loss: 2.1751 - rmse: 1.4606 - val_loss: 1.5888 - val_rmse: 1.2486\n",
      "Epoch 51/100\n",
      "371/371 - 0s - 627us/step - loss: 2.1423 - rmse: 1.4487 - val_loss: 1.5727 - val_rmse: 1.2401\n",
      "Epoch 52/100\n",
      "371/371 - 0s - 612us/step - loss: 2.1652 - rmse: 1.4579 - val_loss: 1.5866 - val_rmse: 1.2501\n",
      "Epoch 53/100\n",
      "371/371 - 0s - 617us/step - loss: 2.0966 - rmse: 1.4336 - val_loss: 1.5220 - val_rmse: 1.2234\n",
      "Epoch 54/100\n",
      "371/371 - 0s - 620us/step - loss: 2.1437 - rmse: 1.4491 - val_loss: 1.5209 - val_rmse: 1.2227\n",
      "Epoch 55/100\n",
      "371/371 - 0s - 615us/step - loss: 2.1256 - rmse: 1.4430 - val_loss: 1.5290 - val_rmse: 1.2274\n",
      "Epoch 56/100\n",
      "371/371 - 0s - 632us/step - loss: 2.0490 - rmse: 1.4166 - val_loss: 1.5017 - val_rmse: 1.2138\n",
      "Epoch 57/100\n",
      "371/371 - 0s - 615us/step - loss: 2.0425 - rmse: 1.4145 - val_loss: 1.5017 - val_rmse: 1.2161\n",
      "Epoch 58/100\n",
      "371/371 - 0s - 623us/step - loss: 2.0383 - rmse: 1.4132 - val_loss: 1.5046 - val_rmse: 1.2162\n",
      "Epoch 59/100\n",
      "371/371 - 0s - 619us/step - loss: 2.0297 - rmse: 1.4093 - val_loss: 1.5041 - val_rmse: 1.2153\n",
      "Epoch 60/100\n",
      "371/371 - 0s - 628us/step - loss: 2.0509 - rmse: 1.4198 - val_loss: 1.4993 - val_rmse: 1.2115\n",
      "Epoch 61/100\n",
      "371/371 - 0s - 618us/step - loss: 2.0435 - rmse: 1.4163 - val_loss: 1.4930 - val_rmse: 1.2085\n",
      "Epoch 62/100\n",
      "371/371 - 0s - 619us/step - loss: 2.0321 - rmse: 1.4121 - val_loss: 1.4605 - val_rmse: 1.1971\n",
      "Epoch 63/100\n",
      "371/371 - 0s - 630us/step - loss: 1.9972 - rmse: 1.3992 - val_loss: 1.4505 - val_rmse: 1.1921\n",
      "Epoch 64/100\n",
      "371/371 - 0s - 614us/step - loss: 2.0138 - rmse: 1.4054 - val_loss: 1.4522 - val_rmse: 1.1925\n",
      "Epoch 65/100\n",
      "371/371 - 0s - 623us/step - loss: 1.9606 - rmse: 1.3865 - val_loss: 1.4223 - val_rmse: 1.1825\n",
      "Epoch 66/100\n",
      "371/371 - 0s - 664us/step - loss: 1.9428 - rmse: 1.3815 - val_loss: 1.4145 - val_rmse: 1.1804\n",
      "Epoch 67/100\n",
      "371/371 - 0s - 636us/step - loss: 1.9425 - rmse: 1.3788 - val_loss: 1.4181 - val_rmse: 1.1787\n",
      "Epoch 68/100\n",
      "371/371 - 0s - 617us/step - loss: 1.9573 - rmse: 1.3854 - val_loss: 1.4191 - val_rmse: 1.1785\n",
      "Epoch 69/100\n",
      "371/371 - 0s - 624us/step - loss: 1.9507 - rmse: 1.3839 - val_loss: 1.4192 - val_rmse: 1.1780\n",
      "Epoch 70/100\n",
      "371/371 - 0s - 637us/step - loss: 1.9134 - rmse: 1.3687 - val_loss: 1.4546 - val_rmse: 1.1939\n",
      "Epoch 71/100\n",
      "371/371 - 0s - 721us/step - loss: 1.9248 - rmse: 1.3751 - val_loss: 1.4199 - val_rmse: 1.1770\n",
      "Epoch 72/100\n",
      "371/371 - 0s - 620us/step - loss: 1.8921 - rmse: 1.3603 - val_loss: 1.4254 - val_rmse: 1.1780\n",
      "Epoch 73/100\n",
      "371/371 - 0s - 624us/step - loss: 1.8831 - rmse: 1.3580 - val_loss: 1.3756 - val_rmse: 1.1588\n",
      "Epoch 74/100\n",
      "371/371 - 0s - 617us/step - loss: 1.8987 - rmse: 1.3636 - val_loss: 1.3917 - val_rmse: 1.1661\n",
      "Epoch 75/100\n",
      "371/371 - 0s - 625us/step - loss: 1.8512 - rmse: 1.3476 - val_loss: 1.3728 - val_rmse: 1.1594\n",
      "Epoch 76/100\n",
      "371/371 - 0s - 619us/step - loss: 1.8440 - rmse: 1.3449 - val_loss: 1.3412 - val_rmse: 1.1465\n",
      "Epoch 77/100\n",
      "371/371 - 0s - 621us/step - loss: 1.8596 - rmse: 1.3530 - val_loss: 1.3822 - val_rmse: 1.1604\n",
      "Epoch 78/100\n",
      "371/371 - 0s - 614us/step - loss: 1.8477 - rmse: 1.3456 - val_loss: 1.3485 - val_rmse: 1.1507\n",
      "Epoch 79/100\n",
      "371/371 - 0s - 621us/step - loss: 1.8364 - rmse: 1.3419 - val_loss: 1.3217 - val_rmse: 1.1364\n",
      "Epoch 80/100\n",
      "371/371 - 0s - 625us/step - loss: 1.8236 - rmse: 1.3358 - val_loss: 1.3173 - val_rmse: 1.1360\n",
      "Epoch 81/100\n",
      "371/371 - 0s - 617us/step - loss: 1.7929 - rmse: 1.3256 - val_loss: 1.3414 - val_rmse: 1.1455\n",
      "Epoch 82/100\n",
      "371/371 - 0s - 621us/step - loss: 1.7982 - rmse: 1.3282 - val_loss: 1.3282 - val_rmse: 1.1432\n",
      "Epoch 83/100\n",
      "371/371 - 0s - 617us/step - loss: 1.8090 - rmse: 1.3329 - val_loss: 1.3484 - val_rmse: 1.1479\n",
      "Epoch 84/100\n",
      "371/371 - 0s - 626us/step - loss: 1.8065 - rmse: 1.3301 - val_loss: 1.2922 - val_rmse: 1.1273\n",
      "Epoch 85/100\n",
      "371/371 - 0s - 617us/step - loss: 1.7614 - rmse: 1.3146 - val_loss: 1.3370 - val_rmse: 1.1450\n",
      "Epoch 86/100\n",
      "371/371 - 0s - 621us/step - loss: 1.7873 - rmse: 1.3247 - val_loss: 1.2964 - val_rmse: 1.1274\n",
      "Epoch 87/100\n",
      "371/371 - 0s - 616us/step - loss: 1.7548 - rmse: 1.3128 - val_loss: 1.2857 - val_rmse: 1.1215\n",
      "Epoch 88/100\n",
      "371/371 - 0s - 626us/step - loss: 1.7535 - rmse: 1.3114 - val_loss: 1.2733 - val_rmse: 1.1191\n",
      "Epoch 89/100\n",
      "371/371 - 0s - 618us/step - loss: 1.7999 - rmse: 1.3275 - val_loss: 1.2954 - val_rmse: 1.1279\n",
      "Epoch 90/100\n",
      "371/371 - 0s - 613us/step - loss: 1.7349 - rmse: 1.3040 - val_loss: 1.2842 - val_rmse: 1.1234\n",
      "Epoch 91/100\n",
      "371/371 - 0s - 623us/step - loss: 1.7680 - rmse: 1.3155 - val_loss: 1.2649 - val_rmse: 1.1131\n",
      "Epoch 92/100\n",
      "371/371 - 0s - 620us/step - loss: 1.7440 - rmse: 1.3068 - val_loss: 1.2145 - val_rmse: 1.0908\n",
      "Epoch 93/100\n",
      "371/371 - 0s - 623us/step - loss: 1.7596 - rmse: 1.3112 - val_loss: 1.2484 - val_rmse: 1.1051\n",
      "Epoch 94/100\n",
      "371/371 - 0s - 614us/step - loss: 1.7295 - rmse: 1.2997 - val_loss: 1.2919 - val_rmse: 1.1231\n",
      "Epoch 95/100\n",
      "371/371 - 0s - 622us/step - loss: 1.7051 - rmse: 1.2899 - val_loss: 1.2762 - val_rmse: 1.1168\n",
      "Epoch 96/100\n",
      "371/371 - 0s - 616us/step - loss: 1.7327 - rmse: 1.3013 - val_loss: 1.2628 - val_rmse: 1.1099\n",
      "Epoch 97/100\n",
      "371/371 - 0s - 621us/step - loss: 1.7488 - rmse: 1.3100 - val_loss: 1.2712 - val_rmse: 1.1162\n",
      "Epoch 98/100\n",
      "371/371 - 0s - 602us/step - loss: 1.7037 - rmse: 1.2924 - val_loss: 1.2500 - val_rmse: 1.1047\n",
      "Epoch 99/100\n",
      "371/371 - 0s - 622us/step - loss: 1.7233 - rmse: 1.2998 - val_loss: 1.2563 - val_rmse: 1.1054\n",
      "Epoch 100/100\n",
      "371/371 - 0s - 615us/step - loss: 1.7147 - rmse: 1.2971 - val_loss: 1.2572 - val_rmse: 1.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 - 0s - 744us/step - loss: 1.5822 - rmse: 2.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - 902us/step - loss: 1.5511 - rmse: 2.3602\n",
      "75/75 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - 858us/step - loss: 1.5885 - rmse: 2.3852\n",
      "75/75 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - 857us/step - loss: 1.6048 - rmse: 2.3942\n",
      "75/75 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - 857us/step - loss: 1.5920 - rmse: 2.3699\n",
      "75/75 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 - 0s - 858us/step - loss: 1.6172 - rmse: 2.4032\n",
      "75/75 - 0s - 1ms/step\n",
      "01:03:44 - p16 - Predicting -\n",
      "8/8 - 0s - 9ms/step\n",
      "01:03:45 - p16 - Done -\n",
      "01:03:45 - p18 - Predicting for patient p18\n",
      "01:03:45 - p18 - Transforming the data -\n",
      "01:03:45 - p18 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 - 1s - 3ms/step - loss: 79.8563 - rmse: 8.8024 - val_loss: 28.4627 - val_rmse: 5.2963\n",
      "Epoch 2/100\n",
      "341/341 - 0s - 632us/step - loss: 19.9303 - rmse: 4.3725 - val_loss: 8.1498 - val_rmse: 2.8398\n",
      "Epoch 3/100\n",
      "341/341 - 0s - 649us/step - loss: 13.2601 - rmse: 3.6020 - val_loss: 7.6591 - val_rmse: 2.7571\n",
      "Epoch 4/100\n",
      "341/341 - 0s - 635us/step - loss: 12.1449 - rmse: 3.4485 - val_loss: 7.4025 - val_rmse: 2.7134\n",
      "Epoch 5/100\n",
      "341/341 - 0s - 675us/step - loss: 11.3491 - rmse: 3.3310 - val_loss: 7.2129 - val_rmse: 2.6793\n",
      "Epoch 6/100\n",
      "341/341 - 0s - 622us/step - loss: 10.3293 - rmse: 3.1811 - val_loss: 7.0517 - val_rmse: 2.6484\n",
      "Epoch 7/100\n",
      "341/341 - 0s - 618us/step - loss: 10.0997 - rmse: 3.1456 - val_loss: 6.9868 - val_rmse: 2.6414\n",
      "Epoch 8/100\n",
      "341/341 - 0s - 623us/step - loss: 9.9605 - rmse: 3.1257 - val_loss: 6.6800 - val_rmse: 2.5779\n",
      "Epoch 9/100\n",
      "341/341 - 0s - 616us/step - loss: 9.7309 - rmse: 3.0883 - val_loss: 6.7252 - val_rmse: 2.5852\n",
      "Epoch 10/100\n",
      "341/341 - 0s - 628us/step - loss: 9.4745 - rmse: 3.0455 - val_loss: 6.6582 - val_rmse: 2.5747\n",
      "Epoch 11/100\n",
      "341/341 - 0s - 616us/step - loss: 9.0043 - rmse: 2.9673 - val_loss: 6.4918 - val_rmse: 2.5410\n",
      "Epoch 12/100\n",
      "341/341 - 0s - 619us/step - loss: 9.1661 - rmse: 3.0008 - val_loss: 6.3162 - val_rmse: 2.5082\n",
      "Epoch 13/100\n",
      "341/341 - 0s - 625us/step - loss: 8.9658 - rmse: 2.9640 - val_loss: 6.3319 - val_rmse: 2.5109\n",
      "Epoch 14/100\n",
      "341/341 - 0s - 612us/step - loss: 8.9206 - rmse: 2.9611 - val_loss: 6.4873 - val_rmse: 2.5408\n",
      "Epoch 15/100\n",
      "341/341 - 0s - 629us/step - loss: 8.6526 - rmse: 2.9111 - val_loss: 6.1758 - val_rmse: 2.4789\n",
      "Epoch 16/100\n",
      "341/341 - 0s - 617us/step - loss: 8.6121 - rmse: 2.9034 - val_loss: 6.1583 - val_rmse: 2.4806\n",
      "Epoch 17/100\n",
      "341/341 - 0s - 622us/step - loss: 8.5448 - rmse: 2.8984 - val_loss: 6.2205 - val_rmse: 2.4898\n",
      "Epoch 18/100\n",
      "341/341 - 0s - 614us/step - loss: 8.5089 - rmse: 2.8887 - val_loss: 6.2389 - val_rmse: 2.4943\n",
      "Epoch 19/100\n",
      "341/341 - 0s - 613us/step - loss: 8.4080 - rmse: 2.8678 - val_loss: 6.1766 - val_rmse: 2.4852\n",
      "Epoch 20/100\n",
      "341/341 - 0s - 621us/step - loss: 8.3193 - rmse: 2.8570 - val_loss: 6.2205 - val_rmse: 2.4932\n",
      "Epoch 21/100\n",
      "341/341 - 0s - 614us/step - loss: 8.2714 - rmse: 2.8468 - val_loss: 6.0760 - val_rmse: 2.4669\n",
      "Epoch 22/100\n",
      "341/341 - 0s - 628us/step - loss: 7.9287 - rmse: 2.7897 - val_loss: 5.8269 - val_rmse: 2.4122\n",
      "Epoch 23/100\n",
      "341/341 - 0s - 618us/step - loss: 8.0583 - rmse: 2.8118 - val_loss: 5.6678 - val_rmse: 2.3742\n",
      "Epoch 24/100\n",
      "341/341 - 0s - 616us/step - loss: 7.8531 - rmse: 2.7767 - val_loss: 5.7668 - val_rmse: 2.3915\n",
      "Epoch 25/100\n",
      "341/341 - 0s - 624us/step - loss: 7.8742 - rmse: 2.7761 - val_loss: 5.4409 - val_rmse: 2.3256\n",
      "Epoch 26/100\n",
      "341/341 - 0s - 616us/step - loss: 7.9987 - rmse: 2.7971 - val_loss: 5.4735 - val_rmse: 2.3327\n",
      "Epoch 27/100\n",
      "341/341 - 0s - 619us/step - loss: 7.9536 - rmse: 2.7897 - val_loss: 5.7073 - val_rmse: 2.3790\n",
      "Epoch 28/100\n",
      "341/341 - 0s - 619us/step - loss: 7.7587 - rmse: 2.7585 - val_loss: 5.4778 - val_rmse: 2.3347\n",
      "Epoch 29/100\n",
      "341/341 - 0s - 636us/step - loss: 7.5619 - rmse: 2.7197 - val_loss: 5.3118 - val_rmse: 2.2966\n",
      "Epoch 30/100\n",
      "341/341 - 0s - 644us/step - loss: 7.6700 - rmse: 2.7417 - val_loss: 5.2731 - val_rmse: 2.2918\n",
      "Epoch 31/100\n",
      "341/341 - 0s - 627us/step - loss: 7.6214 - rmse: 2.7314 - val_loss: 5.3062 - val_rmse: 2.3025\n",
      "Epoch 32/100\n",
      "341/341 - 0s - 645us/step - loss: 7.4578 - rmse: 2.7013 - val_loss: 5.2339 - val_rmse: 2.2848\n",
      "Epoch 33/100\n",
      "341/341 - 0s - 627us/step - loss: 7.5025 - rmse: 2.7118 - val_loss: 5.2733 - val_rmse: 2.2913\n",
      "Epoch 34/100\n",
      "341/341 - 0s - 698us/step - loss: 7.6071 - rmse: 2.7250 - val_loss: 5.1235 - val_rmse: 2.2561\n",
      "Epoch 35/100\n",
      "341/341 - 0s - 638us/step - loss: 7.2972 - rmse: 2.6759 - val_loss: 5.0597 - val_rmse: 2.2404\n",
      "Epoch 36/100\n",
      "341/341 - 0s - 639us/step - loss: 7.3761 - rmse: 2.6922 - val_loss: 5.1774 - val_rmse: 2.2631\n",
      "Epoch 37/100\n",
      "341/341 - 0s - 643us/step - loss: 7.2058 - rmse: 2.6558 - val_loss: 5.0178 - val_rmse: 2.2332\n",
      "Epoch 38/100\n",
      "341/341 - 0s - 642us/step - loss: 7.3117 - rmse: 2.6706 - val_loss: 4.9746 - val_rmse: 2.2156\n",
      "Epoch 39/100\n",
      "341/341 - 0s - 640us/step - loss: 7.3466 - rmse: 2.6834 - val_loss: 5.1454 - val_rmse: 2.2577\n",
      "Epoch 40/100\n",
      "341/341 - 0s - 633us/step - loss: 7.3262 - rmse: 2.6813 - val_loss: 4.7847 - val_rmse: 2.1817\n",
      "Epoch 41/100\n",
      "341/341 - 0s - 627us/step - loss: 7.1340 - rmse: 2.6436 - val_loss: 5.0149 - val_rmse: 2.2286\n",
      "Epoch 42/100\n",
      "341/341 - 0s - 633us/step - loss: 7.1627 - rmse: 2.6475 - val_loss: 4.8111 - val_rmse: 2.1840\n",
      "Epoch 43/100\n",
      "341/341 - 0s - 624us/step - loss: 7.0232 - rmse: 2.6211 - val_loss: 4.7992 - val_rmse: 2.1763\n",
      "Epoch 44/100\n",
      "341/341 - 0s - 623us/step - loss: 6.9970 - rmse: 2.6212 - val_loss: 4.7732 - val_rmse: 2.1716\n",
      "Epoch 45/100\n",
      "341/341 - 0s - 618us/step - loss: 6.9585 - rmse: 2.6050 - val_loss: 4.8996 - val_rmse: 2.2051\n",
      "Epoch 46/100\n",
      "341/341 - 0s - 619us/step - loss: 6.8657 - rmse: 2.5900 - val_loss: 4.6976 - val_rmse: 2.1636\n",
      "Epoch 47/100\n",
      "341/341 - 0s - 617us/step - loss: 6.8716 - rmse: 2.5950 - val_loss: 4.8046 - val_rmse: 2.1834\n",
      "Epoch 48/100\n",
      "341/341 - 0s - 623us/step - loss: 6.9045 - rmse: 2.5996 - val_loss: 4.5576 - val_rmse: 2.1294\n",
      "Epoch 49/100\n",
      "341/341 - 0s - 629us/step - loss: 6.9342 - rmse: 2.6033 - val_loss: 4.5730 - val_rmse: 2.1336\n",
      "Epoch 50/100\n",
      "341/341 - 0s - 620us/step - loss: 6.5700 - rmse: 2.5381 - val_loss: 4.5869 - val_rmse: 2.1279\n",
      "Epoch 51/100\n",
      "341/341 - 0s - 616us/step - loss: 6.8006 - rmse: 2.5779 - val_loss: 4.6942 - val_rmse: 2.1509\n",
      "Epoch 52/100\n",
      "341/341 - 0s - 615us/step - loss: 6.8316 - rmse: 2.5809 - val_loss: 4.5693 - val_rmse: 2.1239\n",
      "Epoch 53/100\n",
      "341/341 - 0s - 620us/step - loss: 6.6932 - rmse: 2.5584 - val_loss: 4.5547 - val_rmse: 2.1196\n",
      "Epoch 54/100\n",
      "341/341 - 0s - 612us/step - loss: 6.6697 - rmse: 2.5540 - val_loss: 4.5575 - val_rmse: 2.1238\n",
      "Epoch 55/100\n",
      "341/341 - 0s - 881us/step - loss: 6.6327 - rmse: 2.5469 - val_loss: 4.4751 - val_rmse: 2.1038\n",
      "Epoch 56/100\n",
      "341/341 - 0s - 629us/step - loss: 6.5164 - rmse: 2.5248 - val_loss: 4.3794 - val_rmse: 2.0818\n",
      "Epoch 57/100\n",
      "341/341 - 0s - 625us/step - loss: 6.5731 - rmse: 2.5354 - val_loss: 4.4728 - val_rmse: 2.1044\n",
      "Epoch 58/100\n",
      "341/341 - 0s - 615us/step - loss: 6.6290 - rmse: 2.5483 - val_loss: 4.4140 - val_rmse: 2.0894\n",
      "Epoch 59/100\n",
      "341/341 - 0s - 620us/step - loss: 6.6690 - rmse: 2.5530 - val_loss: 4.4765 - val_rmse: 2.1008\n",
      "Epoch 60/100\n",
      "341/341 - 0s - 621us/step - loss: 6.5238 - rmse: 2.5228 - val_loss: 4.4039 - val_rmse: 2.0910\n",
      "Epoch 61/100\n",
      "341/341 - 0s - 622us/step - loss: 6.4774 - rmse: 2.5154 - val_loss: 4.2320 - val_rmse: 2.0460\n",
      "Epoch 62/100\n",
      "341/341 - 0s - 623us/step - loss: 6.2764 - rmse: 2.4789 - val_loss: 4.2841 - val_rmse: 2.0608\n",
      "Epoch 63/100\n",
      "341/341 - 0s - 610us/step - loss: 6.3023 - rmse: 2.4817 - val_loss: 4.2386 - val_rmse: 2.0470\n",
      "Epoch 64/100\n",
      "341/341 - 0s - 622us/step - loss: 6.3699 - rmse: 2.4940 - val_loss: 4.1963 - val_rmse: 2.0397\n",
      "Epoch 65/100\n",
      "341/341 - 0s - 617us/step - loss: 6.4990 - rmse: 2.5205 - val_loss: 4.2627 - val_rmse: 2.0545\n",
      "Epoch 66/100\n",
      "341/341 - 0s - 628us/step - loss: 6.3332 - rmse: 2.4874 - val_loss: 4.2751 - val_rmse: 2.0585\n",
      "Epoch 67/100\n",
      "341/341 - 0s - 614us/step - loss: 6.2835 - rmse: 2.4774 - val_loss: 4.3026 - val_rmse: 2.0697\n",
      "Epoch 68/100\n",
      "341/341 - 0s - 629us/step - loss: 6.3289 - rmse: 2.4886 - val_loss: 4.1761 - val_rmse: 2.0351\n",
      "Epoch 69/100\n",
      "341/341 - 0s - 623us/step - loss: 6.2458 - rmse: 2.4691 - val_loss: 3.9905 - val_rmse: 1.9897\n",
      "Epoch 70/100\n",
      "341/341 - 0s - 616us/step - loss: 6.3182 - rmse: 2.4891 - val_loss: 4.3350 - val_rmse: 2.0717\n",
      "Epoch 71/100\n",
      "341/341 - 0s - 623us/step - loss: 6.2912 - rmse: 2.4771 - val_loss: 4.0919 - val_rmse: 2.0120\n",
      "Epoch 72/100\n",
      "341/341 - 0s - 612us/step - loss: 6.0643 - rmse: 2.4361 - val_loss: 4.2584 - val_rmse: 2.0549\n",
      "Epoch 73/100\n",
      "341/341 - 0s - 615us/step - loss: 6.2893 - rmse: 2.4824 - val_loss: 4.1015 - val_rmse: 2.0156\n",
      "Epoch 74/100\n",
      "341/341 - 0s - 620us/step - loss: 6.1564 - rmse: 2.4537 - val_loss: 3.9452 - val_rmse: 1.9735\n",
      "Epoch 75/100\n",
      "341/341 - 0s - 621us/step - loss: 6.1137 - rmse: 2.4429 - val_loss: 4.0970 - val_rmse: 2.0151\n",
      "Epoch 76/100\n",
      "341/341 - 0s - 621us/step - loss: 6.0992 - rmse: 2.4463 - val_loss: 3.9105 - val_rmse: 1.9691\n",
      "Epoch 77/100\n",
      "341/341 - 0s - 616us/step - loss: 6.1117 - rmse: 2.4474 - val_loss: 3.9473 - val_rmse: 1.9728\n",
      "Epoch 78/100\n",
      "341/341 - 0s - 620us/step - loss: 6.0002 - rmse: 2.4209 - val_loss: 4.1353 - val_rmse: 2.0270\n",
      "Epoch 79/100\n",
      "341/341 - 0s - 619us/step - loss: 6.0649 - rmse: 2.4379 - val_loss: 4.0093 - val_rmse: 1.9911\n",
      "Epoch 80/100\n",
      "341/341 - 0s - 624us/step - loss: 5.9290 - rmse: 2.4075 - val_loss: 3.8416 - val_rmse: 1.9452\n",
      "Epoch 81/100\n",
      "341/341 - 0s - 623us/step - loss: 6.1312 - rmse: 2.4489 - val_loss: 4.1974 - val_rmse: 2.0454\n",
      "Epoch 82/100\n",
      "341/341 - 0s - 621us/step - loss: 5.9531 - rmse: 2.4108 - val_loss: 3.9130 - val_rmse: 1.9703\n",
      "Epoch 83/100\n",
      "341/341 - 0s - 624us/step - loss: 6.0002 - rmse: 2.4236 - val_loss: 3.8350 - val_rmse: 1.9511\n",
      "Epoch 84/100\n",
      "341/341 - 0s - 619us/step - loss: 5.9568 - rmse: 2.4155 - val_loss: 3.8581 - val_rmse: 1.9582\n",
      "Epoch 85/100\n",
      "341/341 - 0s - 620us/step - loss: 6.0513 - rmse: 2.4361 - val_loss: 3.8634 - val_rmse: 1.9574\n",
      "Epoch 86/100\n",
      "341/341 - 0s - 612us/step - loss: 6.0281 - rmse: 2.4261 - val_loss: 3.9303 - val_rmse: 1.9715\n",
      "Epoch 87/100\n",
      "341/341 - 0s - 613us/step - loss: 5.8603 - rmse: 2.3935 - val_loss: 3.8667 - val_rmse: 1.9579\n",
      "Epoch 88/100\n",
      "341/341 - 0s - 623us/step - loss: 5.9368 - rmse: 2.4121 - val_loss: 3.7672 - val_rmse: 1.9331\n",
      "Epoch 89/100\n",
      "341/341 - 0s - 619us/step - loss: 5.8038 - rmse: 2.3785 - val_loss: 3.8606 - val_rmse: 1.9609\n",
      "Epoch 90/100\n",
      "341/341 - 0s - 628us/step - loss: 5.9895 - rmse: 2.4226 - val_loss: 4.2308 - val_rmse: 2.0478\n",
      "Epoch 91/100\n",
      "341/341 - 0s - 628us/step - loss: 5.8052 - rmse: 2.3829 - val_loss: 3.7237 - val_rmse: 1.9202\n",
      "Epoch 92/100\n",
      "341/341 - 0s - 614us/step - loss: 5.8888 - rmse: 2.3949 - val_loss: 3.7597 - val_rmse: 1.9303\n",
      "Epoch 93/100\n",
      "341/341 - 0s - 619us/step - loss: 5.7351 - rmse: 2.3684 - val_loss: 3.6973 - val_rmse: 1.9091\n",
      "Epoch 94/100\n",
      "341/341 - 0s - 623us/step - loss: 5.8350 - rmse: 2.3891 - val_loss: 3.7963 - val_rmse: 1.9367\n",
      "Epoch 95/100\n",
      "341/341 - 0s - 623us/step - loss: 5.8288 - rmse: 2.3842 - val_loss: 3.7765 - val_rmse: 1.9330\n",
      "Epoch 96/100\n",
      "341/341 - 0s - 615us/step - loss: 5.7739 - rmse: 2.3767 - val_loss: 3.8660 - val_rmse: 1.9583\n",
      "Epoch 97/100\n",
      "341/341 - 0s - 626us/step - loss: 5.8605 - rmse: 2.3914 - val_loss: 3.7309 - val_rmse: 1.9200\n",
      "Epoch 98/100\n",
      "341/341 - 0s - 617us/step - loss: 5.7893 - rmse: 2.3753 - val_loss: 3.9631 - val_rmse: 1.9817\n",
      "Epoch 99/100\n",
      "341/341 - 0s - 632us/step - loss: 5.6312 - rmse: 2.3472 - val_loss: 3.6605 - val_rmse: 1.9036\n",
      "Epoch 100/100\n",
      "341/341 - 0s - 616us/step - loss: 5.6339 - rmse: 2.3445 - val_loss: 3.7113 - val_rmse: 1.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341/341 - 0s - 805us/step - loss: 5.1530 - rmse: 5.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 - 0s - 947us/step - loss: 4.9741 - rmse: 4.9614\n",
      "69/69 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 - 0s - 909us/step - loss: 5.4074 - rmse: 5.1946\n",
      "69/69 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 - 0s - 909us/step - loss: 5.3578 - rmse: 5.1427\n",
      "69/69 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 - 0s - 905us/step - loss: 4.9094 - rmse: 4.9294\n",
      "69/69 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 - 0s - 965us/step - loss: 5.2270 - rmse: 5.0595\n",
      "69/69 - 0s - 1ms/step\n",
      "01:05:23 - p18 - Predicting -\n",
      "8/8 - 0s - 9ms/step\n",
      "01:05:23 - p18 - Done -\n",
      "01:05:23 - p19 - Predicting for patient p19\n",
      "01:05:23 - p19 - Transforming the data -\n",
      "01:05:23 - p19 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 - 1s - 3ms/step - loss: 49.6992 - rmse: 6.8889 - val_loss: 17.2254 - val_rmse: 4.1324\n",
      "Epoch 2/100\n",
      "360/360 - 0s - 623us/step - loss: 10.3371 - rmse: 3.1660 - val_loss: 4.1145 - val_rmse: 2.0064\n",
      "Epoch 3/100\n",
      "360/360 - 0s - 611us/step - loss: 7.0980 - rmse: 2.6351 - val_loss: 3.5963 - val_rmse: 1.8738\n",
      "Epoch 4/100\n",
      "360/360 - 0s - 609us/step - loss: 6.3670 - rmse: 2.4947 - val_loss: 3.3998 - val_rmse: 1.8229\n",
      "Epoch 5/100\n",
      "360/360 - 0s - 602us/step - loss: 5.7247 - rmse: 2.3704 - val_loss: 3.3301 - val_rmse: 1.8015\n",
      "Epoch 6/100\n",
      "360/360 - 0s - 604us/step - loss: 5.3025 - rmse: 2.2791 - val_loss: 3.0762 - val_rmse: 1.7331\n",
      "Epoch 7/100\n",
      "360/360 - 0s - 601us/step - loss: 4.9296 - rmse: 2.1959 - val_loss: 3.1109 - val_rmse: 1.7399\n",
      "Epoch 8/100\n",
      "360/360 - 0s - 606us/step - loss: 4.8402 - rmse: 2.1784 - val_loss: 3.0395 - val_rmse: 1.7207\n",
      "Epoch 9/100\n",
      "360/360 - 0s - 609us/step - loss: 4.6508 - rmse: 2.1350 - val_loss: 3.0012 - val_rmse: 1.7099\n",
      "Epoch 10/100\n",
      "360/360 - 0s - 603us/step - loss: 4.5034 - rmse: 2.0994 - val_loss: 2.8857 - val_rmse: 1.6767\n",
      "Epoch 11/100\n",
      "360/360 - 0s - 608us/step - loss: 4.4264 - rmse: 2.0806 - val_loss: 3.0663 - val_rmse: 1.7309\n",
      "Epoch 12/100\n",
      "360/360 - 0s - 607us/step - loss: 4.3268 - rmse: 2.0558 - val_loss: 2.8398 - val_rmse: 1.6635\n",
      "Epoch 13/100\n",
      "360/360 - 0s - 605us/step - loss: 4.3475 - rmse: 2.0623 - val_loss: 2.8173 - val_rmse: 1.6576\n",
      "Epoch 14/100\n",
      "360/360 - 0s - 604us/step - loss: 4.1729 - rmse: 2.0215 - val_loss: 2.8848 - val_rmse: 1.6772\n",
      "Epoch 15/100\n",
      "360/360 - 0s - 602us/step - loss: 4.1124 - rmse: 2.0087 - val_loss: 2.7972 - val_rmse: 1.6520\n",
      "Epoch 16/100\n",
      "360/360 - 0s - 608us/step - loss: 4.0177 - rmse: 1.9810 - val_loss: 2.6676 - val_rmse: 1.6137\n",
      "Epoch 17/100\n",
      "360/360 - 0s - 604us/step - loss: 4.0766 - rmse: 1.9940 - val_loss: 2.6032 - val_rmse: 1.5943\n",
      "Epoch 18/100\n",
      "360/360 - 0s - 606us/step - loss: 3.9610 - rmse: 1.9696 - val_loss: 2.5308 - val_rmse: 1.5709\n",
      "Epoch 19/100\n",
      "360/360 - 0s - 597us/step - loss: 3.9088 - rmse: 1.9560 - val_loss: 2.5907 - val_rmse: 1.5898\n",
      "Epoch 20/100\n",
      "360/360 - 0s - 610us/step - loss: 3.8904 - rmse: 1.9511 - val_loss: 2.5350 - val_rmse: 1.5731\n",
      "Epoch 21/100\n",
      "360/360 - 0s - 613us/step - loss: 3.8102 - rmse: 1.9262 - val_loss: 2.4434 - val_rmse: 1.5440\n",
      "Epoch 22/100\n",
      "360/360 - 0s - 602us/step - loss: 3.7802 - rmse: 1.9208 - val_loss: 2.5003 - val_rmse: 1.5613\n",
      "Epoch 23/100\n",
      "360/360 - 0s - 607us/step - loss: 3.7698 - rmse: 1.9181 - val_loss: 2.3984 - val_rmse: 1.5306\n",
      "Epoch 24/100\n",
      "360/360 - 0s - 606us/step - loss: 3.7565 - rmse: 1.9182 - val_loss: 2.4225 - val_rmse: 1.5386\n",
      "Epoch 25/100\n",
      "360/360 - 0s - 607us/step - loss: 3.6590 - rmse: 1.8901 - val_loss: 2.3795 - val_rmse: 1.5260\n",
      "Epoch 26/100\n",
      "360/360 - 0s - 616us/step - loss: 3.6647 - rmse: 1.8939 - val_loss: 2.3766 - val_rmse: 1.5231\n",
      "Epoch 27/100\n",
      "360/360 - 0s - 614us/step - loss: 3.6708 - rmse: 1.8951 - val_loss: 2.3355 - val_rmse: 1.5096\n",
      "Epoch 28/100\n",
      "360/360 - 0s - 606us/step - loss: 3.5748 - rmse: 1.8696 - val_loss: 2.3545 - val_rmse: 1.5180\n",
      "Epoch 29/100\n",
      "360/360 - 0s - 610us/step - loss: 3.4907 - rmse: 1.8461 - val_loss: 2.2879 - val_rmse: 1.4943\n",
      "Epoch 30/100\n",
      "360/360 - 0s - 610us/step - loss: 3.5852 - rmse: 1.8735 - val_loss: 2.2644 - val_rmse: 1.4897\n",
      "Epoch 31/100\n",
      "360/360 - 0s - 605us/step - loss: 3.4409 - rmse: 1.8336 - val_loss: 2.2304 - val_rmse: 1.4783\n",
      "Epoch 32/100\n",
      "360/360 - 0s - 610us/step - loss: 3.5020 - rmse: 1.8493 - val_loss: 2.1874 - val_rmse: 1.4624\n",
      "Epoch 33/100\n",
      "360/360 - 0s - 603us/step - loss: 3.5085 - rmse: 1.8513 - val_loss: 2.2462 - val_rmse: 1.4832\n",
      "Epoch 34/100\n",
      "360/360 - 0s - 648us/step - loss: 3.5011 - rmse: 1.8485 - val_loss: 2.2391 - val_rmse: 1.4789\n",
      "Epoch 35/100\n",
      "360/360 - 0s - 617us/step - loss: 3.4039 - rmse: 1.8231 - val_loss: 2.2836 - val_rmse: 1.4958\n",
      "Epoch 36/100\n",
      "360/360 - 0s - 611us/step - loss: 3.3124 - rmse: 1.7986 - val_loss: 2.1137 - val_rmse: 1.4374\n",
      "Epoch 37/100\n",
      "360/360 - 0s - 603us/step - loss: 3.3411 - rmse: 1.8087 - val_loss: 2.1472 - val_rmse: 1.4484\n",
      "Epoch 38/100\n",
      "360/360 - 0s - 602us/step - loss: 3.3494 - rmse: 1.8118 - val_loss: 2.1333 - val_rmse: 1.4452\n",
      "Epoch 39/100\n",
      "360/360 - 0s - 616us/step - loss: 3.3639 - rmse: 1.8150 - val_loss: 2.1073 - val_rmse: 1.4343\n",
      "Epoch 40/100\n",
      "360/360 - 0s - 610us/step - loss: 3.3227 - rmse: 1.8027 - val_loss: 2.0319 - val_rmse: 1.4091\n",
      "Epoch 41/100\n",
      "360/360 - 0s - 608us/step - loss: 3.3056 - rmse: 1.7949 - val_loss: 2.1165 - val_rmse: 1.4418\n",
      "Epoch 42/100\n",
      "360/360 - 0s - 609us/step - loss: 3.2213 - rmse: 1.7718 - val_loss: 2.0141 - val_rmse: 1.4045\n",
      "Epoch 43/100\n",
      "360/360 - 0s - 604us/step - loss: 3.2180 - rmse: 1.7737 - val_loss: 2.0549 - val_rmse: 1.4195\n",
      "Epoch 44/100\n",
      "360/360 - 0s - 607us/step - loss: 3.1445 - rmse: 1.7542 - val_loss: 1.9725 - val_rmse: 1.3905\n",
      "Epoch 45/100\n",
      "360/360 - 0s - 606us/step - loss: 3.1030 - rmse: 1.7443 - val_loss: 2.0526 - val_rmse: 1.4169\n",
      "Epoch 46/100\n",
      "360/360 - 0s - 607us/step - loss: 3.1184 - rmse: 1.7450 - val_loss: 1.9198 - val_rmse: 1.3731\n",
      "Epoch 47/100\n",
      "360/360 - 0s - 607us/step - loss: 3.1821 - rmse: 1.7623 - val_loss: 1.9108 - val_rmse: 1.3666\n",
      "Epoch 48/100\n",
      "360/360 - 0s - 612us/step - loss: 3.0371 - rmse: 1.7234 - val_loss: 1.9509 - val_rmse: 1.3842\n",
      "Epoch 49/100\n",
      "360/360 - 0s - 607us/step - loss: 3.0292 - rmse: 1.7219 - val_loss: 1.9454 - val_rmse: 1.3817\n",
      "Epoch 50/100\n",
      "360/360 - 0s - 611us/step - loss: 3.0399 - rmse: 1.7242 - val_loss: 1.9029 - val_rmse: 1.3663\n",
      "Epoch 51/100\n",
      "360/360 - 0s - 609us/step - loss: 3.0484 - rmse: 1.7275 - val_loss: 1.9036 - val_rmse: 1.3666\n",
      "Epoch 52/100\n",
      "360/360 - 0s - 609us/step - loss: 3.0494 - rmse: 1.7263 - val_loss: 1.9278 - val_rmse: 1.3724\n",
      "Epoch 53/100\n",
      "360/360 - 0s - 609us/step - loss: 3.0015 - rmse: 1.7132 - val_loss: 1.8700 - val_rmse: 1.3548\n",
      "Epoch 54/100\n",
      "360/360 - 0s - 608us/step - loss: 2.9888 - rmse: 1.7096 - val_loss: 1.8878 - val_rmse: 1.3598\n",
      "Epoch 55/100\n",
      "360/360 - 0s - 609us/step - loss: 2.9888 - rmse: 1.7097 - val_loss: 1.8189 - val_rmse: 1.3357\n",
      "Epoch 56/100\n",
      "360/360 - 0s - 607us/step - loss: 2.9901 - rmse: 1.7087 - val_loss: 1.8328 - val_rmse: 1.3403\n",
      "Epoch 57/100\n",
      "360/360 - 0s - 614us/step - loss: 2.9232 - rmse: 1.6911 - val_loss: 1.7464 - val_rmse: 1.3080\n",
      "Epoch 58/100\n",
      "360/360 - 0s - 606us/step - loss: 2.8919 - rmse: 1.6791 - val_loss: 1.7866 - val_rmse: 1.3238\n",
      "Epoch 59/100\n",
      "360/360 - 0s - 604us/step - loss: 2.9159 - rmse: 1.6878 - val_loss: 1.7893 - val_rmse: 1.3242\n",
      "Epoch 60/100\n",
      "360/360 - 0s - 601us/step - loss: 2.8857 - rmse: 1.6796 - val_loss: 1.8344 - val_rmse: 1.3404\n",
      "Epoch 61/100\n",
      "360/360 - 0s - 600us/step - loss: 2.8859 - rmse: 1.6788 - val_loss: 1.7829 - val_rmse: 1.3243\n",
      "Epoch 62/100\n",
      "360/360 - 0s - 613us/step - loss: 2.8254 - rmse: 1.6606 - val_loss: 1.7754 - val_rmse: 1.3204\n",
      "Epoch 63/100\n",
      "360/360 - 0s - 606us/step - loss: 2.8386 - rmse: 1.6653 - val_loss: 1.7221 - val_rmse: 1.2988\n",
      "Epoch 64/100\n",
      "360/360 - 0s - 606us/step - loss: 2.8683 - rmse: 1.6738 - val_loss: 1.7615 - val_rmse: 1.3172\n",
      "Epoch 65/100\n",
      "360/360 - 0s - 602us/step - loss: 2.7317 - rmse: 1.6362 - val_loss: 1.6832 - val_rmse: 1.2868\n",
      "Epoch 66/100\n",
      "360/360 - 0s - 609us/step - loss: 2.8551 - rmse: 1.6678 - val_loss: 1.7373 - val_rmse: 1.3067\n",
      "Epoch 67/100\n",
      "360/360 - 0s - 602us/step - loss: 2.7813 - rmse: 1.6478 - val_loss: 1.7149 - val_rmse: 1.2973\n",
      "Epoch 68/100\n",
      "360/360 - 0s - 605us/step - loss: 2.7873 - rmse: 1.6501 - val_loss: 1.6776 - val_rmse: 1.2836\n",
      "Epoch 69/100\n",
      "360/360 - 0s - 606us/step - loss: 2.8086 - rmse: 1.6539 - val_loss: 1.6753 - val_rmse: 1.2833\n",
      "Epoch 70/100\n",
      "360/360 - 0s - 600us/step - loss: 2.7656 - rmse: 1.6435 - val_loss: 1.7129 - val_rmse: 1.2961\n",
      "Epoch 71/100\n",
      "360/360 - 0s - 610us/step - loss: 2.7069 - rmse: 1.6271 - val_loss: 1.6781 - val_rmse: 1.2834\n",
      "Epoch 72/100\n",
      "360/360 - 0s - 604us/step - loss: 2.7571 - rmse: 1.6441 - val_loss: 1.5794 - val_rmse: 1.2459\n",
      "Epoch 73/100\n",
      "360/360 - 0s - 618us/step - loss: 2.7407 - rmse: 1.6378 - val_loss: 1.6707 - val_rmse: 1.2806\n",
      "Epoch 74/100\n",
      "360/360 - 0s - 604us/step - loss: 2.7662 - rmse: 1.6440 - val_loss: 1.6832 - val_rmse: 1.2857\n",
      "Epoch 75/100\n",
      "360/360 - 0s - 600us/step - loss: 2.7012 - rmse: 1.6259 - val_loss: 1.5998 - val_rmse: 1.2524\n",
      "Epoch 76/100\n",
      "360/360 - 0s - 607us/step - loss: 2.7102 - rmse: 1.6262 - val_loss: 1.7035 - val_rmse: 1.2935\n",
      "Epoch 77/100\n",
      "360/360 - 0s - 603us/step - loss: 2.6237 - rmse: 1.6027 - val_loss: 1.6974 - val_rmse: 1.2911\n",
      "Epoch 78/100\n",
      "360/360 - 0s - 607us/step - loss: 2.6784 - rmse: 1.6163 - val_loss: 1.6388 - val_rmse: 1.2682\n",
      "Epoch 79/100\n",
      "360/360 - 0s - 608us/step - loss: 2.6478 - rmse: 1.6074 - val_loss: 1.6205 - val_rmse: 1.2607\n",
      "Epoch 80/100\n",
      "360/360 - 0s - 608us/step - loss: 2.5914 - rmse: 1.5920 - val_loss: 1.6784 - val_rmse: 1.2836\n",
      "Epoch 81/100\n",
      "360/360 - 0s - 602us/step - loss: 2.6785 - rmse: 1.6198 - val_loss: 1.6462 - val_rmse: 1.2708\n",
      "Epoch 82/100\n",
      "360/360 - 0s - 608us/step - loss: 2.5669 - rmse: 1.5831 - val_loss: 1.6453 - val_rmse: 1.2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 - 0s - 728us/step - loss: 2.3967 - rmse: 3.4217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 - 0s - 870us/step - loss: 2.3907 - rmse: 3.5208\n",
      "72/72 - 0s - 778us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 - 0s - 839us/step - loss: 2.3811 - rmse: 3.3828\n",
      "72/72 - 0s - 780us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 - 0s - 892us/step - loss: 2.4320 - rmse: 3.3948\n",
      "72/72 - 0s - 775us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 - 0s - 845us/step - loss: 2.4068 - rmse: 3.4707\n",
      "72/72 - 0s - 777us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 - 0s - 835us/step - loss: 2.3731 - rmse: 3.3628\n",
      "72/72 - 0s - 791us/step\n",
      "01:06:54 - p19 - Predicting -\n",
      "8/8 - 0s - 9ms/step\n",
      "01:06:54 - p19 - Done -\n",
      "01:06:54 - p21 - Predicting for patient p21\n",
      "01:06:54 - p21 - Transforming the data -\n",
      "01:06:54 - p21 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 - 1s - 3ms/step - loss: 99.5960 - rmse: 9.8445 - val_loss: 39.6095 - val_rmse: 6.2583\n",
      "Epoch 2/100\n",
      "326/326 - 0s - 648us/step - loss: 24.0441 - rmse: 4.7544 - val_loss: 7.9416 - val_rmse: 2.7998\n",
      "Epoch 3/100\n",
      "326/326 - 0s - 635us/step - loss: 13.4965 - rmse: 3.6351 - val_loss: 6.7918 - val_rmse: 2.5871\n",
      "Epoch 4/100\n",
      "326/326 - 0s - 623us/step - loss: 12.2098 - rmse: 3.4557 - val_loss: 6.4189 - val_rmse: 2.5175\n",
      "Epoch 5/100\n",
      "326/326 - 0s - 630us/step - loss: 11.2885 - rmse: 3.3253 - val_loss: 6.1712 - val_rmse: 2.4682\n",
      "Epoch 6/100\n",
      "326/326 - 0s - 633us/step - loss: 10.8156 - rmse: 3.2544 - val_loss: 6.1294 - val_rmse: 2.4594\n",
      "Epoch 7/100\n",
      "326/326 - 0s - 636us/step - loss: 10.2150 - rmse: 3.1615 - val_loss: 5.9818 - val_rmse: 2.4306\n",
      "Epoch 8/100\n",
      "326/326 - 0s - 638us/step - loss: 10.0099 - rmse: 3.1272 - val_loss: 5.8494 - val_rmse: 2.4067\n",
      "Epoch 9/100\n",
      "326/326 - 0s - 624us/step - loss: 9.4233 - rmse: 3.0368 - val_loss: 5.8038 - val_rmse: 2.3945\n",
      "Epoch 10/100\n",
      "326/326 - 0s - 641us/step - loss: 9.2321 - rmse: 3.0056 - val_loss: 5.6768 - val_rmse: 2.3704\n",
      "Epoch 11/100\n",
      "326/326 - 0s - 622us/step - loss: 9.0505 - rmse: 2.9724 - val_loss: 5.6847 - val_rmse: 2.3719\n",
      "Epoch 12/100\n",
      "326/326 - 0s - 638us/step - loss: 9.0922 - rmse: 2.9775 - val_loss: 5.5144 - val_rmse: 2.3369\n",
      "Epoch 13/100\n",
      "326/326 - 0s - 635us/step - loss: 8.8590 - rmse: 2.9497 - val_loss: 5.4878 - val_rmse: 2.3318\n",
      "Epoch 14/100\n",
      "326/326 - 0s - 642us/step - loss: 8.8076 - rmse: 2.9349 - val_loss: 5.3961 - val_rmse: 2.3119\n",
      "Epoch 15/100\n",
      "326/326 - 0s - 630us/step - loss: 8.4635 - rmse: 2.8770 - val_loss: 5.3068 - val_rmse: 2.2940\n",
      "Epoch 16/100\n",
      "326/326 - 0s - 623us/step - loss: 8.5179 - rmse: 2.8827 - val_loss: 5.3827 - val_rmse: 2.3110\n",
      "Epoch 17/100\n",
      "326/326 - 0s - 628us/step - loss: 8.5804 - rmse: 2.8972 - val_loss: 5.2500 - val_rmse: 2.2812\n",
      "Epoch 18/100\n",
      "326/326 - 0s - 629us/step - loss: 8.1045 - rmse: 2.8157 - val_loss: 5.2156 - val_rmse: 2.2740\n",
      "Epoch 19/100\n",
      "326/326 - 0s - 623us/step - loss: 8.4293 - rmse: 2.8673 - val_loss: 5.0651 - val_rmse: 2.2411\n",
      "Epoch 20/100\n",
      "326/326 - 0s - 626us/step - loss: 8.2616 - rmse: 2.8410 - val_loss: 5.1208 - val_rmse: 2.2551\n",
      "Epoch 21/100\n",
      "326/326 - 0s - 624us/step - loss: 8.2399 - rmse: 2.8351 - val_loss: 5.0053 - val_rmse: 2.2291\n",
      "Epoch 22/100\n",
      "326/326 - 0s - 632us/step - loss: 8.0167 - rmse: 2.8000 - val_loss: 5.0190 - val_rmse: 2.2298\n",
      "Epoch 23/100\n",
      "326/326 - 0s - 630us/step - loss: 8.1348 - rmse: 2.8211 - val_loss: 5.2004 - val_rmse: 2.2667\n",
      "Epoch 24/100\n",
      "326/326 - 0s - 622us/step - loss: 7.8613 - rmse: 2.7687 - val_loss: 4.9133 - val_rmse: 2.2052\n",
      "Epoch 25/100\n",
      "326/326 - 0s - 639us/step - loss: 7.8073 - rmse: 2.7636 - val_loss: 4.9044 - val_rmse: 2.2013\n",
      "Epoch 26/100\n",
      "326/326 - 0s - 625us/step - loss: 7.8570 - rmse: 2.7668 - val_loss: 4.8729 - val_rmse: 2.1977\n",
      "Epoch 27/100\n",
      "326/326 - 0s - 636us/step - loss: 7.7354 - rmse: 2.7490 - val_loss: 4.8498 - val_rmse: 2.1920\n",
      "Epoch 28/100\n",
      "326/326 - 0s - 624us/step - loss: 7.6231 - rmse: 2.7309 - val_loss: 4.8199 - val_rmse: 2.1848\n",
      "Epoch 29/100\n",
      "326/326 - 0s - 624us/step - loss: 7.6159 - rmse: 2.7255 - val_loss: 4.7044 - val_rmse: 2.1591\n",
      "Epoch 30/100\n",
      "326/326 - 0s - 624us/step - loss: 7.6212 - rmse: 2.7245 - val_loss: 4.7202 - val_rmse: 2.1610\n",
      "Epoch 31/100\n",
      "326/326 - 0s - 623us/step - loss: 7.6467 - rmse: 2.7327 - val_loss: 4.5489 - val_rmse: 2.1176\n",
      "Epoch 32/100\n",
      "326/326 - 0s - 651us/step - loss: 7.5902 - rmse: 2.7198 - val_loss: 4.5140 - val_rmse: 2.1093\n",
      "Epoch 33/100\n",
      "326/326 - 0s - 632us/step - loss: 7.5312 - rmse: 2.7140 - val_loss: 4.5764 - val_rmse: 2.1263\n",
      "Epoch 34/100\n",
      "326/326 - 0s - 632us/step - loss: 7.5392 - rmse: 2.7133 - val_loss: 4.5644 - val_rmse: 2.1206\n",
      "Epoch 35/100\n",
      "326/326 - 0s - 632us/step - loss: 7.3858 - rmse: 2.6852 - val_loss: 4.5130 - val_rmse: 2.1089\n",
      "Epoch 36/100\n",
      "326/326 - 0s - 624us/step - loss: 7.4239 - rmse: 2.6965 - val_loss: 4.5761 - val_rmse: 2.1183\n",
      "Epoch 37/100\n",
      "326/326 - 0s - 636us/step - loss: 7.2795 - rmse: 2.6637 - val_loss: 4.5307 - val_rmse: 2.1096\n",
      "Epoch 38/100\n",
      "326/326 - 0s - 626us/step - loss: 7.2866 - rmse: 2.6689 - val_loss: 4.4364 - val_rmse: 2.0877\n",
      "Epoch 39/100\n",
      "326/326 - 0s - 626us/step - loss: 7.1947 - rmse: 2.6531 - val_loss: 4.2692 - val_rmse: 2.0512\n",
      "Epoch 40/100\n",
      "326/326 - 0s - 636us/step - loss: 7.1263 - rmse: 2.6421 - val_loss: 4.2805 - val_rmse: 2.0543\n",
      "Epoch 41/100\n",
      "326/326 - 0s - 622us/step - loss: 7.2281 - rmse: 2.6571 - val_loss: 4.3632 - val_rmse: 2.0712\n",
      "Epoch 42/100\n",
      "326/326 - 0s - 637us/step - loss: 6.9933 - rmse: 2.6129 - val_loss: 4.3443 - val_rmse: 2.0690\n",
      "Epoch 43/100\n",
      "326/326 - 0s - 624us/step - loss: 6.9745 - rmse: 2.6123 - val_loss: 4.2340 - val_rmse: 2.0387\n",
      "Epoch 44/100\n",
      "326/326 - 0s - 624us/step - loss: 7.0802 - rmse: 2.6296 - val_loss: 4.3357 - val_rmse: 2.0640\n",
      "Epoch 45/100\n",
      "326/326 - 0s - 621us/step - loss: 7.0925 - rmse: 2.6292 - val_loss: 4.2813 - val_rmse: 2.0557\n",
      "Epoch 46/100\n",
      "326/326 - 0s - 626us/step - loss: 6.9728 - rmse: 2.6056 - val_loss: 4.1425 - val_rmse: 2.0185\n",
      "Epoch 47/100\n",
      "326/326 - 0s - 635us/step - loss: 6.9016 - rmse: 2.5945 - val_loss: 4.1247 - val_rmse: 2.0129\n",
      "Epoch 48/100\n",
      "326/326 - 0s - 624us/step - loss: 6.9217 - rmse: 2.5974 - val_loss: 4.2009 - val_rmse: 2.0316\n",
      "Epoch 49/100\n",
      "326/326 - 0s - 628us/step - loss: 7.0032 - rmse: 2.6113 - val_loss: 4.1246 - val_rmse: 2.0139\n",
      "Epoch 50/100\n",
      "326/326 - 0s - 622us/step - loss: 6.9063 - rmse: 2.5987 - val_loss: 4.1745 - val_rmse: 2.0279\n",
      "Epoch 51/100\n",
      "326/326 - 0s - 638us/step - loss: 6.8747 - rmse: 2.5901 - val_loss: 4.1219 - val_rmse: 2.0150\n",
      "Epoch 52/100\n",
      "326/326 - 0s - 628us/step - loss: 6.6908 - rmse: 2.5515 - val_loss: 4.1636 - val_rmse: 2.0232\n",
      "Epoch 53/100\n",
      "326/326 - 0s - 620us/step - loss: 6.5849 - rmse: 2.5386 - val_loss: 4.1283 - val_rmse: 2.0192\n",
      "Epoch 54/100\n",
      "326/326 - 0s - 630us/step - loss: 6.7663 - rmse: 2.5707 - val_loss: 4.0482 - val_rmse: 1.9988\n",
      "Epoch 55/100\n",
      "326/326 - 0s - 624us/step - loss: 6.8001 - rmse: 2.5764 - val_loss: 3.9078 - val_rmse: 1.9634\n",
      "Epoch 56/100\n",
      "326/326 - 0s - 636us/step - loss: 6.7000 - rmse: 2.5539 - val_loss: 3.8653 - val_rmse: 1.9513\n",
      "Epoch 57/100\n",
      "326/326 - 0s - 631us/step - loss: 6.7705 - rmse: 2.5667 - val_loss: 3.9298 - val_rmse: 1.9705\n",
      "Epoch 58/100\n",
      "326/326 - 0s - 634us/step - loss: 6.5611 - rmse: 2.5333 - val_loss: 3.8544 - val_rmse: 1.9486\n",
      "Epoch 59/100\n",
      "326/326 - 0s - 631us/step - loss: 6.6415 - rmse: 2.5449 - val_loss: 3.8389 - val_rmse: 1.9462\n",
      "Epoch 60/100\n",
      "326/326 - 0s - 632us/step - loss: 6.7073 - rmse: 2.5601 - val_loss: 4.0834 - val_rmse: 2.0052\n",
      "Epoch 61/100\n",
      "326/326 - 0s - 626us/step - loss: 6.5147 - rmse: 2.5183 - val_loss: 3.9155 - val_rmse: 1.9641\n",
      "Epoch 62/100\n",
      "326/326 - 0s - 635us/step - loss: 6.6447 - rmse: 2.5445 - val_loss: 3.8888 - val_rmse: 1.9595\n",
      "Epoch 63/100\n",
      "326/326 - 0s - 622us/step - loss: 6.4526 - rmse: 2.5086 - val_loss: 3.8828 - val_rmse: 1.9548\n",
      "Epoch 64/100\n",
      "326/326 - 0s - 631us/step - loss: 6.3801 - rmse: 2.4963 - val_loss: 3.7535 - val_rmse: 1.9222\n",
      "Epoch 65/100\n",
      "326/326 - 0s - 625us/step - loss: 6.4500 - rmse: 2.5088 - val_loss: 3.7740 - val_rmse: 1.9261\n",
      "Epoch 66/100\n",
      "326/326 - 0s - 631us/step - loss: 6.3325 - rmse: 2.4872 - val_loss: 3.6955 - val_rmse: 1.9071\n",
      "Epoch 67/100\n",
      "326/326 - 0s - 627us/step - loss: 6.3756 - rmse: 2.4933 - val_loss: 3.7389 - val_rmse: 1.9204\n",
      "Epoch 68/100\n",
      "326/326 - 0s - 651us/step - loss: 6.4202 - rmse: 2.5040 - val_loss: 3.6654 - val_rmse: 1.8998\n",
      "Epoch 69/100\n",
      "326/326 - 0s - 646us/step - loss: 6.2659 - rmse: 2.4725 - val_loss: 3.6014 - val_rmse: 1.8834\n",
      "Epoch 70/100\n",
      "326/326 - 0s - 632us/step - loss: 6.4997 - rmse: 2.5121 - val_loss: 3.6572 - val_rmse: 1.8959\n",
      "Epoch 71/100\n",
      "326/326 - 0s - 629us/step - loss: 6.2034 - rmse: 2.4632 - val_loss: 3.6511 - val_rmse: 1.8961\n",
      "Epoch 72/100\n",
      "326/326 - 0s - 623us/step - loss: 6.3613 - rmse: 2.4902 - val_loss: 3.6149 - val_rmse: 1.8834\n",
      "Epoch 73/100\n",
      "326/326 - 0s - 621us/step - loss: 6.3194 - rmse: 2.4866 - val_loss: 3.6419 - val_rmse: 1.8925\n",
      "Epoch 74/100\n",
      "326/326 - 0s - 633us/step - loss: 6.3552 - rmse: 2.4922 - val_loss: 3.8128 - val_rmse: 1.9356\n",
      "Epoch 75/100\n",
      "326/326 - 0s - 634us/step - loss: 6.3653 - rmse: 2.4908 - val_loss: 3.6012 - val_rmse: 1.8824\n",
      "Epoch 76/100\n",
      "326/326 - 0s - 632us/step - loss: 6.2487 - rmse: 2.4704 - val_loss: 3.6345 - val_rmse: 1.8909\n",
      "Epoch 77/100\n",
      "326/326 - 0s - 619us/step - loss: 6.3016 - rmse: 2.4814 - val_loss: 3.6704 - val_rmse: 1.9022\n",
      "Epoch 78/100\n",
      "326/326 - 0s - 633us/step - loss: 6.2086 - rmse: 2.4586 - val_loss: 3.4629 - val_rmse: 1.8461\n",
      "Epoch 79/100\n",
      "326/326 - 0s - 629us/step - loss: 6.1301 - rmse: 2.4446 - val_loss: 3.4890 - val_rmse: 1.8518\n",
      "Epoch 80/100\n",
      "326/326 - 0s - 656us/step - loss: 6.0191 - rmse: 2.4281 - val_loss: 3.5063 - val_rmse: 1.8562\n",
      "Epoch 81/100\n",
      "326/326 - 0s - 630us/step - loss: 6.0607 - rmse: 2.4333 - val_loss: 3.5099 - val_rmse: 1.8567\n",
      "Epoch 82/100\n",
      "326/326 - 0s - 630us/step - loss: 6.1227 - rmse: 2.4416 - val_loss: 3.4921 - val_rmse: 1.8506\n",
      "Epoch 83/100\n",
      "326/326 - 0s - 618us/step - loss: 6.1578 - rmse: 2.4473 - val_loss: 3.5002 - val_rmse: 1.8544\n",
      "Epoch 84/100\n",
      "326/326 - 0s - 692us/step - loss: 6.1297 - rmse: 2.4425 - val_loss: 3.5353 - val_rmse: 1.8613\n",
      "Epoch 85/100\n",
      "326/326 - 0s - 632us/step - loss: 6.1320 - rmse: 2.4462 - val_loss: 3.6081 - val_rmse: 1.8806\n",
      "Epoch 86/100\n",
      "326/326 - 0s - 633us/step - loss: 6.0561 - rmse: 2.4252 - val_loss: 3.4061 - val_rmse: 1.8288\n",
      "Epoch 87/100\n",
      "326/326 - 0s - 623us/step - loss: 6.0881 - rmse: 2.4341 - val_loss: 3.6565 - val_rmse: 1.8975\n",
      "Epoch 88/100\n",
      "326/326 - 0s - 627us/step - loss: 6.0417 - rmse: 2.4278 - val_loss: 3.4901 - val_rmse: 1.8509\n",
      "Epoch 89/100\n",
      "326/326 - 0s - 623us/step - loss: 6.0648 - rmse: 2.4344 - val_loss: 3.4964 - val_rmse: 1.8546\n",
      "Epoch 90/100\n",
      "326/326 - 0s - 634us/step - loss: 5.9681 - rmse: 2.4123 - val_loss: 3.4764 - val_rmse: 1.8459\n",
      "Epoch 91/100\n",
      "326/326 - 0s - 630us/step - loss: 5.9297 - rmse: 2.4044 - val_loss: 3.4335 - val_rmse: 1.8376\n",
      "Epoch 92/100\n",
      "326/326 - 0s - 624us/step - loss: 5.9437 - rmse: 2.4116 - val_loss: 3.4263 - val_rmse: 1.8338\n",
      "Epoch 93/100\n",
      "326/326 - 0s - 636us/step - loss: 5.8838 - rmse: 2.3968 - val_loss: 3.4444 - val_rmse: 1.8382\n",
      "Epoch 94/100\n",
      "326/326 - 0s - 624us/step - loss: 5.8724 - rmse: 2.3874 - val_loss: 3.3438 - val_rmse: 1.8114\n",
      "Epoch 95/100\n",
      "326/326 - 0s - 633us/step - loss: 6.0025 - rmse: 2.4181 - val_loss: 3.3124 - val_rmse: 1.8071\n",
      "Epoch 96/100\n",
      "326/326 - 0s - 631us/step - loss: 5.9444 - rmse: 2.4125 - val_loss: 3.3116 - val_rmse: 1.8072\n",
      "Epoch 97/100\n",
      "326/326 - 0s - 619us/step - loss: 5.9430 - rmse: 2.4036 - val_loss: 3.3444 - val_rmse: 1.8117\n",
      "Epoch 98/100\n",
      "326/326 - 0s - 629us/step - loss: 5.7869 - rmse: 2.3734 - val_loss: 3.3406 - val_rmse: 1.8105\n",
      "Epoch 99/100\n",
      "326/326 - 0s - 624us/step - loss: 5.9398 - rmse: 2.4079 - val_loss: 3.3606 - val_rmse: 1.8145\n",
      "Epoch 100/100\n",
      "326/326 - 0s - 626us/step - loss: 5.9109 - rmse: 2.3971 - val_loss: 3.3593 - val_rmse: 1.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326/326 - 0s - 1ms/step - loss: 5.2466 - rmse: 5.4109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 0s - 963us/step - loss: 5.0732 - rmse: 5.1980\n",
      "66/66 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 0s - 937us/step - loss: 5.5276 - rmse: 5.4836\n",
      "66/66 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 0s - 936us/step - loss: 5.3082 - rmse: 5.5871\n",
      "66/66 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 0s - 943us/step - loss: 5.3928 - rmse: 5.5108\n",
      "66/66 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 - 0s - 932us/step - loss: 4.8382 - rmse: 5.4212\n",
      "66/66 - 0s - 1ms/step\n",
      "01:08:30 - p21 - Predicting -\n",
      "8/8 - 0s - 9ms/step\n",
      "01:08:30 - p21 - Done -\n",
      "01:08:30 - p22 - Predicting for patient p22\n",
      "01:08:30 - p22 - Transforming the data -\n",
      "01:08:30 - p22 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 - 1s - 3ms/step - loss: 51.5794 - rmse: 7.0901 - val_loss: 24.9049 - val_rmse: 4.9978\n",
      "Epoch 2/100\n",
      "291/291 - 0s - 639us/step - loss: 14.2376 - rmse: 3.6872 - val_loss: 5.3123 - val_rmse: 2.2846\n",
      "Epoch 3/100\n",
      "291/291 - 0s - 623us/step - loss: 8.7920 - rmse: 2.9340 - val_loss: 4.6888 - val_rmse: 2.1405\n",
      "Epoch 4/100\n",
      "291/291 - 0s - 625us/step - loss: 7.7700 - rmse: 2.7578 - val_loss: 4.3164 - val_rmse: 2.0468\n",
      "Epoch 5/100\n",
      "291/291 - 0s - 622us/step - loss: 7.1072 - rmse: 2.6360 - val_loss: 4.2557 - val_rmse: 2.0371\n",
      "Epoch 6/100\n",
      "291/291 - 0s - 626us/step - loss: 6.6629 - rmse: 2.5534 - val_loss: 4.2457 - val_rmse: 2.0322\n",
      "Epoch 7/100\n",
      "291/291 - 0s - 623us/step - loss: 6.5471 - rmse: 2.5305 - val_loss: 4.0882 - val_rmse: 1.9961\n",
      "Epoch 8/100\n",
      "291/291 - 0s - 625us/step - loss: 6.1278 - rmse: 2.4460 - val_loss: 4.0505 - val_rmse: 1.9856\n",
      "Epoch 9/100\n",
      "291/291 - 0s - 627us/step - loss: 5.9178 - rmse: 2.4057 - val_loss: 4.0081 - val_rmse: 1.9728\n",
      "Epoch 10/100\n",
      "291/291 - 0s - 623us/step - loss: 5.8370 - rmse: 2.3888 - val_loss: 3.8869 - val_rmse: 1.9422\n",
      "Epoch 11/100\n",
      "291/291 - 0s - 623us/step - loss: 5.6456 - rmse: 2.3477 - val_loss: 3.9429 - val_rmse: 1.9604\n",
      "Epoch 12/100\n",
      "291/291 - 0s - 623us/step - loss: 5.5611 - rmse: 2.3294 - val_loss: 3.8599 - val_rmse: 1.9397\n",
      "Epoch 13/100\n",
      "291/291 - 0s - 619us/step - loss: 5.4726 - rmse: 2.3135 - val_loss: 3.8080 - val_rmse: 1.9244\n",
      "Epoch 14/100\n",
      "291/291 - 0s - 627us/step - loss: 5.4162 - rmse: 2.3006 - val_loss: 3.7115 - val_rmse: 1.9000\n",
      "Epoch 15/100\n",
      "291/291 - 0s - 626us/step - loss: 5.3359 - rmse: 2.2834 - val_loss: 3.6958 - val_rmse: 1.8962\n",
      "Epoch 16/100\n",
      "291/291 - 0s - 620us/step - loss: 5.1999 - rmse: 2.2518 - val_loss: 3.6116 - val_rmse: 1.8728\n",
      "Epoch 17/100\n",
      "291/291 - 0s - 627us/step - loss: 5.1178 - rmse: 2.2338 - val_loss: 3.6764 - val_rmse: 1.8904\n",
      "Epoch 18/100\n",
      "291/291 - 0s - 622us/step - loss: 5.2260 - rmse: 2.2592 - val_loss: 3.6137 - val_rmse: 1.8744\n",
      "Epoch 19/100\n",
      "291/291 - 0s - 621us/step - loss: 5.1274 - rmse: 2.2383 - val_loss: 3.5853 - val_rmse: 1.8647\n",
      "Epoch 20/100\n",
      "291/291 - 0s - 632us/step - loss: 5.0662 - rmse: 2.2220 - val_loss: 3.5562 - val_rmse: 1.8644\n",
      "Epoch 21/100\n",
      "291/291 - 0s - 635us/step - loss: 5.0789 - rmse: 2.2250 - val_loss: 3.5539 - val_rmse: 1.8616\n",
      "Epoch 22/100\n",
      "291/291 - 0s - 626us/step - loss: 4.9821 - rmse: 2.2067 - val_loss: 3.5868 - val_rmse: 1.8697\n",
      "Epoch 23/100\n",
      "291/291 - 0s - 631us/step - loss: 4.9437 - rmse: 2.1946 - val_loss: 3.5203 - val_rmse: 1.8555\n",
      "Epoch 24/100\n",
      "291/291 - 0s - 624us/step - loss: 4.9296 - rmse: 2.1920 - val_loss: 3.4291 - val_rmse: 1.8229\n",
      "Epoch 25/100\n",
      "291/291 - 0s - 633us/step - loss: 4.8782 - rmse: 2.1799 - val_loss: 3.4126 - val_rmse: 1.8216\n",
      "Epoch 26/100\n",
      "291/291 - 0s - 626us/step - loss: 4.7394 - rmse: 2.1505 - val_loss: 3.3589 - val_rmse: 1.8031\n",
      "Epoch 27/100\n",
      "291/291 - 0s - 627us/step - loss: 4.8625 - rmse: 2.1818 - val_loss: 3.3245 - val_rmse: 1.7980\n",
      "Epoch 28/100\n",
      "291/291 - 0s - 626us/step - loss: 4.6922 - rmse: 2.1413 - val_loss: 3.2415 - val_rmse: 1.7740\n",
      "Epoch 29/100\n",
      "291/291 - 0s - 624us/step - loss: 4.7918 - rmse: 2.1645 - val_loss: 3.4527 - val_rmse: 1.8337\n",
      "Epoch 30/100\n",
      "291/291 - 0s - 613us/step - loss: 4.7506 - rmse: 2.1543 - val_loss: 3.2624 - val_rmse: 1.7801\n",
      "Epoch 31/100\n",
      "291/291 - 0s - 624us/step - loss: 4.7080 - rmse: 2.1409 - val_loss: 3.2283 - val_rmse: 1.7681\n",
      "Epoch 32/100\n",
      "291/291 - 0s - 622us/step - loss: 4.6356 - rmse: 2.1258 - val_loss: 3.1886 - val_rmse: 1.7571\n",
      "Epoch 33/100\n",
      "291/291 - 0s - 626us/step - loss: 4.5840 - rmse: 2.1113 - val_loss: 3.2273 - val_rmse: 1.7724\n",
      "Epoch 34/100\n",
      "291/291 - 0s - 626us/step - loss: 4.6010 - rmse: 2.1172 - val_loss: 3.1810 - val_rmse: 1.7562\n",
      "Epoch 35/100\n",
      "291/291 - 0s - 623us/step - loss: 4.5841 - rmse: 2.1175 - val_loss: 3.1333 - val_rmse: 1.7444\n",
      "Epoch 36/100\n",
      "291/291 - 0s - 631us/step - loss: 4.4784 - rmse: 2.0902 - val_loss: 3.2802 - val_rmse: 1.7902\n",
      "Epoch 37/100\n",
      "291/291 - 0s - 626us/step - loss: 4.4387 - rmse: 2.0776 - val_loss: 3.1158 - val_rmse: 1.7401\n",
      "Epoch 38/100\n",
      "291/291 - 0s - 620us/step - loss: 4.5433 - rmse: 2.1041 - val_loss: 3.1426 - val_rmse: 1.7477\n",
      "Epoch 39/100\n",
      "291/291 - 0s - 630us/step - loss: 4.4702 - rmse: 2.0869 - val_loss: 3.0528 - val_rmse: 1.7248\n",
      "Epoch 40/100\n",
      "291/291 - 0s - 618us/step - loss: 4.4327 - rmse: 2.0761 - val_loss: 2.9917 - val_rmse: 1.7061\n",
      "Epoch 41/100\n",
      "291/291 - 0s - 615us/step - loss: 4.4240 - rmse: 2.0756 - val_loss: 3.1218 - val_rmse: 1.7456\n",
      "Epoch 42/100\n",
      "291/291 - 0s - 623us/step - loss: 4.4390 - rmse: 2.0831 - val_loss: 3.0456 - val_rmse: 1.7225\n",
      "Epoch 43/100\n",
      "291/291 - 0s - 622us/step - loss: 4.2974 - rmse: 2.0472 - val_loss: 3.0008 - val_rmse: 1.7061\n",
      "Epoch 44/100\n",
      "291/291 - 0s - 623us/step - loss: 4.2361 - rmse: 2.0347 - val_loss: 2.9819 - val_rmse: 1.7038\n",
      "Epoch 45/100\n",
      "291/291 - 0s - 622us/step - loss: 4.1510 - rmse: 2.0096 - val_loss: 2.8842 - val_rmse: 1.6757\n",
      "Epoch 46/100\n",
      "291/291 - 0s - 618us/step - loss: 4.2688 - rmse: 2.0417 - val_loss: 2.9969 - val_rmse: 1.7078\n",
      "Epoch 47/100\n",
      "291/291 - 0s - 629us/step - loss: 4.3498 - rmse: 2.0599 - val_loss: 2.8704 - val_rmse: 1.6720\n",
      "Epoch 48/100\n",
      "291/291 - 0s - 624us/step - loss: 4.2328 - rmse: 2.0336 - val_loss: 2.9261 - val_rmse: 1.6903\n",
      "Epoch 49/100\n",
      "291/291 - 0s - 617us/step - loss: 4.0917 - rmse: 1.9965 - val_loss: 2.9527 - val_rmse: 1.6953\n",
      "Epoch 50/100\n",
      "291/291 - 0s - 625us/step - loss: 4.2643 - rmse: 2.0397 - val_loss: 2.8469 - val_rmse: 1.6641\n",
      "Epoch 51/100\n",
      "291/291 - 0s - 630us/step - loss: 4.1617 - rmse: 2.0165 - val_loss: 2.8396 - val_rmse: 1.6660\n",
      "Epoch 52/100\n",
      "291/291 - 0s - 620us/step - loss: 4.0950 - rmse: 1.9965 - val_loss: 2.7996 - val_rmse: 1.6492\n",
      "Epoch 53/100\n",
      "291/291 - 0s - 626us/step - loss: 4.2190 - rmse: 2.0249 - val_loss: 2.8662 - val_rmse: 1.6708\n",
      "Epoch 54/100\n",
      "291/291 - 0s - 618us/step - loss: 4.0811 - rmse: 1.9967 - val_loss: 2.8113 - val_rmse: 1.6554\n",
      "Epoch 55/100\n",
      "291/291 - 0s - 621us/step - loss: 4.0861 - rmse: 1.9945 - val_loss: 2.7781 - val_rmse: 1.6432\n",
      "Epoch 56/100\n",
      "291/291 - 0s - 624us/step - loss: 4.0699 - rmse: 1.9910 - val_loss: 2.8040 - val_rmse: 1.6530\n",
      "Epoch 57/100\n",
      "291/291 - 0s - 623us/step - loss: 4.1237 - rmse: 2.0028 - val_loss: 2.6993 - val_rmse: 1.6156\n",
      "Epoch 58/100\n",
      "291/291 - 0s - 629us/step - loss: 3.9773 - rmse: 1.9711 - val_loss: 2.7169 - val_rmse: 1.6236\n",
      "Epoch 59/100\n",
      "291/291 - 0s - 620us/step - loss: 3.9527 - rmse: 1.9646 - val_loss: 2.7397 - val_rmse: 1.6281\n",
      "Epoch 60/100\n",
      "291/291 - 0s - 624us/step - loss: 4.0314 - rmse: 1.9793 - val_loss: 2.6858 - val_rmse: 1.6134\n",
      "Epoch 61/100\n",
      "291/291 - 0s - 624us/step - loss: 3.8842 - rmse: 1.9493 - val_loss: 2.7067 - val_rmse: 1.6187\n",
      "Epoch 62/100\n",
      "291/291 - 0s - 616us/step - loss: 3.8847 - rmse: 1.9462 - val_loss: 2.6276 - val_rmse: 1.5937\n",
      "Epoch 63/100\n",
      "291/291 - 0s - 621us/step - loss: 3.9645 - rmse: 1.9653 - val_loss: 2.6531 - val_rmse: 1.6025\n",
      "Epoch 64/100\n",
      "291/291 - 0s - 629us/step - loss: 3.9979 - rmse: 1.9745 - val_loss: 2.6227 - val_rmse: 1.5967\n",
      "Epoch 65/100\n",
      "291/291 - 0s - 621us/step - loss: 3.9033 - rmse: 1.9490 - val_loss: 2.5716 - val_rmse: 1.5805\n",
      "Epoch 66/100\n",
      "291/291 - 0s - 619us/step - loss: 3.8695 - rmse: 1.9413 - val_loss: 2.6562 - val_rmse: 1.6108\n",
      "Epoch 67/100\n",
      "291/291 - 0s - 625us/step - loss: 3.8629 - rmse: 1.9390 - val_loss: 2.5931 - val_rmse: 1.5896\n",
      "Epoch 68/100\n",
      "291/291 - 0s - 617us/step - loss: 3.8140 - rmse: 1.9297 - val_loss: 2.5726 - val_rmse: 1.5806\n",
      "Epoch 69/100\n",
      "291/291 - 0s - 630us/step - loss: 3.9543 - rmse: 1.9591 - val_loss: 2.5459 - val_rmse: 1.5754\n",
      "Epoch 70/100\n",
      "291/291 - 0s - 628us/step - loss: 3.7699 - rmse: 1.9167 - val_loss: 2.5003 - val_rmse: 1.5595\n",
      "Epoch 71/100\n",
      "291/291 - 0s - 616us/step - loss: 3.7825 - rmse: 1.9209 - val_loss: 2.5299 - val_rmse: 1.5721\n",
      "Epoch 72/100\n",
      "291/291 - 0s - 626us/step - loss: 3.8306 - rmse: 1.9313 - val_loss: 2.5806 - val_rmse: 1.5871\n",
      "Epoch 73/100\n",
      "291/291 - 0s - 617us/step - loss: 3.7919 - rmse: 1.9233 - val_loss: 2.5458 - val_rmse: 1.5753\n",
      "Epoch 74/100\n",
      "291/291 - 0s - 618us/step - loss: 3.7311 - rmse: 1.9075 - val_loss: 2.5254 - val_rmse: 1.5686\n",
      "Epoch 75/100\n",
      "291/291 - 0s - 627us/step - loss: 3.7616 - rmse: 1.9144 - val_loss: 2.5601 - val_rmse: 1.5791\n",
      "Epoch 76/100\n",
      "291/291 - 0s - 618us/step - loss: 3.7448 - rmse: 1.9105 - val_loss: 2.5231 - val_rmse: 1.5682\n",
      "Epoch 77/100\n",
      "291/291 - 0s - 618us/step - loss: 3.6561 - rmse: 1.8903 - val_loss: 2.6476 - val_rmse: 1.5988\n",
      "Epoch 78/100\n",
      "291/291 - 0s - 626us/step - loss: 3.7147 - rmse: 1.8977 - val_loss: 2.4509 - val_rmse: 1.5432\n",
      "Epoch 79/100\n",
      "291/291 - 0s - 618us/step - loss: 3.6877 - rmse: 1.8956 - val_loss: 2.5108 - val_rmse: 1.5641\n",
      "Epoch 80/100\n",
      "291/291 - 0s - 621us/step - loss: 3.6255 - rmse: 1.8801 - val_loss: 2.4979 - val_rmse: 1.5606\n",
      "Epoch 81/100\n",
      "291/291 - 0s - 628us/step - loss: 3.7685 - rmse: 1.9171 - val_loss: 2.5202 - val_rmse: 1.5682\n",
      "Epoch 82/100\n",
      "291/291 - 0s - 619us/step - loss: 3.6676 - rmse: 1.8889 - val_loss: 2.4518 - val_rmse: 1.5467\n",
      "Epoch 83/100\n",
      "291/291 - 0s - 628us/step - loss: 3.6767 - rmse: 1.8925 - val_loss: 2.4636 - val_rmse: 1.5496\n",
      "Epoch 84/100\n",
      "291/291 - 0s - 616us/step - loss: 3.7053 - rmse: 1.8980 - val_loss: 2.4968 - val_rmse: 1.5595\n",
      "Epoch 85/100\n",
      "291/291 - 0s - 617us/step - loss: 3.5513 - rmse: 1.8630 - val_loss: 2.5176 - val_rmse: 1.5668\n",
      "Epoch 86/100\n",
      "291/291 - 0s - 626us/step - loss: 3.6271 - rmse: 1.8799 - val_loss: 2.4355 - val_rmse: 1.5398\n",
      "Epoch 87/100\n",
      "291/291 - 0s - 624us/step - loss: 3.7053 - rmse: 1.9012 - val_loss: 2.4118 - val_rmse: 1.5325\n",
      "Epoch 88/100\n",
      "291/291 - 0s - 621us/step - loss: 3.7126 - rmse: 1.9056 - val_loss: 2.5341 - val_rmse: 1.5731\n",
      "Epoch 89/100\n",
      "291/291 - 0s - 624us/step - loss: 3.6522 - rmse: 1.8886 - val_loss: 2.3844 - val_rmse: 1.5210\n",
      "Epoch 90/100\n",
      "291/291 - 0s - 618us/step - loss: 3.6276 - rmse: 1.8827 - val_loss: 2.4315 - val_rmse: 1.5380\n",
      "Epoch 91/100\n",
      "291/291 - 0s - 621us/step - loss: 3.6144 - rmse: 1.8770 - val_loss: 2.3572 - val_rmse: 1.5148\n",
      "Epoch 92/100\n",
      "291/291 - 0s - 624us/step - loss: 3.5557 - rmse: 1.8622 - val_loss: 2.3690 - val_rmse: 1.5179\n",
      "Epoch 93/100\n",
      "291/291 - 0s - 618us/step - loss: 3.6418 - rmse: 1.8841 - val_loss: 2.3846 - val_rmse: 1.5223\n",
      "Epoch 94/100\n",
      "291/291 - 0s - 627us/step - loss: 3.5702 - rmse: 1.8652 - val_loss: 2.3341 - val_rmse: 1.5090\n",
      "Epoch 95/100\n",
      "291/291 - 0s - 621us/step - loss: 3.4868 - rmse: 1.8445 - val_loss: 2.3690 - val_rmse: 1.5206\n",
      "Epoch 96/100\n",
      "291/291 - 0s - 619us/step - loss: 3.4535 - rmse: 1.8330 - val_loss: 2.3570 - val_rmse: 1.5139\n",
      "Epoch 97/100\n",
      "291/291 - 0s - 636us/step - loss: 3.4936 - rmse: 1.8461 - val_loss: 2.3871 - val_rmse: 1.5276\n",
      "Epoch 98/100\n",
      "291/291 - 0s - 616us/step - loss: 3.5313 - rmse: 1.8546 - val_loss: 2.3674 - val_rmse: 1.5182\n",
      "Epoch 99/100\n",
      "291/291 - 0s - 628us/step - loss: 3.4478 - rmse: 1.8326 - val_loss: 2.2758 - val_rmse: 1.4879\n",
      "Epoch 100/100\n",
      "291/291 - 0s - 623us/step - loss: 3.4692 - rmse: 1.8426 - val_loss: 2.3402 - val_rmse: 1.5087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 - 0s - 836us/step - loss: 3.2399 - rmse: 3.4710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 - 0s - 1ms/step - loss: 3.2364 - rmse: 3.5319\n",
      "59/59 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 - 0s - 1ms/step - loss: 3.2298 - rmse: 3.3796\n",
      "59/59 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 - 0s - 1ms/step - loss: 3.0751 - rmse: 3.4760\n",
      "59/59 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 - 0s - 1ms/step - loss: 3.2527 - rmse: 3.5454\n",
      "59/59 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/233 - 0s - 1ms/step - loss: 3.1090 - rmse: 3.4143\n",
      "59/59 - 0s - 1ms/step\n",
      "01:10:00 - p22 - Predicting -\n",
      "7/7 - 0s - 11ms/step\n",
      "01:10:01 - p22 - Done -\n",
      "01:10:01 - p24 - Predicting for patient p24\n",
      "01:10:01 - p24 - Transforming the data -\n",
      "01:10:01 - p24 - Fitting the model -\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 - 1s - 4ms/step - loss: 42.2683 - rmse: 6.3190 - val_loss: 11.3973 - val_rmse: 3.3575\n",
      "Epoch 2/100\n",
      "389/389 - 0s - 645us/step - loss: 8.5753 - rmse: 2.8859 - val_loss: 4.3318 - val_rmse: 2.0553\n",
      "Epoch 3/100\n",
      "389/389 - 0s - 624us/step - loss: 6.7001 - rmse: 2.5605 - val_loss: 3.9220 - val_rmse: 1.9518\n",
      "Epoch 4/100\n",
      "389/389 - 0s - 632us/step - loss: 5.8715 - rmse: 2.3936 - val_loss: 3.8107 - val_rmse: 1.9248\n",
      "Epoch 5/100\n",
      "389/389 - 0s - 627us/step - loss: 5.5553 - rmse: 2.3258 - val_loss: 3.6899 - val_rmse: 1.8940\n",
      "Epoch 6/100\n",
      "389/389 - 0s - 627us/step - loss: 5.2374 - rmse: 2.2608 - val_loss: 3.6261 - val_rmse: 1.8782\n",
      "Epoch 7/100\n",
      "389/389 - 0s - 622us/step - loss: 5.0681 - rmse: 2.2298 - val_loss: 3.6889 - val_rmse: 1.8962\n",
      "Epoch 8/100\n",
      "389/389 - 0s - 634us/step - loss: 4.9023 - rmse: 2.1852 - val_loss: 3.6202 - val_rmse: 1.8790\n",
      "Epoch 9/100\n",
      "389/389 - 0s - 624us/step - loss: 4.6637 - rmse: 2.1308 - val_loss: 3.5430 - val_rmse: 1.8573\n",
      "Epoch 10/100\n",
      "389/389 - 0s - 631us/step - loss: 4.5859 - rmse: 2.1134 - val_loss: 3.4514 - val_rmse: 1.8345\n",
      "Epoch 11/100\n",
      "389/389 - 0s - 624us/step - loss: 4.5019 - rmse: 2.0965 - val_loss: 3.5324 - val_rmse: 1.8540\n",
      "Epoch 12/100\n",
      "389/389 - 0s - 639us/step - loss: 4.4729 - rmse: 2.0884 - val_loss: 3.3963 - val_rmse: 1.8191\n",
      "Epoch 13/100\n",
      "389/389 - 0s - 624us/step - loss: 4.3904 - rmse: 2.0707 - val_loss: 3.3221 - val_rmse: 1.7993\n",
      "Epoch 14/100\n",
      "389/389 - 0s - 626us/step - loss: 4.3579 - rmse: 2.0616 - val_loss: 3.3034 - val_rmse: 1.7952\n",
      "Epoch 15/100\n",
      "389/389 - 0s - 621us/step - loss: 4.2328 - rmse: 2.0306 - val_loss: 3.2427 - val_rmse: 1.7774\n",
      "Epoch 16/100\n",
      "389/389 - 0s - 631us/step - loss: 4.2037 - rmse: 2.0265 - val_loss: 3.2588 - val_rmse: 1.7818\n",
      "Epoch 17/100\n",
      "389/389 - 0s - 619us/step - loss: 4.1899 - rmse: 2.0181 - val_loss: 3.2532 - val_rmse: 1.7816\n",
      "Epoch 18/100\n",
      "389/389 - 0s - 623us/step - loss: 4.1353 - rmse: 2.0077 - val_loss: 3.2570 - val_rmse: 1.7828\n",
      "Epoch 19/100\n",
      "389/389 - 0s - 622us/step - loss: 4.0994 - rmse: 1.9998 - val_loss: 3.1928 - val_rmse: 1.7630\n",
      "Epoch 20/100\n",
      "389/389 - 0s - 635us/step - loss: 4.0134 - rmse: 1.9796 - val_loss: 3.0891 - val_rmse: 1.7345\n",
      "Epoch 21/100\n",
      "389/389 - 0s - 626us/step - loss: 4.0177 - rmse: 1.9828 - val_loss: 3.0403 - val_rmse: 1.7240\n",
      "Epoch 22/100\n",
      "389/389 - 0s - 623us/step - loss: 4.0050 - rmse: 1.9772 - val_loss: 2.9769 - val_rmse: 1.7040\n",
      "Epoch 23/100\n",
      "389/389 - 0s - 617us/step - loss: 3.9241 - rmse: 1.9575 - val_loss: 3.0406 - val_rmse: 1.7216\n",
      "Epoch 24/100\n",
      "389/389 - 0s - 629us/step - loss: 3.8273 - rmse: 1.9347 - val_loss: 3.0430 - val_rmse: 1.7241\n",
      "Epoch 25/100\n",
      "389/389 - 0s - 619us/step - loss: 3.8863 - rmse: 1.9477 - val_loss: 2.9777 - val_rmse: 1.7045\n",
      "Epoch 26/100\n",
      "389/389 - 0s - 632us/step - loss: 3.8702 - rmse: 1.9434 - val_loss: 2.9273 - val_rmse: 1.6894\n",
      "Epoch 27/100\n",
      "389/389 - 0s - 626us/step - loss: 3.7543 - rmse: 1.9116 - val_loss: 2.8760 - val_rmse: 1.6744\n",
      "Epoch 28/100\n",
      "389/389 - 0s - 626us/step - loss: 3.7507 - rmse: 1.9096 - val_loss: 2.7970 - val_rmse: 1.6522\n",
      "Epoch 29/100\n",
      "389/389 - 0s - 627us/step - loss: 3.7436 - rmse: 1.9087 - val_loss: 2.7924 - val_rmse: 1.6484\n",
      "Epoch 30/100\n",
      "389/389 - 0s - 625us/step - loss: 3.7129 - rmse: 1.9020 - val_loss: 2.7793 - val_rmse: 1.6463\n",
      "Epoch 31/100\n",
      "389/389 - 0s - 617us/step - loss: 3.6688 - rmse: 1.8921 - val_loss: 2.7967 - val_rmse: 1.6515\n",
      "Epoch 32/100\n",
      "389/389 - 0s - 631us/step - loss: 3.6798 - rmse: 1.8950 - val_loss: 2.7636 - val_rmse: 1.6430\n",
      "Epoch 33/100\n",
      "389/389 - 0s - 630us/step - loss: 3.5999 - rmse: 1.8730 - val_loss: 2.6988 - val_rmse: 1.6223\n",
      "Epoch 34/100\n",
      "389/389 - 0s - 624us/step - loss: 3.5893 - rmse: 1.8704 - val_loss: 2.7295 - val_rmse: 1.6324\n",
      "Epoch 35/100\n",
      "389/389 - 0s - 622us/step - loss: 3.5770 - rmse: 1.8685 - val_loss: 2.7016 - val_rmse: 1.6231\n",
      "Epoch 36/100\n",
      "389/389 - 0s - 626us/step - loss: 3.5210 - rmse: 1.8528 - val_loss: 2.6320 - val_rmse: 1.6029\n",
      "Epoch 37/100\n",
      "389/389 - 0s - 627us/step - loss: 3.5233 - rmse: 1.8534 - val_loss: 2.5970 - val_rmse: 1.5941\n",
      "Epoch 38/100\n",
      "389/389 - 0s - 624us/step - loss: 3.5221 - rmse: 1.8495 - val_loss: 2.5566 - val_rmse: 1.5808\n",
      "Epoch 39/100\n",
      "389/389 - 0s - 629us/step - loss: 3.4792 - rmse: 1.8422 - val_loss: 2.5632 - val_rmse: 1.5823\n",
      "Epoch 40/100\n",
      "389/389 - 0s - 627us/step - loss: 3.4325 - rmse: 1.8309 - val_loss: 2.5552 - val_rmse: 1.5815\n",
      "Epoch 41/100\n",
      "389/389 - 0s - 629us/step - loss: 3.3774 - rmse: 1.8147 - val_loss: 2.5695 - val_rmse: 1.5834\n",
      "Epoch 42/100\n",
      "389/389 - 0s - 622us/step - loss: 3.3718 - rmse: 1.8158 - val_loss: 2.5156 - val_rmse: 1.5679\n",
      "Epoch 43/100\n",
      "389/389 - 0s - 627us/step - loss: 3.3945 - rmse: 1.8177 - val_loss: 2.5311 - val_rmse: 1.5736\n",
      "Epoch 44/100\n",
      "389/389 - 0s - 626us/step - loss: 3.3320 - rmse: 1.8009 - val_loss: 2.4351 - val_rmse: 1.5408\n",
      "Epoch 45/100\n",
      "389/389 - 0s - 629us/step - loss: 3.2988 - rmse: 1.7884 - val_loss: 2.4247 - val_rmse: 1.5387\n",
      "Epoch 46/100\n",
      "389/389 - 0s - 627us/step - loss: 3.3135 - rmse: 1.7954 - val_loss: 2.4143 - val_rmse: 1.5344\n",
      "Epoch 47/100\n",
      "389/389 - 0s - 626us/step - loss: 3.3312 - rmse: 1.8010 - val_loss: 2.3841 - val_rmse: 1.5251\n",
      "Epoch 48/100\n",
      "389/389 - 0s - 621us/step - loss: 3.2052 - rmse: 1.7691 - val_loss: 2.4288 - val_rmse: 1.5393\n",
      "Epoch 49/100\n",
      "389/389 - 0s - 627us/step - loss: 3.2566 - rmse: 1.7833 - val_loss: 2.4477 - val_rmse: 1.5475\n",
      "Epoch 50/100\n",
      "389/389 - 0s - 618us/step - loss: 3.2324 - rmse: 1.7763 - val_loss: 2.3906 - val_rmse: 1.5260\n",
      "Epoch 51/100\n",
      "389/389 - 0s - 630us/step - loss: 3.2457 - rmse: 1.7779 - val_loss: 2.3658 - val_rmse: 1.5208\n",
      "Epoch 52/100\n",
      "389/389 - 0s - 622us/step - loss: 3.1652 - rmse: 1.7558 - val_loss: 2.3366 - val_rmse: 1.5101\n",
      "Epoch 53/100\n",
      "389/389 - 0s - 633us/step - loss: 3.1788 - rmse: 1.7568 - val_loss: 2.2960 - val_rmse: 1.4969\n",
      "Epoch 54/100\n",
      "389/389 - 0s - 618us/step - loss: 3.1714 - rmse: 1.7611 - val_loss: 2.3494 - val_rmse: 1.5136\n",
      "Epoch 55/100\n",
      "389/389 - 0s - 626us/step - loss: 3.1978 - rmse: 1.7650 - val_loss: 2.3057 - val_rmse: 1.5022\n",
      "Epoch 56/100\n",
      "389/389 - 0s - 628us/step - loss: 3.1386 - rmse: 1.7458 - val_loss: 2.2763 - val_rmse: 1.4917\n",
      "Epoch 57/100\n",
      "389/389 - 0s - 627us/step - loss: 3.1428 - rmse: 1.7482 - val_loss: 2.2938 - val_rmse: 1.4973\n",
      "Epoch 58/100\n",
      "389/389 - 0s - 622us/step - loss: 3.1405 - rmse: 1.7506 - val_loss: 2.2611 - val_rmse: 1.4883\n",
      "Epoch 59/100\n",
      "389/389 - 0s - 619us/step - loss: 3.0397 - rmse: 1.7198 - val_loss: 2.2614 - val_rmse: 1.4881\n",
      "Epoch 60/100\n",
      "389/389 - 0s - 621us/step - loss: 3.0705 - rmse: 1.7279 - val_loss: 2.1918 - val_rmse: 1.4644\n",
      "Epoch 61/100\n",
      "389/389 - 0s - 630us/step - loss: 3.0192 - rmse: 1.7149 - val_loss: 2.2107 - val_rmse: 1.4716\n",
      "Epoch 62/100\n",
      "389/389 - 0s - 620us/step - loss: 3.0094 - rmse: 1.7145 - val_loss: 2.2250 - val_rmse: 1.4760\n",
      "Epoch 63/100\n",
      "389/389 - 0s - 624us/step - loss: 3.0103 - rmse: 1.7123 - val_loss: 2.1130 - val_rmse: 1.4380\n",
      "Epoch 64/100\n",
      "389/389 - 0s - 622us/step - loss: 2.9785 - rmse: 1.7042 - val_loss: 2.1387 - val_rmse: 1.4468\n",
      "Epoch 65/100\n",
      "389/389 - 0s - 627us/step - loss: 3.0458 - rmse: 1.7224 - val_loss: 2.1429 - val_rmse: 1.4487\n",
      "Epoch 66/100\n",
      "389/389 - 0s - 632us/step - loss: 2.9397 - rmse: 1.6924 - val_loss: 2.1640 - val_rmse: 1.4555\n",
      "Epoch 67/100\n",
      "389/389 - 0s - 617us/step - loss: 2.9457 - rmse: 1.6959 - val_loss: 2.1563 - val_rmse: 1.4526\n",
      "Epoch 68/100\n",
      "389/389 - 0s - 624us/step - loss: 3.0144 - rmse: 1.7137 - val_loss: 2.1546 - val_rmse: 1.4519\n",
      "Epoch 69/100\n",
      "389/389 - 0s - 625us/step - loss: 2.9979 - rmse: 1.7068 - val_loss: 2.1067 - val_rmse: 1.4356\n",
      "Epoch 70/100\n",
      "389/389 - 0s - 629us/step - loss: 2.9436 - rmse: 1.6927 - val_loss: 2.0814 - val_rmse: 1.4263\n",
      "Epoch 71/100\n",
      "389/389 - 0s - 623us/step - loss: 2.9309 - rmse: 1.6883 - val_loss: 2.0849 - val_rmse: 1.4272\n",
      "Epoch 72/100\n",
      "389/389 - 0s - 630us/step - loss: 2.9322 - rmse: 1.6897 - val_loss: 2.0933 - val_rmse: 1.4292\n",
      "Epoch 73/100\n",
      "389/389 - 0s - 624us/step - loss: 2.9036 - rmse: 1.6821 - val_loss: 2.0969 - val_rmse: 1.4307\n",
      "Epoch 74/100\n",
      "389/389 - 0s - 622us/step - loss: 2.8877 - rmse: 1.6775 - val_loss: 2.1005 - val_rmse: 1.4328\n",
      "Epoch 75/100\n",
      "389/389 - 0s - 634us/step - loss: 2.8761 - rmse: 1.6745 - val_loss: 2.0677 - val_rmse: 1.4217\n",
      "Epoch 76/100\n",
      "389/389 - 0s - 628us/step - loss: 2.9289 - rmse: 1.6896 - val_loss: 2.1082 - val_rmse: 1.4347\n",
      "Epoch 77/100\n",
      "389/389 - 0s - 625us/step - loss: 2.8469 - rmse: 1.6662 - val_loss: 2.0606 - val_rmse: 1.4205\n",
      "Epoch 78/100\n",
      "389/389 - 0s - 625us/step - loss: 2.8163 - rmse: 1.6589 - val_loss: 2.0017 - val_rmse: 1.3991\n",
      "Epoch 79/100\n",
      "389/389 - 0s - 613us/step - loss: 2.7964 - rmse: 1.6479 - val_loss: 1.9615 - val_rmse: 1.3833\n",
      "Epoch 80/100\n",
      "389/389 - 0s - 621us/step - loss: 2.8384 - rmse: 1.6667 - val_loss: 1.9777 - val_rmse: 1.3900\n",
      "Epoch 81/100\n",
      "389/389 - 0s - 625us/step - loss: 2.7854 - rmse: 1.6504 - val_loss: 1.9695 - val_rmse: 1.3869\n",
      "Epoch 82/100\n",
      "389/389 - 0s - 630us/step - loss: 2.8510 - rmse: 1.6675 - val_loss: 1.9549 - val_rmse: 1.3830\n",
      "Epoch 83/100\n",
      "389/389 - 0s - 621us/step - loss: 2.7708 - rmse: 1.6407 - val_loss: 1.9359 - val_rmse: 1.3760\n",
      "Epoch 84/100\n",
      "389/389 - 0s - 630us/step - loss: 2.7491 - rmse: 1.6391 - val_loss: 1.9318 - val_rmse: 1.3759\n",
      "Epoch 85/100\n",
      "389/389 - 0s - 625us/step - loss: 2.7736 - rmse: 1.6449 - val_loss: 1.9921 - val_rmse: 1.3963\n",
      "Epoch 86/100\n",
      "389/389 - 0s - 627us/step - loss: 2.7968 - rmse: 1.6513 - val_loss: 1.9877 - val_rmse: 1.3943\n",
      "Epoch 87/100\n",
      "389/389 - 0s - 627us/step - loss: 2.7987 - rmse: 1.6480 - val_loss: 1.8804 - val_rmse: 1.3553\n",
      "Epoch 88/100\n",
      "389/389 - 0s - 626us/step - loss: 2.7793 - rmse: 1.6467 - val_loss: 1.8858 - val_rmse: 1.3572\n",
      "Epoch 89/100\n",
      "389/389 - 0s - 621us/step - loss: 2.7342 - rmse: 1.6300 - val_loss: 1.9104 - val_rmse: 1.3670\n",
      "Epoch 90/100\n",
      "389/389 - 0s - 671us/step - loss: 2.7689 - rmse: 1.6453 - val_loss: 1.9278 - val_rmse: 1.3729\n",
      "Epoch 91/100\n",
      "389/389 - 0s - 621us/step - loss: 2.7705 - rmse: 1.6454 - val_loss: 1.8924 - val_rmse: 1.3604\n",
      "Epoch 92/100\n",
      "389/389 - 0s - 626us/step - loss: 2.7339 - rmse: 1.6317 - val_loss: 1.9330 - val_rmse: 1.3756\n",
      "Epoch 93/100\n",
      "389/389 - 0s - 619us/step - loss: 2.7354 - rmse: 1.6306 - val_loss: 1.8409 - val_rmse: 1.3417\n",
      "Epoch 94/100\n",
      "389/389 - 0s - 625us/step - loss: 2.7833 - rmse: 1.6481 - val_loss: 1.8535 - val_rmse: 1.3461\n",
      "Epoch 95/100\n",
      "389/389 - 0s - 625us/step - loss: 2.6278 - rmse: 1.6012 - val_loss: 1.9005 - val_rmse: 1.3627\n",
      "Epoch 96/100\n",
      "389/389 - 0s - 621us/step - loss: 2.6666 - rmse: 1.6148 - val_loss: 1.9556 - val_rmse: 1.3844\n",
      "Epoch 97/100\n",
      "389/389 - 0s - 628us/step - loss: 2.6858 - rmse: 1.6141 - val_loss: 1.8159 - val_rmse: 1.3330\n",
      "Epoch 98/100\n",
      "389/389 - 0s - 619us/step - loss: 2.7239 - rmse: 1.6303 - val_loss: 1.8670 - val_rmse: 1.3509\n",
      "Epoch 99/100\n",
      "389/389 - 0s - 623us/step - loss: 2.6760 - rmse: 1.6171 - val_loss: 1.8733 - val_rmse: 1.3537\n",
      "Epoch 100/100\n",
      "389/389 - 0s - 618us/step - loss: 2.6587 - rmse: 1.6118 - val_loss: 1.8781 - val_rmse: 1.3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 - 0s - 727us/step - loss: 2.4454 - rmse: 3.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 0s - 867us/step - loss: 2.3424 - rmse: 2.9274\n",
      "78/78 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 0s - 836us/step - loss: 2.5133 - rmse: 3.0746\n",
      "78/78 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 0s - 837us/step - loss: 2.3989 - rmse: 3.0700\n",
      "78/78 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 0s - 843us/step - loss: 2.3433 - rmse: 2.9802\n",
      "78/78 - 0s - 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/Users/ralf/Projects/learning-projects/datascience-bootcamp/sep24_bds_int_medical/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:75: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 0s - 834us/step - loss: 2.5065 - rmse: 2.9728\n",
      "78/78 - 0s - 1ms/step\n",
      "01:11:41 - p24 - Predicting -\n",
      "9/9 - 0s - 8ms/step\n",
      "01:11:41 - p24 - Done -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/z7m625rj50d5ptztzplh4wgc0000gn/T/ipykernel_44209/4056389323.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[p_num]['y_pred'].loc[data[p_num]['X_test'].index, 'bg+1:00'] = y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            bg+1:00\n",
       "id                 \n",
       "p01_8459   8.476643\n",
       "p01_8460   7.035729\n",
       "p01_8461  11.247608\n",
       "p01_8462  11.681006\n",
       "p01_8463   8.078189"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg+1:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p01_8459</th>\n",
       "      <td>8.476643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8460</th>\n",
       "      <td>7.035729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8461</th>\n",
       "      <td>11.247608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8462</th>\n",
       "      <td>11.681006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8463</th>\n",
       "      <td>8.078189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.315644Z",
     "start_time": "2024-11-28T00:11:41.311036Z"
    }
   },
   "cell_type": "code",
   "source": "results[results['bg+1:00'] < 0]",
   "id": "523d216a1174288",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bg+1:00]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg+1:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.361750Z",
     "start_time": "2024-11-28T00:11:41.359336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check if all results are greater than 0\n",
    "assert (results['bg+1:00'] >= 0).all()"
   ],
   "id": "4ebb52e2cc93d12d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare the submission file",
   "id": "62816c36690eb120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.476037Z",
     "start_time": "2024-11-28T00:11:41.468972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission = results\n",
    "submission"
   ],
   "id": "67839b46a87a5226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            bg+1:00\n",
       "id                 \n",
       "p01_8459   8.476643\n",
       "p01_8460   7.035729\n",
       "p01_8461  11.247608\n",
       "p01_8462  11.681006\n",
       "p01_8463   8.078189\n",
       "...             ...\n",
       "p24_256    6.765179\n",
       "p24_257    9.281958\n",
       "p24_258    6.683356\n",
       "p24_259    7.183572\n",
       "p24_260    6.284007\n",
       "\n",
       "[3644 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg+1:00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p01_8459</th>\n",
       "      <td>8.476643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8460</th>\n",
       "      <td>7.035729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8461</th>\n",
       "      <td>11.247608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8462</th>\n",
       "      <td>11.681006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p01_8463</th>\n",
       "      <td>8.078189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p24_256</th>\n",
       "      <td>6.765179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p24_257</th>\n",
       "      <td>9.281958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p24_258</th>\n",
       "      <td>6.683356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p24_259</th>\n",
       "      <td>7.183572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p24_260</th>\n",
       "      <td>6.284007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3644 rows  1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the submission file",
   "id": "c76df6ba407a2d0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.524819Z",
     "start_time": "2024-11-28T00:11:41.516597Z"
    }
   },
   "cell_type": "code",
   "source": "submission.to_csv(f'submission-{os.path.basename(os.getcwd())}.csv')",
   "id": "a9c239f3e1efc4c9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.586112Z",
     "start_time": "2024-11-28T00:11:41.574196Z"
    }
   },
   "cell_type": "code",
   "source": "train_data['bg+1:00'].describe()",
   "id": "f3eaeb480a74bb7b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150996.000000\n",
       "mean          8.224292\n",
       "std           2.967680\n",
       "min           2.200000\n",
       "25%           6.100000\n",
       "50%           7.600000\n",
       "75%           9.800000\n",
       "max          27.800000\n",
       "Name: bg+1:00, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.628907Z",
     "start_time": "2024-11-28T00:11:41.617580Z"
    }
   },
   "cell_type": "code",
   "source": "train_data[train_data['p_num'] == 'p16']['bg+1:00'].describe()",
   "id": "1480853ed6dbf55a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: bg+1:00, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T00:11:41.661638Z",
     "start_time": "2024-11-28T00:11:41.660404Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5b6e3762ee215db6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
